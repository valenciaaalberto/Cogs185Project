{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "        \n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('../Data/shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='W', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:2.9413243746757507\n",
      "generated sequence: hee down,\n",
      "Or bathed thy growing with our heated bloods.\n",
      "\n",
      "EDWARD:\n",
      "And, in this resolution, I defy thee;\n",
      "Not willing any longer cof\t\tu\tsf\t\tS\n",
      "\n",
      "iter:399/20000 loss:2.5807229697704317\n",
      "generated sequence: omes,\n",
      "While I make way from hence to save my life:\n",
      "You understand me?\n",
      "\n",
      "BIONDELLO:\n",
      "I, sir! ne'er a whit.\n",
      "\n",
      "LUCENTIO:\n",
      "And not a jot\tf\tf\tBifo\t\n",
      "\n",
      "iter:599/20000 loss:2.5336567640304564\n",
      "generated sequence: l thee quite overthrown!\n",
      "O love! O life! not life, but love in death!\n",
      "\n",
      "CAPULET:\n",
      "Despised, distressed, hated, martyr'd, kill'd!\n",
      "U\tb\tf\t\tb\tso\n",
      "\n",
      "iter:799/20000 loss:2.4686169695854185\n",
      "generated sequence: eak to the mariners: fall to't, yarely,\n",
      "or we run ourselves aground: bestir, bestir.\n",
      "\n",
      "Boatswain:\n",
      "Heigh, my hearts! cheerly, chee\to\tbiobif\t\n",
      "\n",
      "iter:999/20000 loss:2.3892748707532885\n",
      "generated sequence: A:\n",
      "What, master, read you? first resolve me that.\n",
      "\n",
      "LUCENTIO:\n",
      "I read that I profess, the Art to Love.\n",
      "\n",
      "BIANCA:\n",
      "UBf\ti\tufyou prove,;\n",
      "\n",
      "iter:1199/20000 loss:2.358395816087723\n",
      "generated sequence: ate;\n",
      "So many hours must I sport myself;\n",
      "So many days my ewes have been with young;\n",
      "So many weeks ere the poor fools will ean:\n",
      "Soo\t\t\tU;\tufo\n",
      "\n",
      "iter:1399/20000 loss:2.3025464701652525\n",
      "generated sequence: o toil and trouble in the world,\n",
      "But that our soft conditions and our hearts\n",
      "Should well agree with our external parts?\n",
      "Come, co\tu\t\to\tuo\t\t\n",
      "\n",
      "iter:1599/20000 loss:2.2565936172008514\n",
      "generated sequence:  thee from Warwick's frown;\n",
      "And pray that I may repossess the crown.\n",
      "3 KING HENRY VI\n",
      "\n",
      "KING HENRY VI:\n",
      "Master lieutenant, now thatuif\t\tu\tf\tf\n",
      "\n",
      "iter:1799/20000 loss:2.2487286031246185\n",
      "generated sequence: ture will betray its folly,\n",
      "Its tenderness, and make itself a pastime\n",
      "To harder bosoms! Looking on the lines\n",
      "Of my boy's face, mitf\tufu\t\tu\n",
      "\n",
      "iter:1999/20000 loss:2.2089415973424913\n",
      "generated sequence: execution did cry out\n",
      "Against the non-performance, 'twas a fear\n",
      "Which oft infects the wisest: these, my lord,\n",
      "Are such allow'd i\tf\tp\tio\tuu\n",
      "\n",
      "iter:2199/20000 loss:2.1836575084924696\n",
      "generated sequence: body that enforced\n",
      "The law against it! But that her tender shame\n",
      "Will not proclaim against her maiden loss,\n",
      "How might she tonguefs\t\tb\tfs\tb\n",
      "\n",
      "iter:2399/20000 loss:2.1253415143489836\n",
      "generated sequence: stand you so assured,\n",
      "As firmly as yourself were still in place:\n",
      "Yea, and perhaps with more successful words\n",
      "Than you, unless yo\t\tou\tu\t\t\tu\n",
      "\n",
      "iter:2599/20000 loss:2.130885177254677\n",
      "generated sequence: o thrive I in my dangerous attempt\n",
      "Of hostile arms! myself myself confound!\n",
      "Heaven and fortune bar me happy hours!\n",
      "Day, yield mevb\tbfuf\tb\t\n",
      "\n",
      "iter:2799/20000 loss:2.111235340833664\n",
      "generated sequence: .\n",
      "O Thou, whose captain I account myself,\n",
      "Look on my forces with a gracious eye;\n",
      "BMuifut\tueir hands thy bruising irons of wrath,\n",
      "\n",
      "iter:2999/20000 loss:2.0851323014497756\n",
      "generated sequence:  again.\n",
      "\n",
      "ROMEO:\n",
      "O blessed, blessed night! I am afeard.\n",
      "Being in night, all this is but a dream,\n",
      "JJJ flattering-sweet to be substuupuuh\n",
      "\n",
      "iter:3199/20000 loss:2.0554523640871047\n",
      "generated sequence:  not comfort home,\n",
      "They'll give him death by inches.\n",
      "\n",
      "SICINIUS:\n",
      "What's the news?\n",
      "\n",
      "Second Messenger:\n",
      "Good news, good news; the laue\tiuu\tff\t\n",
      "\n",
      "iter:3399/20000 loss:2.018509211540222\n",
      "generated sequence: rdon, pardon;\n",
      "And I unjustly too, must grant it you\n",
      "But for my brother not a man would speak,\n",
      "Nor I, ungracious, speak unto myse\t\tv\t\tufs\t\t\n",
      "\n",
      "iter:3599/20000 loss:1.975279911160469\n",
      "generated sequence:  thought;\n",
      "Believe not that the dribbling dart of love\n",
      "Can pierce a complete bosom. Why I desire thee\n",
      "To give me secret harbour, uifnsffi\tU\n",
      "\n",
      "iter:3799/20000 loss:1.9610005390644074\n",
      "generated sequence: ;\n",
      "But by bad courses may be understood\n",
      "That their events can never fall out good.\n",
      "\n",
      "KING RICHARD II:\n",
      "psiup\tupy, to the Earl of Wi\n",
      "\n",
      "iter:3999/20000 loss:1.9765017658472062\n",
      "generated sequence: PETRUCHIO:\n",
      "No, not a whit: I find you passing gentle.\n",
      "'Twas told me you were rough and coy and sullen,\n",
      "And now I find report a vSPBPTSjP;\n",
      "\n",
      "iter:4199/20000 loss:1.925932795405388\n",
      "generated sequence: ve me no help in lamentation;\n",
      "I am not barren to bring forth complaints\n",
      "All springs reduce their currents to mine eyes,\n",
      "That I, f\tuf\tu\tuuf\n",
      "\n",
      "iter:4399/20000 loss:1.9186561864614486\n",
      "generated sequence:  he,\n",
      "That's lesser than a little.\n",
      "Hark! our drums\n",
      "Are bringing forth our youth. We'll break our walls,\n",
      "Rather than they shall poufs\tBifoit\n",
      "\n",
      "iter:4599/20000 loss:1.908307324051857\n",
      "generated sequence:  the bawdy hand of the\n",
      "dial is now upon the prick of noon.\n",
      "\n",
      "Nurse:\n",
      "Out upon you! what a man are you!\n",
      "\n",
      "ROMEO:\n",
      "One, gentlewoman, tuif\tupu\t-\t\n",
      "\n",
      "iter:4799/20000 loss:1.869630784392357\n",
      "generated sequence: I trust; for they are soldiers,\n",
      "Witty, courteous, liberal, full of spirit.\n",
      "While you are thus employ'd, what resteth more,\n",
      "But t\tuifs\ti\tup\n",
      "\n",
      "iter:4999/20000 loss:1.8323731356859208\n",
      "generated sequence: y their hate,\n",
      "Than death prorogued, wanting of thy love.\n",
      "\n",
      "JULIET:\n",
      "By whose direction found'st thou out this place?\n",
      "\n",
      "ROMEO:\n",
      "By lopu\tf\ttpufu\n",
      "\n",
      "iter:5199/20000 loss:1.8647855138778686\n",
      "generated sequence: ?\n",
      "\n",
      "AUFIDIUS:\n",
      "I know thee not: thy name?\n",
      "\n",
      "CORIOLANUS:\n",
      "My name is Caius Marcius, who hath done\n",
      "oLp\tp\tL particularly and to all the\n",
      "\n",
      "iter:5399/20000 loss:1.8414858770370484\n",
      "generated sequence:  ha't.\n",
      "\n",
      "VINCENTIO:\n",
      "'Tis a good hearing when children are toward.\n",
      "\n",
      "LUCENTIO:\n",
      "But a harsh hearing when women are froward.\n",
      "\n",
      "BBJOUCHu\tuui\n",
      "\n",
      "iter:5599/20000 loss:1.836481118798256\n",
      "generated sequence: NENIUS:\n",
      "It then remains\n",
      "That you do speak to the people.\n",
      "\n",
      "CORIOLANUS:\n",
      "I do beseech you,\n",
      "Let me o'erleap that custom, for I cannoPoPPT;\tUPi\n",
      "\n",
      "iter:5799/20000 loss:1.8346543562412263\n",
      "generated sequence: either. You, sir, come you hither;\n",
      "You that have been so tenderly officious\n",
      "With Lady Margery, your midwife there,\n",
      "upgsave this \tm\tf\tb\n",
      "\n",
      "iter:5999/20000 loss:1.8216803526878358\n",
      "generated sequence: d eat him quick,\n",
      "As thou dost swallow up this good king's blood\n",
      "Which his hell-govern'd arm hath butchered!\n",
      "\n",
      "GLOUCESTER:\n",
      "Lady, y\tu\toiu\to\tu\n",
      "\n",
      "iter:6199/20000 loss:1.805577999353409\n",
      "generated sequence: ard order: this we came not to,\n",
      "Only for propagation of a dower\n",
      "Remaining in the coffer of her friends,\n",
      "From whom we thought it ob\tuub\t\tb\n",
      "\n",
      "iter:6399/20000 loss:1.81121999502182\n",
      "generated sequence: y grief is but thy absence for a time.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Joy absent, grief is present for that time.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "What is s\tusfo\t\tuo\t\n",
      "\n",
      "iter:6599/20000 loss:1.7968369126319885\n",
      "generated sequence: Since presently your souls must part your bodies--\n",
      "With too much urging your pernicious lives,\n",
      "For 'twere no charity; yet, to waMo\tf\tu\tf\t\t\n",
      "\n",
      "iter:6799/20000 loss:1.7978557062149048\n",
      "generated sequence: art a widow; yet thou art a mother,\n",
      "And hast the comfort of thy children left thee:\n",
      "But death hath snatch'd my husband from mineu\tiuuuft\tv\n",
      "\n",
      "iter:6999/20000 loss:1.7988973957300187\n",
      "generated sequence: !\n",
      "\n",
      "GLOUCESTER:\n",
      "As much unto my good lord chamberlain!\n",
      "Well are you welcome to the open air.\n",
      "sp;sLebh your lordship brook'd impri\t\n",
      "\n",
      "iter:7199/20000 loss:1.7600910067558289\n",
      "generated sequence: t\n",
      "Shall be this cold corpse on the earth's cold face;\n",
      "But if I thrive, the gain of my attempt\n",
      "The least of you shall share his piJffo\t\tuf\t\n",
      "\n",
      "iter:7399/20000 loss:1.7518382048606873\n",
      "generated sequence:  here, rap me here,\n",
      "knock me well, and knock me soundly'? And come you\n",
      "now with, 'knocking at the gate'?\n",
      "\n",
      "PETRUCHIO:\n",
      "Sirrah, be u\t\tb\t\tubom\n",
      "\n",
      "iter:7599/20000 loss:1.7669874000549317\n",
      "generated sequence: NRY VI:\n",
      "Be patient, gentle Earl of Westmoreland.\n",
      "\n",
      "CLIFFORD:\n",
      "Patience is for poltroons, such as he:\n",
      "UZ\tdurst not sit there, had yHL;cJP\n",
      "\n",
      "iter:7799/20000 loss:1.7424248069524766\n",
      "generated sequence: .\n",
      "Will you be gone?\n",
      "\n",
      "VIRGILIA:\n",
      "\n",
      "SICINIUS:\n",
      "Are you mankind?\n",
      "\n",
      "VOLUMNIA:\n",
      "Ay, fool; is that a shame? Note but this fool.\n",
      "Uio\t\tu\t\t\t m\n",
      "\n",
      "iter:7999/20000 loss:1.7491725951433181\n",
      "generated sequence: o us or thee.\n",
      "\n",
      "Post:\n",
      "\n",
      "OXFORD:\n",
      "I like it well that our fair queen and mistress\n",
      "Smiles at her news, while Warwick frowns at his.\n",
      "\n",
      "ots\ttoft\tf\n",
      "\n",
      "iter:8199/20000 loss:1.7438065558671951\n",
      "generated sequence: w oft when men are at the point of death\n",
      "Have they been merry! which their keepers call\n",
      "A lightning before death: O, how may I\n",
      "Cpus\tiupj\t\t\n",
      "\n",
      "iter:8399/20000 loss:1.7558462297916413\n",
      "generated sequence: s a king, my flatterers\n",
      "Were then but subjects; being now a subject,\n",
      "I have a king here to my flatterer.\n",
      "Being so great, I have fusu\tt\ti\tu\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:1.7348415756225586\n",
      "generated sequence: e or two of ginger, but that I\n",
      "may beg; four pound of prunes, and as many of\n",
      "raisins o' the sun.\n",
      "\n",
      "AUTOLYCUS:\n",
      "O that ever I was b\tuv\tui\tvuv\n",
      "\n",
      "iter:8799/20000 loss:1.7265254241228103\n",
      "generated sequence: , how the villain would close now, after his\n",
      "treasonable abuses!\n",
      "\n",
      "ESCALUS:\n",
      "Such a fellow is not to be talked withal. Away with\n",
      "h\tuf\tfuif\tu\n",
      "\n",
      "iter:8999/20000 loss:1.7190131005644798\n",
      "generated sequence: ich too untimely here did scorn the earth.\n",
      "\n",
      "ROMEO:\n",
      "This day's black fate on more days doth depend;\n",
      "This but begins the woe, otheofbuiuuuse\n",
      "\n",
      "iter:9199/20000 loss:1.7296626007556914\n",
      "generated sequence:  be so far forth friendly\n",
      "maintained all by helping Baptista's eldest daughter\n",
      "to a husband we set his youngest free for a husbauv\tu\t\tu\tof\n",
      "\n",
      "iter:9399/20000 loss:1.7007957923412322\n",
      "generated sequence: ries it away.\n",
      "Tybalt, you rat-catcher, will you walk?\n",
      "\n",
      "TYBALT:\n",
      "What wouldst thou have with me?\n",
      "\n",
      "MERCUTIO:\n",
      "Good king of cats, notft\tfutiuop\n",
      "\n",
      "iter:9599/20000 loss:1.6895764774084092\n",
      "generated sequence: me to your father's? we'll\n",
      "to dinner, thither.\n",
      "\n",
      "ROMEO:\n",
      "I will follow you.\n",
      "\n",
      "MERCUTIO:\n",
      "Farewell, ancient lady; farewell,\n",
      "'lady, laf\tu\t\tup\tt\t\n",
      "\n",
      "iter:9799/20000 loss:1.7093482500314712\n",
      "generated sequence: ill fair Juliet wake:\n",
      "She will beshrew me much that Romeo\n",
      "Hath had no notice of these accidents;\n",
      "But I will write again to Mantutbbupotfup\n",
      "\n",
      "iter:9999/20000 loss:1.6896885168552398\n",
      "generated sequence: e less, some more your voices:\n",
      "Indeed I would be consul.\n",
      "\n",
      "Sixth Citizen:\n",
      "He has done nobly, and cannot go without any honest\n",
      "man\tub\t\t\t\tu\t\t\n",
      "\n",
      "iter:10199/20000 loss:1.6946597021818162\n",
      "generated sequence: of this; it does offend my heart:\n",
      "Pray now, no more.\n",
      "\n",
      "COMINIUS:\n",
      "Look, sir, your mother!\n",
      "\n",
      "CORIOLANUS:\n",
      "O,\n",
      "You have, I know, petitivpu\tjt\t\tut\n",
      "\n",
      "iter:10399/20000 loss:1.6871774500608445\n",
      "generated sequence: ands.\n",
      "\n",
      "CAPULET:\n",
      "When the sun sets, the air doth drizzle dew;\n",
      "But for the sunset of my brother's son\n",
      "It rains downright.\n",
      "BBb;bow!uu\tf\n",
      "\n",
      "iter:10599/20000 loss:1.6919705307483672\n",
      "generated sequence: e.\n",
      "\n",
      "MENENIUS:\n",
      "Do you hear?\n",
      "\n",
      "COMINIUS:\n",
      "Yet one time he did call me by my name:\n",
      "I urged our old acquaintance, and the drops\n",
      "UUbSESE;\n",
      "\n",
      "iter:10799/20000 loss:1.694147190451622\n",
      "generated sequence: US:\n",
      "Stop,\n",
      "Or all will fall in broil.\n",
      "\n",
      "CORIOLANUS:\n",
      "Are these your herd?\n",
      "Must these have voices, that can yield them now\n",
      "f\tvb\ttraiTf\n",
      "\n",
      "iter:10999/20000 loss:1.6711959993839265\n",
      "generated sequence:  thy glory\n",
      "To feed my humour, wish thyself no harm.\n",
      "\n",
      "LADY ANNE:\n",
      "No! why?  When he that is my husband now\n",
      "Came to me, as I followuij\tui\to\t\t\n",
      "\n",
      "iter:11199/20000 loss:1.6817412209510803\n",
      "generated sequence:  friends at peace on earth.\n",
      "Rivers and Hastings, take each other's hand;\n",
      "Dissemble not your hatred, swear your love.\n",
      "\n",
      "RIVERS:\n",
      "Byu\t\to\th\t\tuu\n",
      "\n",
      "iter:11399/20000 loss:1.6699212330579758\n",
      "generated sequence: e controll'd the war; but one of these--\n",
      "As he hath spices of them all, not all,\n",
      "For I dare so far free him--made him fear'd,\n",
      "So\tups\ti\ts\t\t\n",
      "\n",
      "iter:11599/20000 loss:1.6669474941492082\n",
      "generated sequence: APULET:\n",
      "Well, well, thou hast a careful father, child;\n",
      "One who, to put thee from thy heaviness,\n",
      "i\tth sorted out a sudden day of OFTPOi\n",
      "\n",
      "iter:11799/20000 loss:1.6818178570270539\n",
      "generated sequence: f my trade:\n",
      "And there it is in writing, fairly drawn.\n",
      "\n",
      "BIANCA:\n",
      "Why, I am past my gamut long ago.\n",
      "\n",
      "HORTENSIO:\n",
      "Yet read the gamut puzpuifu\t\t\n",
      "\n",
      "iter:11999/20000 loss:1.6690831285715104\n",
      "generated sequence: climate souls refined\n",
      "Should show so heinous, black, obscene a deed!\n",
      "I speak to subjects, and a subject speaks,\n",
      "Stirr'd up by Goifofs\t\tufo\n",
      "\n",
      "iter:12199/20000 loss:1.6561009204387664\n",
      "generated sequence: he is grown most kind of late.\n",
      "\n",
      "Both Tribunes:\n",
      "Hail sir!\n",
      "\n",
      "MENENIUS:\n",
      "Hail to you both!\n",
      "\n",
      "SICINIUS:\n",
      "Your Coriolanus\n",
      "Is not much misb\tuo\tuffvf\n",
      "\n",
      "iter:12399/20000 loss:1.6752995359897613\n",
      "generated sequence: nry Bolingbroke.\n",
      "\n",
      "KING RICHARD II:\n",
      "Give me the crown. Here, cousin, seize the crown;\n",
      "Here cousin:\n",
      "On this side my hand, and on te\t\tuBvjfep\n",
      "\n",
      "iter:12599/20000 loss:1.651305605173111\n",
      "generated sequence: ight.\n",
      "\n",
      "CAPULET:\n",
      "Young Romeo is it?\n",
      "\n",
      "TYBALT:\n",
      "'Tis he, that villain Romeo.\n",
      "\n",
      "CAPULET:\n",
      "Content thee, gentle coz, let him alone;\n",
      "UUBMpppi\n",
      "\n",
      "iter:12799/20000 loss:1.6473943203687669\n",
      "generated sequence:  did repent me, after more advice;\n",
      "For testimony whereof, one in the prison,\n",
      "That should by private order else have died,\n",
      "I haveu\th\tuf\tf\tu\n",
      "\n",
      "iter:12999/20000 loss:1.6706337249279022\n",
      "generated sequence: ense:\n",
      "I mean, Hortensio is afeard of you.\n",
      "\n",
      "Widow:\n",
      "He that is giddy thinks the world turns round.\n",
      "\n",
      "PETRUCHIO:\n",
      "Roundly replied.\n",
      "\n",
      "K\tpf\t\tDJuf\t\n",
      "\n",
      "iter:13199/20000 loss:1.6703909456729888\n",
      "generated sequence: this land by lease;\n",
      "But for thy world enjoying but this land,\n",
      "Is it not more than shame to shame it so?\n",
      "Landlord of England art \tfd\tufo\t\tu\n",
      "\n",
      "iter:13399/20000 loss:1.6556132817268372\n",
      "generated sequence: well we know your tenderness of heart\n",
      "And gentle, kind, effeminate remorse,\n",
      "Which we have noted in you to your kin,\n",
      "And egally if\t\t\tuf\tufp\n",
      "\n",
      "iter:13599/20000 loss:1.6661206138134004\n",
      "generated sequence: t.\n",
      "\n",
      "ANGELO:\n",
      "He shall not, Isabel, if you give me love.\n",
      "\n",
      "ISABELLA:\n",
      "I know your virtue hath a licence in't,\n",
      "BBJffO\tMems a little fi\n",
      "\n",
      "iter:13799/20000 loss:1.6462137126922607\n",
      "generated sequence:  EDWARD IV:\n",
      "So, lie thou there: die thou, and die our fear;\n",
      "For Warwick was a bug that fear'd us all.\n",
      "Now, Montague, sit fast; IuMSfMLSu\tJ\n",
      "\n",
      "iter:13999/20000 loss:1.6424494934082032\n",
      "generated sequence:  this proud disdainful haggard.\n",
      "And so farewell, Signior Lucentio.\n",
      "Kindness in women, not their beauteous looks,\n",
      "Shall win my louffo\tuf\tvu\n",
      "\n",
      "iter:14199/20000 loss:1.6398987227678299\n",
      "generated sequence:  sadly after; grace my mournings here;\n",
      "In weeping after this untimely bier.\n",
      "\n",
      "\n",
      "SAMPSON:\n",
      "Gregory, o' my word, we'll not carry coalu\ts\tf\tusp\t\n",
      "\n",
      "iter:14399/20000 loss:1.6498504918813706\n",
      "generated sequence: \n",
      "\n",
      "Servant:\n",
      "My master's.\n",
      "\n",
      "ROMEO:\n",
      "Indeed, I should have ask'd you that before.\n",
      "\n",
      "Servant:\n",
      "\t\tffseil tell you without asking: my mast\n",
      "\n",
      "iter:14599/20000 loss:1.6401762586832047\n",
      "generated sequence: sumed his royal person:\n",
      "'Tis very grievous to be thought upon.\n",
      "What, is he in his bed?\n",
      "\n",
      "HASTINGS:\n",
      "He is.\n",
      "\n",
      "GLOUCESTER:\n",
      "Go you bef\ttf\t\tufo\tu\n",
      "\n",
      "iter:14799/20000 loss:1.6218458372354507\n",
      "generated sequence: them good.\n",
      "\n",
      "LADY GREY:\n",
      "Therefore I came unto your majesty.\n",
      "\n",
      "KING EDWARD IV:\n",
      "I'll tell you how these lands are to be got.\n",
      "\n",
      "LADY Gif\tfuiss\t\n",
      "\n",
      "iter:14999/20000 loss:1.6448835676908493\n",
      "generated sequence: him;\n",
      "His remedies are tame i' the present peace\n",
      "And quietness of the people, which before\n",
      "Were in wild hurry. Here do we make hipob\tJpo\tuf\n",
      "\n",
      "iter:15199/20000 loss:1.6458748495578766\n",
      "generated sequence: \n",
      "Imagine 'twere the right Vincentio.\n",
      "\n",
      "BIONDELLO:\n",
      "Tut, fear not me.\n",
      "\n",
      "TRANIO:\n",
      "But hast thou done thy errand to Baptista?\n",
      "\n",
      "\tfmio\t\tue\n",
      "\n",
      "iter:15399/20000 loss:1.6085278350114822\n",
      "generated sequence: orship means to make\n",
      "a puppet of her.\n",
      "\n",
      "PETRUCHIO:\n",
      "O monstrous arrogance! Thou liest, thou thread,\n",
      "thou thimble,\n",
      "Thou yard, threeo\t\tftfuc\to\n",
      "\n",
      "iter:15599/20000 loss:1.6296048063039779\n",
      "generated sequence: foul bunch-back'd toad!\n",
      "\n",
      "QUEEN MARGARET:\n",
      "I call'd thee then vain flourish of my fortune;\n",
      "I call'd thee then poor shadow, painted\t\ttmuft\tfb\n",
      "\n",
      "iter:15799/20000 loss:1.6338298314809798\n",
      "generated sequence:  away this captive scold.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Nay, take away this scolding crookback rather.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Peace, wilful boy, or uopo\tu\tfo\t\n",
      "\n",
      "iter:15999/20000 loss:1.6171807199716568\n",
      "generated sequence: ft;\n",
      "Riddling confession finds but riddling shrift.\n",
      "\n",
      "ROMEO:\n",
      "Then plainly know my heart's dear love is set\n",
      "Jo\t\tmo fair daughter ofp\t\t\n",
      "\n",
      "iter:16199/20000 loss:1.623369573354721\n",
      "generated sequence: BOLINGBROKE:\n",
      "You shall.\n",
      "\n",
      "KING RICHARD II:\n",
      "Then give me leave to go.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Whither?\n",
      "\n",
      "KING RICHARD II:\n",
      "Whither you wvMp\tpsvJMJ\n",
      "\n",
      "iter:16399/20000 loss:1.621352515220642\n",
      "generated sequence: gainst the butchers of his life!\n",
      "But since correction lieth in those hands\n",
      "Which made the fault that we cannot correct,\n",
      "Put we oi\tt\tfiuif\t\n",
      "\n",
      "iter:16599/20000 loss:1.6069199526309967\n",
      "generated sequence: sion without giving?\n",
      "\n",
      "TYBALT:\n",
      "Mercutio, thou consort'st with Romeo,--\n",
      "\n",
      "MERCUTIO:\n",
      "Consort! what, dost thou make us minstrels? an\n",
      "ftseu\tti\ts\n",
      "\n",
      "iter:16799/20000 loss:1.626374905705452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: female buds shall you this night\n",
      "Inherit at my house; hear all, all see,\n",
      "And like her most whose merit most shall be:\n",
      "Which on mp\tbo\t\tusm\t\n",
      "\n",
      "iter:16999/20000 loss:1.6247377431392669\n",
      "generated sequence: EN ELIZABETH:\n",
      "Why brother Rivers, are you yet to learn\n",
      "What late misfortune is befall'n King Edward?\n",
      "\n",
      "RIVERS:\n",
      "What! loss of someUJuUj\tFOvU\n",
      "\n",
      "iter:17199/20000 loss:1.6099327731132507\n",
      "generated sequence: ks,\n",
      "Nor made to court an amorous looking-glass;\n",
      "I, that am rudely stamp'd, and want love's majesty\n",
      "J\tfufsut before a wanton amblf\t\n",
      "\n",
      "iter:17399/20000 loss:1.594748548567295\n",
      "generated sequence: might have your\n",
      "action of slander too.\n",
      "\n",
      "ELBOW:\n",
      "Marry, I thank your good worship for it. What is't\n",
      "your worship's pleasure I shalftff\tuf\tf\t\n",
      "\n",
      "iter:17599/20000 loss:1.611655045747757\n",
      "generated sequence: fair beloved: therefore, I pray you,\n",
      "As you have ever been my father's honour'd friend,\n",
      "When he shall miss me,--as, in faith, I \tuofubs\t\tf\n",
      "\n",
      "iter:17799/20000 loss:1.6114692240953445\n",
      "generated sequence: t\n",
      "For which the people stir: if you will pass\n",
      "To where you are bound, you must inquire your way,\n",
      "\t\t\tu\tfoiu are out of, with a ge\t\n",
      "\n",
      "iter:17999/20000 loss:1.6091457027196885\n",
      "generated sequence: t sea?\n",
      "\n",
      "ISABELLA:\n",
      "I have heard of the lady, and good words went with her name.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "UU;;should this Angelo have marriu\t\to\n",
      "\n",
      "iter:18199/20000 loss:1.5886828303337097\n",
      "generated sequence: ce of God and this mine arm,\n",
      "To prove him, in defending of myself,\n",
      "A traitor to my God, my king, and me:\n",
      "And as I truly fight, df\tuvfupvfu\n",
      "\n",
      "iter:18399/20000 loss:1.6007642948627472\n",
      "generated sequence: money. I hope to see Romans as cheap\n",
      "as Volscians. They are rising, they are rising.\n",
      "\n",
      "All:\n",
      "In, in, in, in!\n",
      "\n",
      "SICINIUS:\n",
      "uPufear nofue\t\t\n",
      "\n",
      "iter:18599/20000 loss:1.605821213722229\n",
      "generated sequence: rpetual, could not move the gods\n",
      "To look that way thou wert.\n",
      "\n",
      "LEONTES:\n",
      "Go on, go on\n",
      "Thou canst not speak too much; I have deservfi\tisop\tuf\n",
      "\n",
      "iter:18799/20000 loss:1.6077239120006561\n",
      "generated sequence: e you till you are so?\n",
      "\n",
      "COMINIUS:\n",
      "Marcius,\n",
      "We have at disadvantage fought and did\n",
      "Retire to win our purpose.\n",
      "\n",
      "MARCIUS:\n",
      "How lies su\t\tsu\ttmm\n",
      "\n",
      "iter:18999/20000 loss:1.5980198568105697\n",
      "generated sequence:  I go; I'll win them, fear it not:\n",
      "And thus most humbly I do take my leave.\n",
      "Sir John and Sir Hugh Mortimer, mine uncles,\n",
      "You areu;uiv\tu;tf\n",
      "\n",
      "iter:19199/20000 loss:1.5851289689540864\n",
      "generated sequence: will.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "My lords, before it pleased his majesty\n",
      "To raise my state to title of a queen,\n",
      "v\tOme but right, and you \toff\n",
      "\n",
      "iter:19399/20000 loss:1.607545599937439\n",
      "generated sequence: e assurance here in Padua\n",
      "Of greater sums than I have promised.\n",
      "So shall you quietly enjoy your hope,\n",
      "And marry sweet Bianca wit\tus\t\tsfsei\n",
      "\n",
      "iter:19599/20000 loss:1.5795290422439576\n",
      "generated sequence: pect more favourable. Good my lords,\n",
      "I am not prone to weeping, as our sex\n",
      "Commonly are; the want of which vain dew\n",
      "Perchance shf\tf\tufv\t\tu\n",
      "\n",
      "iter:19799/20000 loss:1.616769317984581\n",
      "generated sequence: to say. We will give you sleepy drinks,\n",
      "that your senses, unintelligent of our insufficience,\n",
      "uj\t, though they cannot praise us,ivu\tu\t\n",
      "\n",
      "iter:19999/20000 loss:1.5907955944538117\n",
      "generated sequence: , thou\n",
      "Hast cleansed my bosom, I from thee departed\n",
      "Thy penitent reform'd: but we have been\n",
      "Deceived in thy integrity, deceived\n",
      "uif\tmU\tu\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,input,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"created to be awed by man,\\nWast born to bear? I was not made a horse;\\nAnd yet I bear a burthen like an ass,\\nSpurr'd, gall'd and pf\\tui\\t\\tui\\tuf\\tuuf\\t\\tufpufup\\rUBu\\tiuf\\tfpui\\tuf\\tuf\\ru\\tufu\\tup\\tiufu\\t\\tuuuf\\tf\\t\\t\\rUop\\tup\\tiu\\tuf\\tufuuufmfif\\tpu\\tof\\tuupuu\\t\\t\\rU;fmffe\\t\\ruiu\\t\\te\\tuup\\tu\\t\\tuifuuifui\\tuii\\tuui\\t\\ti\\ti\\tUfoiufi\\tu\\t\\tifui\\tui\\tUiui\\tiui\\tufi\\tiuuiii\\tu\\tuuUfp\\tui\\tufiui\\tui\\tiii\\t\\t\\tf\\tu\\tiup\\tuii\\tiiuuUf\\r\\t\\t\\t\\t\\tuUifiuu\\tuii\\tuiuuif\\tiif\\tifuiffuiifuufufuf\\tpfi\\tfuiuuf\\tifuifuffifufifui\\tfufiifffuiuiif\\t\\tuifui\\tfifuifufffuuu\\tuiufi\\tuiffuffiif\\tUuuuuuiff\\tfiiuiffuifiif\\tuff\\tuf\\tif\\t\\tiff\\tii\\ti\\ti\\tu\\t\\tfu\\tifii\\tuf\\tif\\ti\\t\\tf\\ti\\tf\\tifu\\ti\\tff\\t\\t\\tififf\\tuuif\\tifu\\tf\\tif\\ti\\t\\t\\tiiiuifi\\tfuif\\t\\ti\\t\\tff\\tufiiiiif\\t\\tu\\tffif\\t\\tif\\tff\\tui\\t\\tui\\tuf\\tuuf\\t\\tuffufufuiuu\\tiuf\\tffui\\tuf\\tufuu\\tufu\\tuf\\tiufu\\t\\tuuuf\\tf\\t\\tuiif\\tuf\\tiu\\tuf\\tufuuuf\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes To Model\n",
    "\n",
    "In attempting to printing the output of the current model, the main change was for the model to pass in the input twice,since the target gave away the answers in the decoder layer. This prevented the model from generalizing to other input and thus had bad behavior in printing words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
