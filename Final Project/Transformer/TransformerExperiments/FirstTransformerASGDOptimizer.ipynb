{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b\n",
      "\f\n",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "# d_ff = 2048\n",
    "# d_ff = 128\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='Wha', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:2.8661644983291628\n",
      "generated sequence: hort work;\n",
      "For, by your leaves, you shall not stay alone\n",
      "Till holy church incorporate two in one.\n",
      "\n",
      "BENVOLIO:\n",
      "I pray thee, good Mfof\tbfoff\t\n",
      "\n",
      "iter:399/20000 loss:2.576798870563507\n",
      "generated sequence: o marry but by my free leave?\n",
      "\n",
      "LEONTES:\n",
      "Never, Paulina; so be blest my spirit!\n",
      "\n",
      "PAULINA:\n",
      "Then, good my lords, bear witness to hisu\toffpuus\n",
      "\n",
      "iter:599/20000 loss:2.5288721823692324\n",
      "generated sequence: atisfy.\n",
      "\n",
      "WARWICK:\n",
      "Ay, but he's dead: off with the traitor's head,\n",
      "And rear it in the place your father's stands.\n",
      "TTi now to Londoio\t\tp\n",
      "\n",
      "iter:799/20000 loss:2.4725409710407256\n",
      "generated sequence: ther come,\n",
      "Where shall we sojourn till our coronation?\n",
      "\n",
      "GLOUCESTER:\n",
      "Where it seems best unto your royal self.\n",
      "If I may counsel y\tf\t\tuf\tf\t\t\n",
      "\n",
      "iter:999/20000 loss:2.418916380405426\n",
      "generated sequence: ONE:\n",
      "Why, here's a change indeed in the commonwealth!\n",
      "What shall become of me?\n",
      "\n",
      "POMPEY:\n",
      "u\t\t\t; fear you not: good counsellors lac\t\t;\n",
      "\n",
      "iter:1199/20000 loss:2.3561621582508088\n",
      "generated sequence: nce to France.\n",
      "And now what rests but that we spend the time\n",
      "With stately triumphs, mirthful comic shows,\n",
      "Such as befits the ple\ti\tu\t\tu\tfo\n",
      "\n",
      "iter:1399/20000 loss:2.307565053105354\n",
      "generated sequence: have come so far,\n",
      "And be it moon, or sun, or what you please:\n",
      "An if you please to call it a rush-candle,\n",
      "Henceforth I vow it sha\tof\tupof\tu\n",
      "\n",
      "iter:1599/20000 loss:2.2748088032007217\n",
      "generated sequence: , 'tis but a while!\n",
      "Tread on the sand; why, there you quickly sink:\n",
      "Bestride the rock; the tide will wash you off,\n",
      "b\tiffbbsiou f\n",
      "\n",
      "iter:1799/20000 loss:2.2313932663202287\n",
      "generated sequence:  friar too.\n",
      "\n",
      "PRINCE:\n",
      "What misadventure is so early up,\n",
      "That calls our person from our morning's rest?\n",
      "\n",
      "CAPULET:\n",
      "What should it buffoofuivv\n",
      "\n",
      "iter:1999/20000 loss:2.1976525843143464\n",
      "generated sequence:  direction\n",
      "Let's want no discipline, make no delay,\n",
      "For, lords, to-morrow is a busy day.\n",
      "\n",
      "RICHMOND:\n",
      "The weary sun hath made a goufof\tb\tos\t\n",
      "\n",
      "iter:2199/20000 loss:2.150754103064537\n",
      "generated sequence: e old folks,\n",
      "how the young folks lay their heads together!\n",
      "Master, master, look about you: who goes there, ha?\n",
      "\n",
      "HORTENSIO:\n",
      "Peace\tue\t\tupe\t\t\n",
      "\n",
      "iter:2399/20000 loss:2.1266803300380706\n",
      "generated sequence: S:\n",
      "For corn at their own rates; whereof, they say,\n",
      "The city is well stored.\n",
      "\n",
      "MARCIUS:\n",
      "Hang 'em! They say!\n",
      "They'll sit by the firi\tUps\tufs\t\n",
      "\n",
      "iter:2599/20000 loss:2.085358046293259\n",
      "generated sequence: m:\n",
      "Unshout the noise that banish'd Marcius,\n",
      "Repeal him with the welcome of his mother;\n",
      "Cry 'Welcome, ladies, welcome!'\n",
      "\n",
      "All:\n",
      "BLf\t\t\ts\t\n",
      "\n",
      "iter:2799/20000 loss:2.0831647229194643\n",
      "generated sequence: ibunes\n",
      "To the people! Coriolanus, patience!\n",
      "Speak, good Sicinius.\n",
      "\n",
      "SICINIUS:\n",
      "Hear me, people; peace!\n",
      "\n",
      "Citizens:\n",
      "Let's hear our toftf\tfBSvn\n",
      "\n",
      "iter:2999/20000 loss:2.0425590574741364\n",
      "generated sequence: henceforth shall I joy again,\n",
      "Never, O never shall I see more joy!\n",
      "\n",
      "RICHARD:\n",
      "I cannot weep; for all my body's moisture\n",
      "Scarce sef\t\tf\tpvf\tf\n",
      "\n",
      "iter:3199/20000 loss:2.0227686685323714\n",
      "generated sequence:  of pines I met them; never\n",
      "Saw I men scour so on their way: I eyed them\n",
      "Even to their ships.\n",
      "\n",
      "LEONTES:\n",
      "How blest am I\n",
      "In my jusuvfusohsfu\n",
      "\n",
      "iter:3399/20000 loss:1.997554721236229\n",
      "generated sequence: ORK:\n",
      "Which for some reasons, sir, I mean to see.\n",
      "I fear, I fear,--\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "What should you fear?\n",
      "U\tftffothing but someOUF\n",
      "\n",
      "iter:3599/20000 loss:1.9807565629482269\n",
      "generated sequence: d to misuse me so.\n",
      "\n",
      "PETRUCHIO:\n",
      "Now, by the world, it is a lusty wench;\n",
      "I love her ten times more than e'er I did:\n",
      "O, how I long \tuioufo\ts\t\n",
      "\n",
      "iter:3799/20000 loss:1.9583187019824981\n",
      "generated sequence: doubt not then but innocence shall make\n",
      "False accusation blush and tyranny\n",
      "Tremble at patience. You, my lord, best know,\n",
      "Who lea\tossiuhoiu\n",
      "\n",
      "iter:3999/20000 loss:1.947816506624222\n",
      "generated sequence: ather keeps from all access of suitors,\n",
      "And will not promise her to any man\n",
      "Until the elder sister first be wed:\n",
      "The younger theoifu\tufuup\n",
      "\n",
      "iter:4199/20000 loss:1.9159010881185532\n",
      "generated sequence: LANUS:\n",
      "I had rather have one scratch my head i' the sun\n",
      "When the alarum were struck than idly sit\n",
      "To hear my nothings monster'd.VUHT;\tUHu\t\n",
      "\n",
      "iter:4399/20000 loss:1.8876644790172576\n",
      "generated sequence: ch the friar\n",
      "Subtly hath minister'd to have me dead,\n",
      "Lest in this marriage he should be dishonour'd,\n",
      "Because he married me beforifu\tfsuj\to\n",
      "\n",
      "iter:4599/20000 loss:1.8753541219234466\n",
      "generated sequence: hou liest.\n",
      "Three parts of that receipt I had for Calais\n",
      "Disbursed I duly to his highness' soldiers;\n",
      "The other part reserved I by\totu\tt\t\t\t\n",
      "\n",
      "iter:4799/20000 loss:1.8554612648487092\n",
      "generated sequence: et of the park.\n",
      "Thus stands the case: you know our king, my brother,\n",
      "Is prisoner to the bishop here, at whose hands\n",
      "He hath good\t\tu\t\tu\tf\tu\n",
      "\n",
      "iter:4999/20000 loss:1.8409233462810517\n",
      "generated sequence: and honour I for aye allow.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Here comes my son Aumerle.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Aumerle that was;\n",
      "But that is lost for bsp\tufvpvt\t\n",
      "\n",
      "iter:5199/20000 loss:1.8528836673498155\n",
      "generated sequence: say, with child, and\n",
      "being great-bellied, and longing, as I said, for\n",
      "prunes; and having but two in the dish, as I said,\n",
      "Master \tu\t\tufo\tfu\n",
      "\n",
      "iter:5399/20000 loss:1.8471314775943757\n",
      "generated sequence: tending but the signal to begin.\n",
      "\n",
      "Lord Marshal:\n",
      "Sound, trumpets; and set forward, combatants.\n",
      "Stay, the king hath thrown his wari\tp\tfpbupu\n",
      "\n",
      "iter:5599/20000 loss:1.8239789932966233\n",
      "generated sequence:  those\n",
      "That scarce, some two days since, were worth a noble.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "By Him that raised me to this careful height\n",
      "Sfomuifv\t\t\n",
      "\n",
      "iter:5799/20000 loss:1.7998065286874771\n",
      "generated sequence: on, whom you know\n",
      "Of stuff'd sufficiency: now from the oracle\n",
      "They will bring all; whose spiritual counsel had,\n",
      "iifvfi\ttop or spv\t\n",
      "\n",
      "iter:5999/20000 loss:1.8001559546589851\n",
      "generated sequence: royal throne of kings, this scepter'd isle,\n",
      "This earth of majesty, this seat of Mars,\n",
      "This other Eden, demi-paradise,\n",
      "This fortrfv\tspu\tffv\n",
      "\n",
      "iter:6199/20000 loss:1.8285234069824219\n",
      "generated sequence: omplain.\n",
      "\n",
      "ISABELLA:\n",
      "And is this all?\n",
      "Then, O you blessed ministers above,\n",
      "Keep me in patience, and with ripen'd time\n",
      "DDfold the vf\tmooh\n",
      "\n",
      "iter:6399/20000 loss:1.8001658302545547\n",
      "generated sequence:  stay too long from her:\n",
      "The morning wears, 'tis time we were at church.\n",
      "\n",
      "TRANIO:\n",
      "See not your bride in these unreverent robes:\n",
      "ufio\tui\t\tu\n",
      "\n",
      "iter:6599/20000 loss:1.787254003882408\n",
      "generated sequence: IUS:\n",
      "Hang 'em! They say!\n",
      "They'll sit by the fire, and presume to know\n",
      "What's done i' the Capitol; who's like to rise,\n",
      "puf\tuhrive;T;\n",
      "\n",
      "iter:6799/20000 loss:1.7960068029165268\n",
      "generated sequence: lone.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "HASTINGS:\n",
      "Why, master mayor, why stand you in a doubt?\n",
      "Open the gates; we are King Henry's friends.\n",
      "\n",
      "Mayor:\n",
      "pJ;s\n",
      "\n",
      "iter:6999/20000 loss:1.7574354535341263\n",
      "generated sequence: thou shalt to London presently,\n",
      "And whet on Warwick to this enterprise.\n",
      "Thou, Richard, shalt to the Duke of Norfolk,\n",
      "And tell hiifstuufufi\n",
      "\n",
      "iter:7199/20000 loss:1.7668547821044922\n",
      "generated sequence: ROMEO:\n",
      "'Tis torture, and not mercy: heaven is here,\n",
      "Where Juliet lives; and every cat and dog\n",
      "tSo little mouse, every unworthy t;;BH;\n",
      "\n",
      "iter:7399/20000 loss:1.782670676112175\n",
      "generated sequence:  on him such a countenance\n",
      "As he had lost some province and a region\n",
      "Loved as he loves himself: even now I met him\n",
      "With customaruseu\tobu\t\t\n",
      "\n",
      "iter:7599/20000 loss:1.7658636635541916\n",
      "generated sequence: \n",
      "Take heed, Signior Baptista, lest you be\n",
      "cony-catched in this business: I dare swear this\n",
      "is the right Vincentio.\n",
      "\n",
      "Pedant:\n",
      "pojeufee\t\n",
      "\n",
      "iter:7799/20000 loss:1.748139244914055\n",
      "generated sequence: nca, get thee in.\n",
      "\n",
      "KATHARINA:\n",
      "What, will you not suffer me? Nay, now I see\n",
      "She is your treasure, she must have a husband;\n",
      "I mustppo\tu\tsiui\n",
      "\n",
      "iter:7999/20000 loss:1.7442902368307114\n",
      "generated sequence: more in them\n",
      "than you'ld think, sister.\n",
      "\n",
      "PERDITA:\n",
      "Ay, good brother, or go about to think.\n",
      "\n",
      "AUTOLYCUS:\n",
      "Lawn as white as driven snf\tfsug\tuif\n",
      "\n",
      "iter:8199/20000 loss:1.7328281086683273\n",
      "generated sequence: o openly\n",
      "Proceed in justice, which shall have due course,\n",
      "Even to the guilt or the purgation.\n",
      "Produce the prisoner.\n",
      "\n",
      "Officer:\n",
      "It\tu\ts\tef\tBv\n",
      "\n",
      "iter:8399/20000 loss:1.7351823598146439\n",
      "generated sequence: \n",
      "Ay, the heads of the maids, or their maidenheads;\n",
      "take it in what sense thou wilt.\n",
      "\n",
      "GREGORY:\n",
      "They must take it in sense that feBS\t\tuff\tuf\n",
      "\n",
      "iter:8599/20000 loss:1.7101298308372497\n",
      "generated sequence: 't not enough thou hast suborn'd these women\n",
      "To accuse this worthy man, but, in foul mouth\n",
      "And in the witness of his proper ear,tpuugpu\tug\n",
      "\n",
      "iter:8799/20000 loss:1.7134593135118485\n",
      "generated sequence: GLOUCESTER:\n",
      "Sirrah, leave us to ourselves: we must confer.\n",
      "\n",
      "KING HENRY VI:\n",
      "So flies the reckless shepherd from the wolf;\n",
      "So firsPFOD\tUPiUp\n",
      "\n",
      "iter:8999/20000 loss:1.723167005777359\n",
      "generated sequence: ng-day.\n",
      "Provide the feast, father, and bid the guests;\n",
      "I will be sure my Katharina shall be fine.\n",
      "\n",
      "BAPTISTA:\n",
      "Uffnow not what to ff\n",
      "\n",
      "iter:9199/20000 loss:1.7135918015241622\n",
      "generated sequence: softly;\n",
      "Yond crickets shall not hear it.\n",
      "\n",
      "HERMIONE:\n",
      "Come on, then,\n",
      "And give't me in mine ear.\n",
      "\n",
      "LEONTES:\n",
      "\tvs he met there? his tr\tvp\t\t\t\t\n",
      "\n",
      "iter:9399/20000 loss:1.7112321084737778\n",
      "generated sequence: CIUS:\n",
      "They have a leader,\n",
      "Tullus Aufidius, that will put you to 't.\n",
      "I sin in envying his nobility,\n",
      "UBf\t\tere I any thing but whatF;D;\n",
      "\n",
      "iter:9599/20000 loss:1.6937496370077134\n",
      "generated sequence: blot out me, and put his own son in.\n",
      "\n",
      "CLIFFORD:\n",
      "And reason too:\n",
      "Who should succeed the father but the son?\n",
      "\n",
      "RICHARD:\n",
      "Are you thef\tviuvsiuf\n",
      "\n",
      "iter:9799/20000 loss:1.7208445346355439\n",
      "generated sequence: d how the less,\n",
      "That burn by day and night: and then I loved thee\n",
      "And show'd thee all the qualities o' the isle,\n",
      "The fresh sprin\tuf\tfuif\tu\n",
      "\n",
      "iter:9999/20000 loss:1.7074823331832887\n",
      "generated sequence: \n",
      "No more infected with my country's love\n",
      "Than when I parted hence, but still subsisting\n",
      "Under your great command. You are to knoT\tvufv\t\tus\n",
      "\n",
      "iter:10199/20000 loss:1.6954665529727935\n",
      "generated sequence: nd Dion, have\n",
      "Been both at Delphos, and from thence have brought\n",
      "The seal'd-up oracle, by the hand deliver'd\n",
      "Of great Apollo's pe\tupuve\tub\n",
      "\n",
      "iter:10399/20000 loss:1.7046857088804246\n",
      "generated sequence: nd pluck out his eyes!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "You shall not be admitted to his sight.\n",
      "\n",
      "ISABELLA:\n",
      "Unhappy Claudio! wretched Isabel!\n",
      "Inj\t\tujmup\tuo\n",
      "\n",
      "iter:10599/20000 loss:1.687421647310257\n",
      "generated sequence: :\n",
      "A pox o' your throat, you bawling, blasphemous,\n",
      "incharitable dog!\n",
      "\n",
      "Boatswain:\n",
      "Work you then.\n",
      "\n",
      "ANTONIO:\n",
      "Hang, cur! hang, you wh\tXou\tofuo\t\n",
      "\n",
      "iter:10799/20000 loss:1.682982975244522\n",
      "generated sequence: ast made good haste:\n",
      "Come, we will walk. There's other of our friends\n",
      "Will greet us here anon, my gentle Varrius.\n",
      "\n",
      "ISABELLA:\n",
      "To o\tiufo\toup\n",
      "\n",
      "iter:10999/20000 loss:1.6874567085504533\n",
      "generated sequence: o;\n",
      "Am I the master here, or you? go to.\n",
      "You'll not endure him! God shall mend my soul!\n",
      "You'll make a mutiny among my guests!\n",
      "Youu\tBofu\tuif\n",
      "\n",
      "iter:11199/20000 loss:1.651049600839615\n",
      "generated sequence: dvance his burning eye,\n",
      "The day to cheer and night's dank dew to dry,\n",
      "I must up-fill this osier cage of ours\n",
      "With baleful weeds \tfspp\tufo\t\n",
      "\n",
      "iter:11399/20000 loss:1.6751405888795852\n",
      "generated sequence: od! convey? conveyers are you all,\n",
      "That rise thus nimbly by a true king's fall.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "ufs\tf\t\tesday next we solemnls\t\n",
      "\n",
      "iter:11599/20000 loss:1.6797340363264084\n",
      "generated sequence: se their heads?\n",
      "\n",
      "KING RICHARD III:\n",
      "No, to the dignity and height of honour\n",
      "The high imperial type of this earth's glory.\n",
      "\n",
      "QUEEN fsu\tfso\tuf\n",
      "\n",
      "iter:11799/20000 loss:1.6764902466535567\n",
      "generated sequence: e white o' the eye to his discourse. But\n",
      "the bottom of the news is that our general is cut i'\n",
      "the middle and but one half of whasu\tfoisus\n",
      "\n",
      "iter:11999/20000 loss:1.658205779194832\n",
      "generated sequence:  be courtesy, sir, accept of it.\n",
      "\n",
      "Pedant:\n",
      "O sir, I do; and will repute you ever\n",
      "The patron of my life and liberty.\n",
      "\n",
      "TRANIO:\n",
      "Thenub\tup\tu\ti\t\n",
      "\n",
      "iter:12199/20000 loss:1.6920206093788146\n",
      "generated sequence: crown at home.\n",
      "For what hath broach'd this tumult but thy pride?\n",
      "Hadst thou been meek, our title still had slept;\n",
      "And we, in piti\tvppuoiuf\n",
      "\n",
      "iter:12399/20000 loss:1.6579963141679763\n",
      "generated sequence: and ne'er be satisfied!\n",
      "\n",
      "KING HENRY VI:\n",
      "How will the country for these woful chances\n",
      "Misthink the king and not be satisfied!\n",
      "\n",
      "Soup\tup\tt\tpu\n",
      "\n",
      "iter:12599/20000 loss:1.684815186858177\n",
      "generated sequence: ink, and be the seas on him!\n",
      "White-liver'd runagate, what doth he there?\n",
      "\n",
      "STANLEY:\n",
      "I know not, mighty sovereign, but by guess.\n",
      "\n",
      "o\t\t\tuu\t\tuv\n",
      "\n",
      "iter:12799/20000 loss:1.6494762897491455\n",
      "generated sequence: his power:\n",
      "I will lead forth my soldiers to the plain,\n",
      "And thus my battle shall be ordered:\n",
      "My foreward shall be drawn out all ifo\tuf\tf\t\t\n",
      "\n",
      "iter:12999/20000 loss:1.6707486325502396\n",
      "generated sequence: NGHAM:\n",
      "No, so God help me, they spake not a word;\n",
      "But, like dumb statues or breathing stones,\n",
      "UJu\td each on other, and look'd deJBB\tB\n",
      "\n",
      "iter:13199/20000 loss:1.6021066731214524\n",
      "generated sequence: ing\n",
      "Counsel o' the war, but at his nurse's tears\n",
      "He whined and roar'd away your victory,\n",
      "Jvoef\tages blush'd at him and men of heoei\n",
      "\n",
      "iter:13399/20000 loss:1.6436269468069076\n",
      "generated sequence: gh'st degree\n",
      "Murder, stem murder, in the direst degree;\n",
      "All several sins, all used in each degree,\n",
      "Throng to the bar, crying allfbf\t\tu\tsf\t\n",
      "\n",
      "iter:13599/20000 loss:1.6764430671930313\n",
      "generated sequence: ory base and sovereignty a slave,\n",
      "Proud majesty a subject, state a peasant.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "My lord,--\n",
      "\n",
      "KING RICHARD II:\n",
      "No lorve\tufo\teuo\n",
      "\n",
      "iter:13799/20000 loss:1.6538749897480012\n",
      "generated sequence: \n",
      "\n",
      "RICHARD:\n",
      "Ah, Warwick, why hast thou withdrawn thyself?\n",
      "Thy brother's blood the thirsty earth hath drunk,\n",
      "Broach'd with the steBB\t\tFfo\t\t\n",
      "\n",
      "iter:13999/20000 loss:1.6379578286409378\n",
      "generated sequence: her, by some chance,\n",
      "Some trick not worth an egg, shall grow dear friends\n",
      "And interjoin their issues. So with me:\n",
      "My birth-placef\tf\tuf\tuiv\n",
      "\n",
      "iter:14199/20000 loss:1.6335665136575699\n",
      "generated sequence:  night, let's harbour here in York;\n",
      "And when the morning sun shall raise his car\n",
      "Above the border of this horizon,\n",
      "We'll forwarduet\tf\t\tu\t\t\n",
      "\n",
      "iter:14399/20000 loss:1.658015449643135\n",
      "generated sequence: on,\n",
      "using painting, do prove my occupation a mystery:\n",
      "but what mystery there should be in hanging, if I\n",
      "should be hanged, I cannve\tJ\t\tue\tu\n",
      "\n",
      "iter:14599/20000 loss:1.6502222043275834\n",
      "generated sequence:  with her breath she did perfume the air:\n",
      "Sacred and sweet was all I saw in her.\n",
      "\n",
      "TRANIO:\n",
      "Nay, then, 'tis time to stir him from ujo\tfuf\tfu\n",
      "\n",
      "iter:14799/20000 loss:1.6420580804347993\n",
      "generated sequence: ll arraign your conscience,\n",
      "And try your penitence, if it be sound,\n",
      "Or hollowly put on.\n",
      "\n",
      "JULIET:\n",
      "I'll gladly learn.\n",
      "\n",
      "DUKE VINCEN\t\tulfflo\t\t\n",
      "\n",
      "iter:14999/20000 loss:1.6516206419467927\n",
      "generated sequence: \n",
      "True, I talk of dreams,\n",
      "Which are the children of an idle brain,\n",
      "Begot of nothing but vain fantasy,\n",
      "Which is as thin of substanBi\tm\t\tu\tui\n",
      "\n",
      "iter:15199/20000 loss:1.606260170340538\n",
      "generated sequence: To my inheritance of free descent.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "The noble duke hath been too much abused.\n",
      "\n",
      "LORD ROSS:\n",
      "It stands your grace uieub\tutef\t\n",
      "\n",
      "iter:15399/20000 loss:1.6197740083932877\n",
      "generated sequence: s,\n",
      "Unpeopled offices, untrodden stones?\n",
      "And what hear there for welcome but my groans?\n",
      "Therefore commend me; let him not come th\t\tXDe\t\tv\t\t\n",
      "\n",
      "iter:15599/20000 loss:1.624552947282791\n",
      "generated sequence: this widow's wit.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "KING EDWARD IV:\n",
      "Now tell me, madam, do you love your children?\n",
      "\n",
      "LADY GREY:\n",
      "Ay, full as dearly asifuuufu\tvf\n",
      "\n",
      "iter:15799/20000 loss:1.5991813498735428\n",
      "generated sequence: s hat,\n",
      "And Walter's dagger was not come from sheathing:\n",
      "There were none fine but Adam, Ralph, and Gregory;\n",
      "The rest were ragged,\tufui\tT\t\t\t\n",
      "\n",
      "iter:15999/20000 loss:1.6150827503204346\n",
      "generated sequence: deliver'd\n",
      "Of great Apollo's priest; and that, since then,\n",
      "You have not dared to break the holy seal\n",
      "Nor read the secrets in't.\n",
      "\n",
      "\t\t\tef\t\t\t\tT\n",
      "\n",
      "iter:16199/20000 loss:1.6226950085163117\n",
      "generated sequence: e and leap,\n",
      "The one in fear to lose what they enjoy,\n",
      "The other to enjoy by rage and war:\n",
      "These signs forerun the death or fall o\tuuf\tup\tub\n",
      "\n",
      "iter:16399/20000 loss:1.581671501994133\n",
      "generated sequence: ed.\n",
      "\n",
      "JULIET:\n",
      "Farewell! God knows when we shall meet again.\n",
      "I have a faint cold fear thrills through my veins,\n",
      "TTVDFVTmost freeze\t\t\n",
      "\n",
      "iter:16599/20000 loss:1.597822772860527\n",
      "generated sequence: lance of the mother, the affection\n",
      "of nobleness which nature shows above her breeding,\n",
      "and many other evidences proclaim her wit\tuhi\tu\tfu\t\n",
      "\n",
      "iter:16799/20000 loss:1.6223553001880646\n",
      "generated sequence: h what he would say, let him feel your sword,\n",
      "Which we will second. When he lies along,\n",
      "After your way his tale pronounced shallfuifuiuf\tu\n",
      "\n",
      "iter:16999/20000 loss:1.6246120983362198\n",
      "generated sequence: e by fortune of my birth,\n",
      "Near to the king in blood, and near in love\n",
      "Till you did make him misinterpret me,\n",
      "Have stoop'd my nec\tuz\tufvfit\n",
      "\n",
      "iter:17199/20000 loss:1.6315866756439208\n",
      "generated sequence:  betwixt them then such an affection,\n",
      "which cannot choose but branch now. Since their\n",
      "more mature dignities and royal necessitieum\t\tiof\tu\t\n",
      "\n",
      "iter:17399/20000 loss:1.5838931626081467\n",
      "generated sequence: th my brother's.\n",
      "What, are there no posts dispatch'd for Ireland?\n",
      "How shall we do for money for these wars?\n",
      "Come, sister,--cousi\tfuf\tuffv\t\n",
      "\n",
      "iter:17599/20000 loss:1.592950314283371\n",
      "generated sequence: Only for bearing burdens, and sore blows\n",
      "For sinking under them.\n",
      "\n",
      "SICINIUS:\n",
      "This, as you say, suggested\n",
      "At some time when his so;\tf\tufvfuf\n",
      "\n",
      "iter:17799/20000 loss:1.6099944978952407\n",
      "generated sequence: sequence yet hanging in the stars\n",
      "Shall bitterly begin his fearful date\n",
      "With this night's revels and expire the term\n",
      "Of a despis\t\tvf\tei\tu\t\n",
      "\n",
      "iter:17999/20000 loss:1.6023111236095429\n",
      "generated sequence:  have heard, sir, of such a man, who hath a\n",
      "daughter of most rare note: the report of her is\n",
      "extended more than can be thought tufsf\tuf\tst\n",
      "\n",
      "iter:18199/20000 loss:1.597190074324608\n",
      "generated sequence:  I am no mourner for that news,\n",
      "Because they have been still mine enemies:\n",
      "But, that I'll give my voice on Richard's side,\n",
      "To bauOusfu\tuuf\n",
      "\n",
      "iter:18399/20000 loss:1.590915217399597\n",
      "generated sequence: r father.\n",
      "\n",
      "PERDITA:\n",
      "Happy be you!\n",
      "All that you speak shows fair.\n",
      "\n",
      "CAMILLO:\n",
      "Who have we here?\n",
      "We'll make an instrument of this, o\tupoif\t\t\n",
      "\n",
      "iter:18599/20000 loss:1.602657191157341\n",
      "generated sequence: n's\n",
      "persuasion.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "But hear you.\n",
      "\n",
      "BARNARDINE:\n",
      "Not a word: if you have any thing to say to me,\n",
      "come to my ward; foret\tUf\t\t\t\ts\n",
      "\n",
      "iter:18799/20000 loss:1.5985190325975418\n",
      "generated sequence: lved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to thefft\tufoift\n",
      "\n",
      "iter:18999/20000 loss:1.617973176240921\n",
      "generated sequence: n the\n",
      "rest, as I said, and, as I say, paying for them very\n",
      "honestly; for, as you know, Master Froth, I could\n",
      "not give you three-uuif\tN\t\tui\n",
      "\n",
      "iter:19199/20000 loss:1.609840714931488\n",
      "generated sequence: yields must be embraced,\n",
      "And not neglected; else, if heaven would,\n",
      "And we will not, heaven's offer we refuse,\n",
      "The proffer'd mean\tu\t\t\tuuf\tu\n",
      "\n",
      "iter:19399/20000 loss:1.5993650111556053\n",
      "generated sequence: I will not vex your souls--\n",
      "Since presently your souls must part your bodies--\n",
      "With too much urging your pernicious lives,\n",
      "For ';ufu\t\tupv\t\n",
      "\n",
      "iter:19599/20000 loss:1.5910881954431533\n",
      "generated sequence:  greater a run\n",
      "but my head and my neck. A fire good Curtis.\n",
      "\n",
      "CURTIS:\n",
      "Is my master and his wife coming, Grumio?\n",
      "\n",
      "GRUMIO:\n",
      "O, ay, Cus\t\tsi\t\tus\n",
      "\n",
      "iter:19799/20000 loss:1.6156424409151078\n",
      "generated sequence:  urging me to fury: O, be gone!\n",
      "By heaven, I love thee better than myself;\n",
      "For I come hither arm'd against myself:\n",
      "Stay not, be usfiofiuf\t\n",
      "\n",
      "iter:19999/20000 loss:1.588225767314434\n",
      "generated sequence: then how quickly should this arm of mine.\n",
      "Now prisoner to the palsy, chastise thee\n",
      "And minister correction to thy fault!\n",
      "\n",
      "HENRY ifs\tuf\tfuv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.ASGD(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,target,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asures seized, our soldiers put to flight,\\nAnd, as thou seest, ourselves in heavy plight.\\n\\nKING LEWIS XI:\\nRenowned queen, with po\\tsfs\\tu\\tsozs\\t\\tu\\tsfu\\t\\tf\\tosf\\tufsiui\\tuffo\\tfi\\tUO\\t\\t\\tuo\\tuif\\tsu\\tss\\ti\\tu\\tsf\\tsffs\\tuo\\tufsof\\tuffo\\tfi\\rUUjJDTupOiJuuUJ\\rUJs\\t\\tf\\ts\\tuvsss\\t\\tufoifuf\\tufsfuiuf\\t\\tfuuiufsiuusu\\tfsuisffifuiss\\tusfuiDuuui\\tuifsufiuffufuiufsufssfui\\tuisf\\tsuiss\\tusfUiioJBui\\tDfJiiiJUiJfuusufuisfffuuis\\tfsisuisfsifisuusiifisffiifiusfiffssfsifffuifsifBiiifuifsfisfissisifisfisffsifuiffsufifffuifsiff\\tJOifuBsJfffJifJsiifisiffsssiiffusfffiffsffsffiifffsffssffsfifsfssffsffsssifsffsOfffsifsfsffsffffffsffsffssffsifssfisfsssifsffssuJDfsiOfJsssJfsJfffsfffssfffffssifsssfssfssfssffsssfssffssfsfsfsffssfssffffsfssfDsssffsfsfssfssssssfssfssffssffsffsffsffffsfs'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In attempting to printing the output of the current model, the main change was for the model to pass in the input twice,since the target gave away the answers. This prevented the model from generalizing to other input and thus had bad behavior in printing words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
