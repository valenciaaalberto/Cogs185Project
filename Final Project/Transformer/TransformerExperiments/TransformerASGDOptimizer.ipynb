{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r\n",
      "\u000b\n",
      "\f\n",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='Wha', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:4.176154737472534\n",
      "generated sequence: ' minds:\n",
      "'Tybalt is dead, and Romeo--banished;'\n",
      "That 'banished,' that one word 'banished,'\n",
      "Hath slain ten thousand Tybalts. Tyba\tf\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:399/20000 loss:3.6381276834011076\n",
      "generated sequence: o grieve\n",
      "At knowing of thy choice.\n",
      "\n",
      "FLORIZEL:\n",
      "Come, come, he must not.\n",
      "Mark our contract.\n",
      "\n",
      "POLIXENES:\n",
      "Mark your divorce, young s\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:599/20000 loss:3.4876121783256533\n",
      "generated sequence: t a little way above our heads,\n",
      "Staying for thine to keep him company:\n",
      "Either thou, or I, or both, must go with him.\n",
      "\n",
      "TYBALT:\n",
      "Th\tf\tf\t\t\t\t\t\t\n",
      "\n",
      "iter:799/20000 loss:3.419471619129181\n",
      "generated sequence: lo?\n",
      "\n",
      "BIONDELLO:\n",
      "I cannot tarry: I knew a wench married in an\n",
      "afternoon as she went to the garden for parsley to\n",
      "stuff a rabbit; \t\t\t\t\t\t\t\t\tf\n",
      "\n",
      "iter:999/20000 loss:3.3683382260799406\n",
      "generated sequence: the matter?\n",
      "\n",
      "DUKE OF YORK:\n",
      "Peace, foolish woman.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "I will not peace. What is the matter, Aumerle.\n",
      "\n",
      "DUKE OF AUMER\t\t\tu\t\t\t\t\t\t\n",
      "\n",
      "iter:1199/20000 loss:3.336646330356598\n",
      "generated sequence: d to one that is so ill!\n",
      "In sadness, cousin, I do love a woman.\n",
      "\n",
      "BENVOLIO:\n",
      "I aim'd so near, when I supposed you loved.\n",
      "\n",
      "ROMEO:\n",
      "A\tu\t\tu\t\t\tu\t\n",
      "\n",
      "iter:1399/20000 loss:3.264236551523209\n",
      "generated sequence: OUCESTER:\n",
      "Come, cousin, canst thou quake, and change thy colour,\n",
      "Murder thy breath in the middle of a word,\n",
      "And then begin againu\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:1599/20000 loss:3.243054735660553\n",
      "generated sequence: t me to the queen.\n",
      "\n",
      "Gaoler:\n",
      "I may not, madam:\n",
      "To the contrary I have express commandment.\n",
      "\n",
      "PAULINA:\n",
      "Here's ado,\n",
      "To lock up hones\tu\t\tu\t\tu\t\t\n",
      "\n",
      "iter:1799/20000 loss:3.2004876375198363\n",
      "generated sequence: Y:\n",
      "And that is more than I will yield unto:\n",
      "I know I am too mean to be your queen,\n",
      "And yet too good to be your concubine.\n",
      "\n",
      "KING \t\t\t\t\t\tu\tf\t\n",
      "\n",
      "iter:1999/20000 loss:3.183159132003784\n",
      "generated sequence: .\n",
      "\n",
      "LEONTES:\n",
      "Force her hence.\n",
      "\n",
      "PAULINA:\n",
      "Let him that makes but trifles of his eyes\n",
      "First hand me: on mine own accord I'll off;\n",
      "Bu\t\t\t\t\tu\t\t\t\t\n",
      "\n",
      "iter:2199/20000 loss:3.1288955557346343\n",
      "generated sequence: ewell of our several friends.\n",
      "\n",
      "Lord Marshal:\n",
      "The appellant in all duty greets your highness,\n",
      "And craves to kiss your hand and ta\tf\t\t\tu\t\tu\t\n",
      "\n",
      "iter:2399/20000 loss:3.115978707075119\n",
      "generated sequence: , my good lord.\n",
      "\n",
      "KING RICHARD II:\n",
      "Then I must not say no.\n",
      "\n",
      "QUEEN:\n",
      "What sport shall we devise here in this garden,\n",
      "To drive away \tuf\tu\t\t\t\tu\n",
      "\n",
      "iter:2599/20000 loss:3.1203760385513304\n",
      "generated sequence: itted fool,\n",
      "Presuming on an ague's privilege,\n",
      "Darest with thy frozen admonition\n",
      "Make pale our cheek, chasing the royal blood\n",
      "Wito\t\t\t\tu\t\t\t\t\n",
      "\n",
      "iter:2799/20000 loss:3.073973380327225\n",
      "generated sequence: ou have no cause.\n",
      "\n",
      "ARCHBISHOP OF YORK:\n",
      "My gracious lady, go;\n",
      "And thither bear your treasure and your goods.\n",
      "For my part, I'll re\t\tufo\t\tu\t\t\n",
      "\n",
      "iter:2999/20000 loss:3.046903986930847\n",
      "generated sequence: night.\n",
      "\n",
      "MERCUTIO:\n",
      "And so did I.\n",
      "\n",
      "ROMEO:\n",
      "Well, what was yours?\n",
      "\n",
      "MERCUTIO:\n",
      "That dreamers often lie.\n",
      "\n",
      "ROMEO:\n",
      "In bed asleep, while t\to\tf\t\t\t\tf\t\n",
      "\n",
      "iter:3199/20000 loss:3.0415371930599213\n",
      "generated sequence:  very heart.\n",
      "\n",
      "FLORIZEL:\n",
      "I am bound to you:\n",
      "There is some sap in this.\n",
      "\n",
      "CAMILLO:\n",
      "A cause more promising\n",
      "Than a wild dedication ofu\t\t\t\tuf\to\t\n",
      "\n",
      "iter:3399/20000 loss:3.0028118693828585\n",
      "generated sequence:  in my soul, and would not let it forth\n",
      "To seek the empty, vast and wandering air;\n",
      "But smother'd it within my panting bulk,\n",
      "Whicuo\tuf\tu\ts\t\n",
      "\n",
      "iter:3599/20000 loss:3.0056833207607268\n",
      "generated sequence: tand cavilling thus.\n",
      "\n",
      "RICHARD:\n",
      "Sound drums and trumpets, and the king will fly.\n",
      "\n",
      "YORK:\n",
      "Sons, peace!\n",
      "\n",
      "KING HENRY VI:\n",
      "Peace, thou!\to\t\tu\to\to\t\n",
      "\n",
      "iter:3799/20000 loss:2.9649926900863646\n",
      "generated sequence: behind.\n",
      "\n",
      "First Citizen:\n",
      "Neighbour, well met: whither away so fast?\n",
      "\n",
      "Second Citizen:\n",
      "I promise you, I scarcely know myself:\n",
      "fear f\tfo\t\t\t\n",
      "\n",
      "iter:3999/20000 loss:2.969595367908478\n",
      "generated sequence: very drop of water swear against it\n",
      "And gape at widest to glut him.\n",
      "\n",
      "ANTONIO:\n",
      "Let's all sink with the king.\n",
      "\n",
      "SEBASTIAN:\n",
      "Let's taf\t\t\tu\t\ts\tu\n",
      "\n",
      "iter:4199/20000 loss:2.9305334961414338\n",
      "generated sequence:  face,\n",
      "She was the fairest creature in the world;\n",
      "And yet she is inferior to none.\n",
      "\n",
      "SLY:\n",
      "Am I a lord? and have I such a lady?\n",
      "ff\t\tof\t\t\n",
      "\n",
      "iter:4399/20000 loss:2.949903280735016\n",
      "generated sequence: d\n",
      "there rooted betwixt them then such an affection,\n",
      "which cannot choose but branch now. Since their\n",
      "\tf\t\t\tu\tsure dignities and ro\t\n",
      "\n",
      "iter:4599/20000 loss:2.912987300157547\n",
      "generated sequence: am!\n",
      "Ay, let the county take you in your bed;\n",
      "He'll fright you up, i' faith. Will it not be?\n",
      "\t\t\tu\t\tdress'd! and in your clothes! of\n",
      "\n",
      "iter:4799/20000 loss:2.879764643907547\n",
      "generated sequence: th to defend my loyalty and truth\n",
      "To God, my king and my succeeding issue,\n",
      "Against the Duke of Hereford that appeals me\n",
      "And, by \tfu\tsu\t\t\t\t\n",
      "\n",
      "iter:4999/20000 loss:2.8852051663398743\n",
      "generated sequence: g queen.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Call forth Bagot.\n",
      "Now, Bagot, freely speak thy mind;\n",
      "What thou dost know of noble Gloucester's deat\tufs\t\t\t\n",
      "\n",
      "iter:5199/20000 loss:2.8572918379306795\n",
      "generated sequence: reathes in,\n",
      "And there die strangled ere my Romeo comes?\n",
      "Or, if I live, is it not very like,\n",
      "The horrible conceit of death and ni\t\to\tf\t\tuo\t\n",
      "\n",
      "iter:5399/20000 loss:2.872182089090347\n",
      "generated sequence: cause why music was ordain'd!\n",
      "Was it not to refresh the mind of man\n",
      "After his studies or his usual pain?\n",
      "Then give me leave to rfos\t\tuff\tu\n",
      "\n",
      "iter:5599/20000 loss:2.8396042466163633\n",
      "generated sequence: imself penitently in prison? how\n",
      "seems he to be touched?\n",
      "\n",
      "Provost:\n",
      "A man that apprehends death no more dreadfully but\n",
      "as a drunkof\t\t\t\tu\t\t\t\n",
      "\n",
      "iter:5799/20000 loss:2.8364171516895293\n",
      "generated sequence: ffices, untrodden stones?\n",
      "And what hear there for welcome but my groans?\n",
      "Therefore commend me; let him not come there,\n",
      "To seek o\t\tof\t\t\tu\t\t\n",
      "\n",
      "iter:5999/20000 loss:2.833576177358627\n",
      "generated sequence: e in splendor of mine own.\n",
      "\n",
      "LADY CAPULET:\n",
      "Nurse, where's my daughter? call her forth to me.\n",
      "\n",
      "Nurse:\n",
      "Now, by my maidenhead, at tw\tuo\tu\t\t\t\t\t\n",
      "\n",
      "iter:6199/20000 loss:2.8158712232112886\n",
      "generated sequence: consent to my sharp appetite;\n",
      "Lay by all nicety and prolixious blushes,\n",
      "That banish what they sue for; redeem thy brother\n",
      "By yiefs\t\t\t\t\tu\ts\n",
      "\n",
      "iter:6399/20000 loss:2.810277841091156\n",
      "generated sequence: e well assured\n",
      "Her faction will be full as strong as ours.\n",
      "\n",
      "KING EDWARD IV:\n",
      "We are advertised by our loving friends\n",
      "That they do\tuf\t\t\tuo\t\t\n",
      "\n",
      "iter:6599/20000 loss:2.7978334999084473\n",
      "generated sequence:  ho, Barnardine!\n",
      "\n",
      "BARNARDINE:\n",
      "\n",
      "POMPEY:\n",
      "Your friends, sir; the hangman. You must be so\n",
      "good, sir, to rise and be put to death.\n",
      "\n",
      "Buf\t\tu\to\t\to\n",
      "\n",
      "iter:6799/20000 loss:2.771701283454895\n",
      "generated sequence: care not.\n",
      "\n",
      "TYBALT:\n",
      "Follow me close, for I will speak to them.\n",
      "Gentlemen, good den: a word with one of you.\n",
      "\n",
      "MERCUTIO:\n",
      "Und but onfo\t\tu\t\t\t\n",
      "\n",
      "iter:6999/20000 loss:2.7965018486976625\n",
      "generated sequence: !\n",
      "\n",
      "KING RICHARD III:\n",
      "Good news or bad, that thou comest in so bluntly?\n",
      "\n",
      "CATESBY:\n",
      "Bad news, my lord: Ely is fled to Richmond;\n",
      "\tuJ\t\n",
      "\n",
      "iter:7199/20000 loss:2.756050612926483\n",
      "generated sequence:  know\n",
      "The royal fool thou copest with,--\n",
      "\n",
      "Shepherd:\n",
      "O, my heart!\n",
      "\n",
      "POLIXENES:\n",
      "I'll have thy beauty scratch'd with briers, and maduf\tsfUif\tu\n",
      "\n",
      "iter:7399/20000 loss:2.7472826933860777\n",
      "generated sequence: y:\n",
      "Once more, good night, kind lords and gentlemen.\n",
      "O Thou, whose captain I account myself,\n",
      "Uu\tf\tuf\tmy forces with a gracious ey\t\n",
      "\n",
      "iter:7599/20000 loss:2.7469909310340883\n",
      "generated sequence:  kin,\n",
      "And egally indeed to all estates,--\n",
      "Yet whether you accept our suit or no,\n",
      "Your brother's son shall never reign our king;\n",
      "ufo\t\tUo\t\tu\n",
      "\n",
      "iter:7799/20000 loss:2.74859748005867\n",
      "generated sequence: ad aches! what a head have I!\n",
      "It beats as it would fall in twenty pieces.\n",
      "My back o' t' other side,--O, my back, my back!\n",
      "ueshreo\tuoff\t\t\n",
      "\n",
      "iter:7999/20000 loss:2.729603576660156\n",
      "generated sequence: DWARD IV:\n",
      "I pray thee, peace: my soul is full of sorrow.\n",
      "\n",
      "DORSET:\n",
      "I will not rise, unless your highness grant.\n",
      "\n",
      "KING EDWARD IV:\n",
      "UfoJfu\tf\n",
      "\n",
      "iter:8199/20000 loss:2.7634219658374786\n",
      "generated sequence: en from me, and these detestable things put upon\n",
      "me.\n",
      "\n",
      "Clown:\n",
      "What, by a horseman, or a footman?\n",
      "\n",
      "AUTOLYCUS:\n",
      "A footman, sweet sir\t\tu\t\t\tfuf\t\n",
      "\n",
      "iter:8399/20000 loss:2.727446494102478\n",
      "generated sequence:  what: but he\n",
      "at that time, overfond of the shepherd's daughter,\n",
      "so he then took her to be, who began to be much\n",
      "uf\t\tsick, and huffo\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:2.6941491961479187\n",
      "generated sequence:  then let them\n",
      "If I say fine, cry 'Fine;' if death, cry 'Death.'\n",
      "Insisting on the old prerogative\n",
      "And power i' the truth o' the u\tf\t\tu\t\t\tu\n",
      "\n",
      "iter:8799/20000 loss:2.7015163993835447\n",
      "generated sequence: our leave,\n",
      "How doth the prince, and my young son of York?\n",
      "\n",
      "BRAKENBURY:\n",
      "Right well, dear madam. By your patience,\n",
      "I may not suffe\ts\tu\t\tof\t\t\n",
      "\n",
      "iter:8999/20000 loss:2.694933910369873\n",
      "generated sequence: ageant;\n",
      "One heaved a-high, to be hurl'd down below;\n",
      "A mother only mock'd with two sweet babes;\n",
      "A dream of what thou wert, a breao\t\to\t\t\tUu\t\n",
      "\n",
      "iter:9199/20000 loss:2.718677501678467\n",
      "generated sequence: nd eaten him too.\n",
      "\n",
      "First Servingman:\n",
      "But, more of thy news?\n",
      "\n",
      "Third Servingman:\n",
      "Why, he is so made on here within, as if he were \t\tu\to\t\t\tuf\n",
      "\n",
      "iter:9399/20000 loss:2.7232979273796083\n",
      "generated sequence: u know\n",
      "My daughter Katharina is to be married:\n",
      "Now, on the Sunday following, shall Bianca\n",
      "Be bride to you, if you this assurance\tuf\t\tfUf\tu\n",
      "\n",
      "iter:9599/20000 loss:2.6889972269535063\n",
      "generated sequence: sces have much corn; take these rats thither\n",
      "To gnaw their garners. Worshipful mutiners,\n",
      "Your valour puts well forth: pray, foll\tf\t\tufof\tu\n",
      "\n",
      "iter:9799/20000 loss:2.6769809234142303\n",
      "generated sequence: ou have deserved nobly of your country, and you\n",
      "have not deserved nobly.\n",
      "\n",
      "CORIOLANUS:\n",
      "Your enigma?\n",
      "\n",
      "Fourth Citizen:\n",
      "You have bee\tsufof\tu\t\t\n",
      "\n",
      "iter:9999/20000 loss:2.6955677247047425\n",
      "generated sequence: RENCE:\n",
      "His majesty\n",
      "Tendering my person's safety, hath appointed\n",
      "This conduct to convey me to the Tower.\n",
      "\n",
      "GLOUCESTER:\n",
      "Ufo\t what cJ\t\n",
      "\n",
      "iter:10199/20000 loss:2.6766426408290864\n",
      "generated sequence: rsity.\n",
      "\n",
      "TRANIO:\n",
      "How now! what's the matter?\n",
      "\n",
      "BAPTISTA:\n",
      "What, is the man lunatic?\n",
      "\n",
      "TRANIO:\n",
      "UUiJ you seem a sober ancient gentlema\t\to\t\t\n",
      "\n",
      "iter:10399/20000 loss:2.693713595867157\n",
      "generated sequence: e vulgar eye, that he bears all things fairly.\n",
      "And shows good husbandry for the Volscian state,\n",
      "Fights dragon-like, and does ach\tufs\t\to\tu\t\n",
      "\n",
      "iter:10599/20000 loss:2.6653895139694215\n",
      "generated sequence: The law hath not been dead, though it hath slept:\n",
      "Those many had not dared to do that evil,\n",
      "If the first that did the edict infrif\tu\tofufo\n",
      "\n",
      "iter:10799/20000 loss:2.6479395043849947\n",
      "generated sequence: n out themselves;\n",
      "Small showers last long, but sudden storms are short;\n",
      "He tires betimes that spurs too fast betimes;\n",
      "With eager\tu\ts\tu\tf\tf\n",
      "\n",
      "iter:10999/20000 loss:2.6709215259552\n",
      "generated sequence: VALERIA:\n",
      "In troth, there's wondrous things spoke of him.\n",
      "\n",
      "MENENIUS:\n",
      "Wondrous! ay, I warrant you, and not without his\n",
      "U\tue purcha;o\t\tJ\to\n",
      "\n",
      "iter:11199/20000 loss:2.668512434959412\n",
      "generated sequence: ies. This is some changeling:\n",
      "open't. What's within, boy?\n",
      "\n",
      "Clown:\n",
      "You're a made old man: if the sins of your youth\n",
      "uifo\turgiven o\t\t\n",
      "\n",
      "iter:11399/20000 loss:2.654324518442154\n",
      "generated sequence: the constable's own word:\n",
      "If thou art dun, we'll draw thee from the mire\n",
      "Of this sir-reverence love, wherein thou stick'st\n",
      "Up to\tf\tuf\t\t\t\to\n",
      "\n",
      "iter:11599/20000 loss:2.678202118873596\n",
      "generated sequence: tracted manner. His actions\n",
      "show much like to madness: pray heaven his wisdom be\n",
      "not tainted! And why meet him at the gates, and\t\tof\t\t\tufo\n",
      "\n",
      "iter:11799/20000 loss:2.632961090803146\n",
      "generated sequence: non\n",
      "Drums in his ear, at which he starts and wakes,\n",
      "And being thus frighted swears a prayer or two\n",
      "And sleeps again. This is tha\t\t\tU\t\tsf\tu\n",
      "\n",
      "iter:11999/20000 loss:2.6510820734500884\n",
      "generated sequence:  and swoon for what's to come upon thee.\n",
      "The glorious gods sit in hourly synod about thy\n",
      "particular prosperity, and love thee nouo\t\tu\tf\t\t\t\n",
      "\n",
      "iter:12199/20000 loss:2.630657345056534\n",
      "generated sequence: Sirrah, no more!\n",
      "\n",
      "LUCIO:\n",
      "Enough, my lord.\n",
      "\n",
      "ANGELO:\n",
      "My lord, I must confess I know this woman:\n",
      "And five years since there was som;o\t\tof\tu\t\t\n",
      "\n",
      "iter:12399/20000 loss:2.634587572813034\n",
      "generated sequence: hroats are\n",
      "sentenced and stay upon execution.\n",
      "\n",
      "SICINIUS:\n",
      "Is't possible that so short a time can alter the\n",
      "condition of a man!\n",
      "\n",
      "Mf\t\to\t\tuo\t\t\n",
      "\n",
      "iter:12599/20000 loss:2.638404458761215\n",
      "generated sequence: wrong:\n",
      "His name is Licio, born in Mantua.\n",
      "\n",
      "BAPTISTA:\n",
      "You're welcome, sir; and he, for your good sake.\n",
      "Ufo\tfor my daughter Katharf\t\t\t\t\n",
      "\n",
      "iter:12799/20000 loss:2.6340522527694703\n",
      "generated sequence: shall anon over-read it at your pleasure; where you\n",
      "shall find, within these two days he will be here.\n",
      "This is a thing that Ange\tfo\t\tuo\t\t\t\n",
      "\n",
      "iter:12999/20000 loss:2.6299096870422365\n",
      "generated sequence: Beseech you, tenderly apply to her\n",
      "Some remedies for life.\n",
      "Apollo, pardon\n",
      "My great profaneness 'gainst thine oracle!\n",
      "I'll reconc;\t\t\t\tffu\t\t\n",
      "\n",
      "iter:13199/20000 loss:2.629072493314743\n",
      "generated sequence: ake us say\n",
      "'This is put forth too truly:' besides, I have stay'd\n",
      "To tire your royalty.\n",
      "\n",
      "LEONTES:\n",
      "We are tougher, brother,\n",
      "Than yof\tus\tu\to\t\n",
      "\n",
      "iter:13399/20000 loss:2.6341462445259096\n",
      "generated sequence: that have been more kindly beholding to you than\n",
      "any, freely give unto you this young scholar,\n",
      "that hath been long studying at R\tfo\tufof\tu\n",
      "\n",
      "iter:13599/20000 loss:2.6234449195861815\n",
      "generated sequence: th\n",
      "here, sir; a man of four-score pound a year; whose\n",
      "father died at Hallowmas: was't not at Hallowmas,\n",
      "Master Froth?\n",
      "\n",
      "FROTH:\n",
      "Al\tfUf\t\t\t\tu\t\n",
      "\n",
      "iter:13799/20000 loss:2.6137679839134216\n",
      "generated sequence: astely. Therefore, go back.\n",
      "\n",
      "MENENIUS:\n",
      "Prithee, fellow, remember my name is Menenius,\n",
      "uifays factionary on the party of your geno\t\t\t\t\t\n",
      "\n",
      "iter:13999/20000 loss:2.6170262825489043\n",
      "generated sequence: BENVOLIO:\n",
      "Why dost thou stay?\n",
      "\n",
      "First Citizen:\n",
      "Which way ran he that kill'd Mercutio?\n",
      "Tybalt, that murderer, which way ran he?\n",
      "\n",
      "UFUJ;;\t\t;\n",
      "\n",
      "iter:14199/20000 loss:2.6134631645679476\n",
      "generated sequence: there be the victory!\n",
      "For Margaret my queen, and Clifford too,\n",
      "Have chid me from the battle; swearing both\n",
      "They prosper best of \tf\t\t\tuf\tu\t\n",
      "\n",
      "iter:14399/20000 loss:2.6166837358474733\n",
      "generated sequence: right,\n",
      "And Henry but usurps the diadem.\n",
      "\n",
      "MONTAGUE:\n",
      "Ay, now my sovereign speaketh like himself;\n",
      "And now will I be Edward's champi\to\tf\t\tUo\t\t\n",
      "\n",
      "iter:14599/20000 loss:2.6173671925067903\n",
      "generated sequence:  said, for\n",
      "prunes; and having but two in the dish, as I said,\n",
      "Master Froth here, this very man, having eaten the\n",
      "rest, as I saidu\too\t\tu\t\t\t\n",
      "\n",
      "iter:14799/20000 loss:2.602805179357529\n",
      "generated sequence:  not have cut him off. Some one hath set you on:\n",
      "Confess the truth, and say by whose advice\n",
      "Thou camest here to complain.\n",
      "\n",
      "ISABEu\t\t\tufof\tu\n",
      "\n",
      "iter:14999/20000 loss:2.5991085624694823\n",
      "generated sequence: ! for the fail\n",
      "Of any point in't shall not only be\n",
      "Death to thyself but to thy lewd-tongued wife,\n",
      "u\t\t\tu\t\t\tuthis time we pardon. \n",
      "\n",
      "iter:15199/20000 loss:2.595102175474167\n",
      "generated sequence: though they were flesh'd villains, bloody dogs,\n",
      "Melting with tenderness and kind compassion\n",
      "Wept like two children in their deat\tf\ts\tfu\tf\t\n",
      "\n",
      "iter:15399/20000 loss:2.594121081829071\n",
      "generated sequence: tands with me:\n",
      "Antonio, my father, is deceased;\n",
      "And I have thrust myself into this maze,\n",
      "Haply to wive and thrive as best I may:\to\t\t\tuio\tf\n",
      "\n",
      "iter:15599/20000 loss:2.594065581560135\n",
      "generated sequence: lance from him\n",
      "To the duke himself, to tax him with injustice?\n",
      "Take him hence; to the rack with him! We'll touse you\n",
      "Joint by jo\to\tf\tu\t\t\tf\n",
      "\n",
      "iter:15799/20000 loss:2.5984446990489958\n",
      "generated sequence:  say.\n",
      "I have bethought me of another fault.\n",
      "Provost, how came it Claudio was beheaded\n",
      "At an unusual hour?\n",
      "\n",
      "Provost:\n",
      "U\tufos commau\to\t\n",
      "\n",
      "iter:15999/20000 loss:2.6073221838474274\n",
      "generated sequence: .\n",
      "O Buckingham, take heed of yonder dog!\n",
      "Look, when he fawns, he bites; and when he bites,\n",
      "U;iF\tfft\t tooth will rankle to the de\n",
      "\n",
      "iter:16199/20000 loss:2.5952661848068237\n",
      "generated sequence: olingbroke is changed:\n",
      "You must to Pomfret, not unto the Tower.\n",
      "And, madam, there is order ta'en for you;\n",
      "With all swift speed y\t\tt\t\tf\t\tf\t\n",
      "\n",
      "iter:16399/20000 loss:2.5936630606651305\n",
      "generated sequence: tering\n",
      "Becomes not Rome, nor has Coriolanus\n",
      "Deserved this so dishonour'd rub, laid falsely\n",
      "I' the plain way of his merit.\n",
      "\n",
      "CORIOi\t\tt\t\tUF\tf\n",
      "\n",
      "iter:16599/20000 loss:2.5751767337322233\n",
      "generated sequence: r treasure and your goods.\n",
      "For my part, I'll resign unto your grace\n",
      "The seal I keep: and so betide to me\n",
      "As well I tender you an\tu\t\t\to\t\t\t\t\n",
      "\n",
      "iter:16799/20000 loss:2.5788197314739225\n",
      "generated sequence: er\n",
      "To some more fitter place, and that with speed.\n",
      "\n",
      "Servant:\n",
      "Here is the sister of the man condemn'd\n",
      "Desires access to you.\n",
      "\n",
      "ANG\tfUi\tu\t\tf\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:16999/20000 loss:2.5895487213134767\n",
      "generated sequence: or valiant ignorance,\n",
      "And perish constant fools. Who is't can blame him?\n",
      "Your enemies and his find something in him.\n",
      "\n",
      "MENENIUS:\n",
      "\t\tifo\too\t\t\n",
      "\n",
      "iter:17199/20000 loss:2.572739214897156\n",
      "generated sequence: shead. And then for the\n",
      "land-service, to see how the bear tore out his\n",
      "shoulder-bone; how he cried to me for help and said\n",
      "io\t\tn\tf\to\t\n",
      "\n",
      "iter:17399/20000 loss:2.5955886840820312\n",
      "generated sequence:  cannot judge: but to conclude with truth,\n",
      "Their weapons like to lightning came and went;\n",
      "Our soldiers', like the night-owl's laufo\t\t\t\tu\ts\n",
      "\n",
      "iter:17599/20000 loss:2.592369875907898\n",
      "generated sequence: O:\n",
      "I never heard the absent duke much detected for\n",
      "women; he was not inclined that way.\n",
      "\n",
      "LUCIO:\n",
      "O, sir, you are deceived.\n",
      "\n",
      "U\ti\t\tf\t\t\n",
      "\n",
      "iter:17799/20000 loss:2.5736716866493223\n",
      "generated sequence: st villanously; believe it.\n",
      "\n",
      "FRIAR PETER:\n",
      "Well, he in time may come to clear himself;\n",
      "But at this instant he is sick my lord,\n",
      "Of\t\tift\t\to\t\t\n",
      "\n",
      "iter:17999/20000 loss:2.5702104473114016\n",
      "generated sequence:  the earth my hell.\n",
      "A grievous burthen was thy birth to me;\n",
      "Tetchy and wayward was thy infancy;\n",
      "Thy school-days frightful, despeui\t\tu\to\ti\t\n",
      "\n",
      "iter:18199/20000 loss:2.5796779000759127\n",
      "generated sequence: RY VI:\n",
      "\n",
      "YORK:\n",
      "What then?\n",
      "\n",
      "KING HENRY VI:\n",
      "An if he may, then am I lawful king;\n",
      "For Richard, in the view of many lords,\n",
      "UU\t;gn'd tJ\ti;\t\n",
      "\n",
      "iter:18399/20000 loss:2.5771096658706667\n",
      "generated sequence: e crown, my curse;\n",
      "And in thy need such comfort come to thee\n",
      "As now I reap at thy too cruel hand!\n",
      "Hard-hearted Clifford, take me\tuf\t\ti\t\tuf\n",
      "\n",
      "iter:18599/20000 loss:2.56501956820488\n",
      "generated sequence: es me unpregnant\n",
      "And dull to all proceedings. A deflower'd maid!\n",
      "And by an eminent body that enforced\n",
      "The law against it! But th\t\tuf\tus\tf\t\n",
      "\n",
      "iter:18799/20000 loss:2.5722703671455385\n",
      "generated sequence:  the villany.\n",
      "\n",
      "GRUMIO:\n",
      "Error i' the bill, sir; error i' the bill.\n",
      "I commanded the sleeves should be cut out and\n",
      "sewed up again; ii\t\tift\t\to\n",
      "\n",
      "iter:18999/20000 loss:2.5602802884578706\n",
      "generated sequence:  not fierce and terrible\n",
      "Only in strokes; but, with thy grim looks and\n",
      "The thunder-like percussion of thy sounds,\n",
      "Thou madst thii\t\t\ti\tt\t\tf\n",
      "\n",
      "iter:19199/20000 loss:2.5707684922218323\n",
      "generated sequence: o hope in't: our throats are\n",
      "sentenced and stay upon execution.\n",
      "\n",
      "SICINIUS:\n",
      "Is't possible that so short a time can alter the\n",
      "cond\tu\t\tf\tuo\tt\n",
      "\n",
      "iter:19399/20000 loss:2.5639451813697813\n",
      "generated sequence: d him,\n",
      "For hand to hand he would have vanquish'd thee.\n",
      "Now my soul's palace is become a prison:\n",
      "Ah, would she break from hence, \ti\ttf\tUf\t\t\n",
      "\n",
      "iter:19599/20000 loss:2.568830199241638\n",
      "generated sequence: ll out with a tailor for wearing\n",
      "his new doublet before Easter? with another, for\n",
      "tying his new shoes with old riband? and yet t\t\ti\t\t\tiit\t\n",
      "\n",
      "iter:19799/20000 loss:2.5504566383361817\n",
      "generated sequence:  pluck but off these rags; and\n",
      "then, death, death!\n",
      "\n",
      "Clown:\n",
      "Alack, poor soul! thou hast need of more rags to lay\n",
      "on thee, rather if\t\tffif\t\t\n",
      "\n",
      "iter:19999/20000 loss:2.5643610632419587\n",
      "generated sequence: ave.\n",
      "Marry, would the word 'farewell' have lengthen'd hours\n",
      "And added years to his short banishment,\n",
      "Usoff\tuld have had a volumeof\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.ASGD(model.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,target,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y, I say, and bring them hither straight.\\n\\nLUCENTIO:\\nHere is a wonder, if you talk of a wonder.\\n\\nHORTENSIO:\\nAnd so it is: I wond\\t\\ti\\ti\\to\\t\\tio\\t\\tif\\tt\\t\\ti\\t\\t\\tfi\\tt\\t\\t\\t\\ti\\t\\t\\tot\\t\\t\\t\\rUUJDFOJi\\t;\\rUB\\t\\t\\tit\\ti\\ti\\t\\t\\t\\t\\t\\t\\tit\\ti\\t\\t\\ti\\t\\t\\tfi\\t\\ti\\ti\\t\\t\\t\\t\\t\\t\\rUUB;Ji\\tJ;\\t;\\rUo\\t\\ti\\t\\tit\\tit\\t\\ri\\ti\\t\\t\\t\\tii\\ti\\ti\\tii\\t\\tii\\t\\ti\\tii\\tiii\\t\\ti\\tiiii\\tiii\\t\\tiiiUii\\tFOJ\\t\\ti\\rUioiii\\t\\ti\\ti\\tiiiiiii\\t\\ti\\tiii\\tiii\\t\\tii\\ti\\tiiiiiiUiio\\r\\t\\ti\\t\\ri\\rUi\\tii\\tii\\t\\ti\\t\\tiU\\ti\\tiiii\\t\\ti\\ti\\ti\\t\\tii\\t\\tii\\ti\\t\\ti\\t\\t\\tii\\ti\\t\\t\\t\\ti\\t\\t\\tii\\t\\t\\ti\\t\\tiOJ\\tii\\tUi\\t\\t\\t\\t\\tii\\ti\\ti\\t\\t\\t\\t\\t\\t\\tii\\ti\\t\\t\\ti\\t\\t\\tii\\t\\ti\\ti\\t\\t\\t\\t\\t\\ti\\t\\t\\tUii\\tiU\\tUi\\ti\\t\\ti\\t\\tii\\tii\\tii\\ti\\t\\t\\t\\tii\\ti\\ti\\tii\\t\\tii\\t\\ti\\tii\\tiii\\t\\ti\\tiiii\\tiii\\t\\tiii\\tii\\tJ\\ti\\t\\tii\\tiiiii\\t\\ti\\ti\\tiiiiiii\\t\\ti\\tiii\\tiii\\t\\tii\\ti\\tiiiiii\\tiiii\\t\\ti\\tiii\\ti\\tii\\tii\\t\\ti\\t\\ti\\t\\ti\\tiiii\\t\\ti\\ti\\ti\\t\\tii\\t\\tii\\ti\\t\\ti\\t\\t\\tii\\ti\\t\\t\\t\\ti\\t\\t\\tii\\t\\t\\ti\\t\\ti\\ti\\tii\\t\\ti\\t\\t\\t\\t\\tii\\ti\\ti\\t\\t\\t\\t\\t\\t\\tii\\ti\\t\\t\\ti\\t\\t\\tii\\t\\ti\\ti'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In attempting to printing the output of the current model, the main change was for the model to pass in the input twice,since the target gave away the answers. This prevented the model from generalizing to other input and thus had bad behavior in printing words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
