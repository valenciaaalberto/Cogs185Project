{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r\n",
      "\u000b\n",
      "\f\n",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='Wha', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:4.17666111946106\n",
      "generated sequence: ozen to death.\n",
      "\n",
      "CURTIS:\n",
      "There's fire ready; and therefore, good Grumio, the news.\n",
      "\n",
      "GRUMIO:\n",
      "Why, 'Jack, boy! ho! boy!' and as muc\t\t\t\tf\t\tf\t\t\n",
      "\n",
      "iter:399/20000 loss:3.657717888355255\n",
      "generated sequence: t?\n",
      "The tribunes cannot do't for shame; the people\n",
      "Deserve such pity of him as the wolf\n",
      "Does of the shepherds: for his best frien\t\t\t\t\t\tf\t\t\t\n",
      "\n",
      "iter:599/20000 loss:3.490976847410202\n",
      "generated sequence: he shall miss me,--as, in faith, I mean not\n",
      "To see him any more,--cast your good counsels\n",
      "Upon his passion; let myself and fortu\t\tf\t\t\t\t\tf\t\n",
      "\n",
      "iter:799/20000 loss:3.402112808227539\n",
      "generated sequence: cheer? how is't with you, best brother?\n",
      "\n",
      "HERMIONE:\n",
      "You look as if you held a brow of much distraction\n",
      "Are you moved, my lord?\n",
      "\n",
      "Lf\t\t\t\t\tf\t\t\t\n",
      "\n",
      "iter:999/20000 loss:3.356063177585602\n",
      "generated sequence: \n",
      "\n",
      "LADY ANNE:\n",
      "No more than from my soul I mourn for yours.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Farewell, thou woful welcomer of glory!\n",
      "\n",
      "LADY ANNE:\n",
      "jj\t\t\tuf\t\t\t\n",
      "\n",
      "iter:1199/20000 loss:3.3223059606552123\n",
      "generated sequence: oves: he\n",
      "has the prettiest love-songs for maids; so without\n",
      "bawdry, which is strange; with such delicate\n",
      "burthens of dildos and \to\t\tfu\t\tj\t\n",
      "\n",
      "iter:1399/20000 loss:3.277044053077698\n",
      "generated sequence: trable to your. kind entreats,\n",
      "Albeit against my conscience and my soul.\n",
      "Cousin of Buckingham, and you sage, grave men,\n",
      "Since yo\t\t\t\t\t\tu\t\tu\n",
      "\n",
      "iter:1599/20000 loss:3.249942378997803\n",
      "generated sequence: e house Publius and Quintus were,\n",
      "That our beat water brought by conduits hither;\n",
      "And  \n",
      "Twice being  \n",
      "Was his great ancestor.\n",
      "\n",
      "S\tu\t\t\t\t\tu\t\t\n",
      "\n",
      "iter:1799/20000 loss:3.2163208365440368\n",
      "generated sequence: 'd with a scarf,\n",
      "Bearing a Tartar's painted bow of lath,\n",
      "Scaring the ladies like a crow-keeper;\n",
      "Nor no without-book prologue, fa\t\tu\tui\tu\tu\n",
      "\n",
      "iter:1999/20000 loss:3.186787710189819\n",
      "generated sequence: er\n",
      "constable. How long have you been in this place of constable?\n",
      "\n",
      "ELBOW:\n",
      "Seven year and a half, sir.\n",
      "\n",
      "ESCALUS:\n",
      "I thought, by you\t\tjf\t\t\ti\t\t\n",
      "\n",
      "iter:2199/20000 loss:3.1685409080982208\n",
      "generated sequence: t makes her queen who should be else?\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "What, thou?\n",
      "\n",
      "KING RICHARD III:\n",
      "I, even I: what think you of it, madam?\n",
      "\n",
      "iu\t\t\t\t\tuf\t\n",
      "\n",
      "iter:2399/20000 loss:3.128263393640518\n",
      "generated sequence: To rain a shower of commanded tears,\n",
      "An onion will do well for such a shift,\n",
      "Which in a napkin being close convey'd\n",
      "Shall in desf\tu\t\tu\tu\tu\n",
      "\n",
      "iter:2599/20000 loss:3.0996720385551453\n",
      "generated sequence: ast;\n",
      "I care not what, so it be wholesome food.\n",
      "\n",
      "GRUMIO:\n",
      "What say you to a neat's foot?\n",
      "\n",
      "KATHARINA:\n",
      "\tuf\t\tpassing good: I prithee \t\ti\t\n",
      "\n",
      "iter:2799/20000 loss:3.0914362144470213\n",
      "generated sequence: ,\n",
      "I do not like these several councils, I.\n",
      "\n",
      "HASTINGS:\n",
      "My lord,\n",
      "I hold my life as dear as you do yours;\n",
      "\tu\tvu\tvir in my life, I d\t\n",
      "\n",
      "iter:2999/20000 loss:3.057398682832718\n",
      "generated sequence: ord; 'tis yours:\n",
      "Jove send her\n",
      "A better guiding spirit! What needs these hands?\n",
      "You, that are thus so tender o'er his follies,\n",
      "Wv\t\t\tufit\tu\n",
      "\n",
      "iter:3199/20000 loss:3.044633758068085\n",
      "generated sequence: ough the ear with a\n",
      "love-song; the very pin of his heart cleft with the\n",
      "blind bow-boy's butt-shaft: and is he a man to\n",
      "encounterv\tifuif\tu\t\n",
      "\n",
      "iter:3399/20000 loss:3.019490770101547\n",
      "generated sequence: ntague is bound as well as I,\n",
      "In penalty alike; and 'tis not hard, I think,\n",
      "For men so old as we to keep the peace.\n",
      "\n",
      "PARIS:\n",
      "Of h\tiui\t\tuu\tu\n",
      "\n",
      "iter:3599/20000 loss:2.987304848432541\n",
      "generated sequence: 'ld divide,\n",
      "And burn in many places; on the topmast,\n",
      "The yards and bowsprit, would I flame distinctly,\n",
      "Then meet and join. Jove'fm\tu\ttft\t\t\n",
      "\n",
      "iter:3799/20000 loss:2.961692806482315\n",
      "generated sequence:  and my profit on't\n",
      "Is, I know how to curse. The red plague rid you\n",
      "For learning me your language!\n",
      "\n",
      "PROSPERO:\n",
      "Hag-seed, hence!\n",
      "Fuu\t\tuf\tuf\t\n",
      "\n",
      "iter:3999/20000 loss:2.949974763393402\n",
      "generated sequence: vise a death as cruel for thee\n",
      "As thou art tender to't.\n",
      "\n",
      "PERDITA:\n",
      "Even here undone!\n",
      "I was not much afeard; for once or twice\n",
      "I wft\t\tuuu\t\tu\n",
      "\n",
      "iter:4199/20000 loss:2.94922723531723\n",
      "generated sequence: ing sun\n",
      "Ne'er saw her match since first the world begun.\n",
      "\n",
      "BENVOLIO:\n",
      "Tut, you saw her fair, none else being by,\n",
      "i\trself poised wit\tiu\t\t\t\n",
      "\n",
      "iter:4399/20000 loss:2.9073743879795075\n",
      "generated sequence: s so hard? whence come you? what's your will?\n",
      "\n",
      "Nurse:\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Welcome, then.\n",
      "\n",
      "Nurse:\n",
      "O holy friar, O, tell me, holy fri\tu\tvufuf\t\n",
      "\n",
      "iter:4599/20000 loss:2.9036588990688323\n",
      "generated sequence: ful.\n",
      "\n",
      "GLOUCESTER:\n",
      "My lord, will't please you pass along?\n",
      "Myself and my good cousin Buckingham\n",
      "p\tll to your mother, to entreat of\t\tm\n",
      "\n",
      "iter:4799/20000 loss:2.8757480084896088\n",
      "generated sequence: s,\n",
      "Of whom he's chief, with all the size that verity\n",
      "Would without lapsing suffer: nay, sometimes,\n",
      "p\tu\tfvf a bowl upon a subtle \t\t\n",
      "\n",
      "iter:4999/20000 loss:2.8840629184246063\n",
      "generated sequence: hou a kingdom; all of you allegiance:\n",
      "The sorrow that I have, by right is yours,\n",
      "And all the pleasures you usurp are mine.\n",
      "\n",
      "GLOUfv\tuuu\tt\ti\n",
      "\n",
      "iter:5199/20000 loss:2.8573605477809907\n",
      "generated sequence: ur amendment,\n",
      "Are come to play a pleasant comedy;\n",
      "For so your doctors hold it very meet,\n",
      "Seeing too much sadness hath congeal'd \tfuuf\t\t\tf\t\n",
      "\n",
      "iter:5399/20000 loss:2.86370760679245\n",
      "generated sequence: Sometime the flood prevails, and then the wind;\n",
      "Now one the better, then another best;\n",
      "Both tugging to be victors, breast to breuvf\titf\tui\n",
      "\n",
      "iter:5599/20000 loss:2.8628805899620056\n",
      "generated sequence: ot true, none were enough.\n",
      "\n",
      "LUCIO:\n",
      "I was once before him for getting a wench with child.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Did you such a thing?\n",
      "viuifs\t\tu\t\n",
      "\n",
      "iter:5799/20000 loss:2.842662055492401\n",
      "generated sequence: table. He'll go, he says,\n",
      "and sowl the porter of Rome gates by the ears: he\n",
      "uf\tf mow all down before him, and leave his passage iufm\t\n",
      "\n",
      "iter:5999/20000 loss:2.8046871101856232\n",
      "generated sequence: \n",
      "And frame your mind to mirth and merriment,\n",
      "Which bars a thousand harms and lengthens life.\n",
      "\n",
      "SLY:\n",
      "\t\tu\tfuf\t will, let them play \n",
      "\n",
      "iter:6199/20000 loss:2.828014509677887\n",
      "generated sequence: Lest you be cropp'd before you come to prime.\n",
      "What news from Oxford? hold those justs and triumphs?\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "\t\tiu\tv\tuf \n",
      "\n",
      "iter:6399/20000 loss:2.816486315727234\n",
      "generated sequence: more leisure, I will so excuse\n",
      "As you shall well be satisfied withal.\n",
      "But where is Kate? I stay too long from her:\n",
      "The morning wfvf\tum\tt\ts\n",
      "\n",
      "iter:6599/20000 loss:2.813637315034866\n",
      "generated sequence: \n",
      "Boatswain:\n",
      "What, must our mouths be cold?\n",
      "\n",
      "GONZALO:\n",
      "The king and prince at prayers! let's assist them,\n",
      "bvui\tput\tase is as their\n",
      "\n",
      "iter:6799/20000 loss:2.7846182942390443\n",
      "generated sequence: Of any point in't shall not only be\n",
      "Death to thyself but to thy lewd-tongued wife,\n",
      "Whom for this time we pardon. We enjoin thee,p\tuu\t\tufvt\n",
      "\n",
      "iter:6999/20000 loss:2.7881173419952394\n",
      "generated sequence: And who shines now but Henry's enemies?\n",
      "O Phoebus, hadst thou never given consent\n",
      "That Phaethon should cheque thy fiery steeds,\n",
      "\t\tupfvu\tf\n",
      "\n",
      "iter:7199/20000 loss:2.785849548578262\n",
      "generated sequence: d,\n",
      "it follows,\n",
      "Nothing is done to purpose. Therefore, beseech you,--\n",
      "You that will be less fearful than discreet,\n",
      "tiu\tvmmve the \t\t\n",
      "\n",
      "iter:7399/20000 loss:2.8020354497432707\n",
      "generated sequence: om whose simplicity I think it not\n",
      "uneasy to get the cause of my son's resort thither.\n",
      "Prithee, be my present partner in this buvfupfv\t\tu\t\n",
      "\n",
      "iter:7599/20000 loss:2.7780758154392244\n",
      "generated sequence: so I am.\n",
      "\n",
      "Third Servingman:\n",
      "Pray you, poor gentleman, take up some other\n",
      "station; here's no place for you; pray you, avoid: come\tvu\tuuf\n",
      "\n",
      "iter:7799/20000 loss:2.7397095549106596\n",
      "generated sequence: elf must yield to odds;\n",
      "And many strokes, though with a little axe,\n",
      "Hew down and fell the hardest-timber'd oak.\n",
      "By many hands yo\tm\tuf\t\tiu\t\n",
      "\n",
      "iter:7999/20000 loss:2.7578784155845644\n",
      "generated sequence:  country are requited\n",
      "But with that surname; a good memory,\n",
      "And witness of the malice and displeasure\n",
      "Which thou shouldst bear mupvs\tif\tuu\n",
      "\n",
      "iter:8199/20000 loss:2.7543046462535856\n",
      "generated sequence: our prattling nurse\n",
      "Into a rapture lets her baby cry\n",
      "While she chats him: the kitchen malkin pins\n",
      "Her richest lockram 'bout her vsfuffuiim\n",
      "\n",
      "iter:8399/20000 loss:2.722129250764847\n",
      "generated sequence: is cheers my heart, to see your forwardness.\n",
      "\n",
      "OXFORD:\n",
      "Here pitch our battle; hence we will not budge.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Brave folt\tupf\t\tf\tu\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:2.728682541847229\n",
      "generated sequence: GHAM:\n",
      "My lord, whoever journeys to the Prince,\n",
      "For God's sake, let not us two be behind;\n",
      "For, by the way, I'll sort occasion,\n",
      "Up\tum\n",
      "\n",
      "iter:8799/20000 loss:2.74933776140213\n",
      "generated sequence: , she and that friar,\n",
      "I saw them at the prison: a saucy friar,\n",
      "A very scurvy fellow.\n",
      "\n",
      "FRIAR PETER:\n",
      "Blessed be your royal grace!\n",
      "\tu\tf\tuu\t\tu\n",
      "\n",
      "iter:8999/20000 loss:2.7190023469924927\n",
      "generated sequence:  name remains;\n",
      "The cruelty and envy of the people,\n",
      "Permitted by our dastard nobles, who\n",
      "Have all forsook me, hath devour'd the ru\tuf\tuf\tfu\n",
      "\n",
      "iter:9199/20000 loss:2.722036474943161\n",
      "generated sequence: ;\n",
      "For York in justice puts his armour on.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "If that be right which Warwick says is right,\n",
      "There is no wrong, but e\tUb\tfup\tf\t\n",
      "\n",
      "iter:9399/20000 loss:2.7201175725460054\n",
      "generated sequence: eep duty more impression show\n",
      "Than that of common sons.\n",
      "\n",
      "VOLUMNIA:\n",
      "O, stand up blest!\n",
      "Whilst, with no softer cushion than the fl\t\tfu\tsi\tuf\n",
      "\n",
      "iter:9599/20000 loss:2.7345015358924867\n",
      "generated sequence: d I thank thee. Hoo!\n",
      "Marcius coming home!\n",
      "\n",
      "VOLUMNIA:\n",
      "Nay,'tis true.\n",
      "\n",
      "VOLUMNIA:\n",
      "Look, here's a letter from him: the state hath\n",
      "an\tu\tuifu\t\tu\n",
      "\n",
      "iter:9799/20000 loss:2.6959089744091034\n",
      "generated sequence: traight dream on fees,\n",
      "O'er ladies ' lips, who straight on kisses dream,\n",
      "Which oft the angry Mab with blisters plagues,\n",
      "Because ifutifiu\tf\n",
      "\n",
      "iter:9999/20000 loss:2.693777369260788\n",
      "generated sequence: of woe; but for the miracle,\n",
      "I mean our preservation, few in millions\n",
      "Can speak like us: then wisely, good sir, weigh\n",
      "Our sorrow\t\tup\t\t\tufs\n",
      "\n",
      "iter:10199/20000 loss:2.680816980600357\n",
      "generated sequence: O:\n",
      "Pluck up thy spirits; look cheerfully upon me.\n",
      "Here love; thou see'st how diligent I am\n",
      "U\tmsp\tus thy meat myself and bring it\t\n",
      "\n",
      "iter:10399/20000 loss:2.69130583524704\n",
      "generated sequence: good lord, assured\n",
      "I hate not you for her proud arrogance.\n",
      "\n",
      "DERBY:\n",
      "I do beseech you, either not believe\n",
      "The envious slanders of i\t\t\tum\tf\t\t\n",
      "\n",
      "iter:10599/20000 loss:2.6845762801170348\n",
      "generated sequence: r backs; he trod the water,\n",
      "Whose enmity he flung aside, and breasted\n",
      "The surge most swoln that met him; his bold head\n",
      "'Bove thefufup\t\t\tuf\n",
      "\n",
      "iter:10799/20000 loss:2.6774592065811156\n",
      "generated sequence: fter I have done what I promised?\n",
      "\n",
      "Shepherd:\n",
      "Ay, sir.\n",
      "\n",
      "AUTOLYCUS:\n",
      "Well, give me the moiety. Are you a party in this business?\n",
      "\n",
      "C\ti\tfu\tufuf\n",
      "\n",
      "iter:10999/20000 loss:2.6730338525772095\n",
      "generated sequence: so with him.\n",
      "\n",
      "Provost:\n",
      "So please you, this friar hath been with him, and\n",
      "advised him for the entertainment of death.\n",
      "\n",
      "ESCALUS:\n",
      "G\t\tu\ttifuft\n",
      "\n",
      "iter:11199/20000 loss:2.6710945951938627\n",
      "generated sequence:  she sings it; 'tis in\n",
      "request, I can tell you.\n",
      "\n",
      "MOPSA:\n",
      "We can both sing it: if thou'lt bear a part, thou\n",
      "shalt hear; 'tis in thu\tf\tu\tt\ti\t\n",
      "\n",
      "iter:11399/20000 loss:2.6688242208957673\n",
      "generated sequence: ed whelp hag-born--not honour'd with\n",
      "A human shape.\n",
      "\n",
      "ARIEL:\n",
      "Yes, Caliban her son.\n",
      "\n",
      "PROSPERO:\n",
      "Dull thing, I say so; he, that Cali\t\tipf\tmfif\n",
      "\n",
      "iter:11599/20000 loss:2.6622987949848174\n",
      "generated sequence: er the sun shone bright on.\n",
      "\n",
      "PAULINA:\n",
      "O Hermione,\n",
      "As every present time doth boast itself\n",
      "Above a better gone, so must thy grave\tfuif\tu\ts\t\n",
      "\n",
      "iter:11799/20000 loss:2.6585838210582735\n",
      "generated sequence: d with nothing. Worthy Marcius,\n",
      "Had we no quarrel else to Rome, but that\n",
      "Thou art thence banish'd, we would muster all\n",
      "From twel\tu\ttifu\t\ti\n",
      "\n",
      "iter:11999/20000 loss:2.6829525458812715\n",
      "generated sequence: rs drown: beseech you all, my lords,\n",
      "With thoughts so qualified as your charities\n",
      "Shall best instruct you, measure me; and so\n",
      "uhf\tu\tf\t\t\t\n",
      "\n",
      "iter:12199/20000 loss:2.646123490333557\n",
      "generated sequence: r ships are stay'd at Venice, and the duke,\n",
      "For private quarrel 'twixt your duke and him,\n",
      "Hath publish'd and proclaim'd it openlfu\tftf\tuuf\n",
      "\n",
      "iter:12399/20000 loss:2.654226553440094\n",
      "generated sequence:  societies secure; but\n",
      "security enough to make fellowships accurst: much\n",
      "upon this riddle runs the wisdom of the world. This\n",
      "newu\t\tpt\tit\t\t\n",
      "\n",
      "iter:12599/20000 loss:2.634798815250397\n",
      "generated sequence: derstanding pate but thine?\n",
      "For thy conceit is soaking, will draw in\n",
      "More than the common blocks: not noted, is't,\n",
      "But of the fi\t\tf\tiu\t\tt\t\n",
      "\n",
      "iter:12799/20000 loss:2.6303441524505615\n",
      "generated sequence: e such power,\n",
      "She had just cause.\n",
      "\n",
      "LEONTES:\n",
      "She had; and would incense me\n",
      "To murder her I married.\n",
      "\n",
      "PAULINA:\n",
      "I should so.\n",
      "Were I\tb\tspfbf\tf\n",
      "\n",
      "iter:12999/20000 loss:2.650277135372162\n",
      "generated sequence:  with the Montagues!\n",
      "\n",
      "CAPULET:\n",
      "What noise is this? Give me my long sword, ho!\n",
      "\n",
      "LADY CAPULET:\n",
      "A crutch, a crutch! why call you fou\tti\tui\t\tu\n",
      "\n",
      "iter:13199/20000 loss:2.6237935507297516\n",
      "generated sequence: ey stay at door, sir.\n",
      "\n",
      "POLIXENES:\n",
      "O, father, you'll know more of that hereafter.\n",
      "Is it not too far gone? 'Tis time to part them.\t\tu\tiu\tuui\n",
      "\n",
      "iter:13399/20000 loss:2.625648864507675\n",
      "generated sequence: l be consul:\n",
      "I have seen the dumb men throng to see him and\n",
      "The blind to bear him speak: matrons flung gloves,\n",
      "Ladies and maids mif\tip\t\t\t\t\n",
      "\n",
      "iter:13599/20000 loss:2.6118042600154876\n",
      "generated sequence: \n",
      "DUKE VINCENTIO:\n",
      "Most notedly, sir.\n",
      "\n",
      "LUCIO:\n",
      "Do you so, sir? And was the duke a fleshmonger, a\n",
      "JUu\t\tJFnd a coward, as you then reUp\n",
      "\n",
      "iter:13799/20000 loss:2.632594542503357\n",
      "generated sequence: eling:\n",
      "open't. What's within, boy?\n",
      "\n",
      "Clown:\n",
      "You're a made old man: if the sins of your youth\n",
      "U\tf\tforgiven you, you're well to liv\tmt\ti\n",
      "\n",
      "iter:13999/20000 loss:2.638870368003845\n",
      "generated sequence: ury spent, anon\n",
      "Did this break-from her: 'Good Antigonus,\n",
      "Since fate, against thy better disposition,\n",
      "Hath made thy person for t\tf\tu\tf\t\ti\t\n",
      "\n",
      "iter:14199/20000 loss:2.6237200331687927\n",
      "generated sequence:  Duke of Norfolk, sprightfully and bold,\n",
      "Stays but the summons of the appellant's trumpet.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Why, then, the chamu\t\t\t\tu\t\tuJ\n",
      "\n",
      "iter:14399/20000 loss:2.61880353808403\n",
      "generated sequence: nd:\n",
      "Hold, take my ring.\n",
      "\n",
      "Servant:\n",
      "My lord, I had forgot to tell your lordship,\n",
      "To-day, as I came by, I called there;\n",
      "Uf\tm\t\tbhall\t\t\n",
      "\n",
      "iter:14599/20000 loss:2.6216476368904114\n",
      "generated sequence: s bark at me as I halt by them;\n",
      "Why, I, in this weak piping time of peace,\n",
      "Have no delight to pass away the time,\n",
      "Unless to spy \tufuf\tuuiu\n",
      "\n",
      "iter:14799/20000 loss:2.6242502582073213\n",
      "generated sequence: diness; not I.\n",
      "\n",
      "Second Soldier:\n",
      "Nor I.\n",
      "\n",
      "First Soldier:\n",
      "See, they have shut him in.\n",
      "\n",
      "All:\n",
      "To the pot, I warrant him.\n",
      "\n",
      "LARTIUS:\n",
      "i\t\tt\t\t\t\t\n",
      "\n",
      "iter:14999/20000 loss:2.591909042596817\n",
      "generated sequence: ters, take it not unkindly, pray,\n",
      "That I have been thus pleasant with you both.\n",
      "\n",
      "HORTENSIO:\n",
      "You may go walk, and give me leave ai\tf\t\tuiu\t\t\n",
      "\n",
      "iter:15199/20000 loss:2.6143966460227968\n",
      "generated sequence: erson from night-foes?\n",
      "\n",
      "WARWICK:\n",
      "This is his tent; and see where stand his guard.\n",
      "Courage, my masters! honour now or never!\n",
      "But \tf\t\t\ti\tf\tf\n",
      "\n",
      "iter:15399/20000 loss:2.606718180179596\n",
      "generated sequence: t\n",
      "To serve me last, that I may longest keep\n",
      "Thy sorrow in my breast. Come, ladies, go,\n",
      "To meet at London London's king in woe.\n",
      "WiUi\tb\t\tff\t\n",
      "\n",
      "iter:15599/20000 loss:2.601119841337204\n",
      "generated sequence: r to dull delay;\n",
      "Delay leads impotent and snail-paced beggary\n",
      "Then fiery expedition be my wing,\n",
      "Jove's Mercury, and herald for afbi\tb\tsmmb\n",
      "\n",
      "iter:15799/20000 loss:2.612248743772507\n",
      "generated sequence: STIAN:\n",
      "As if it had lungs and rotten ones.\n",
      "\n",
      "ANTONIO:\n",
      "Or as 'twere perfumed by a fen.\n",
      "\n",
      "GONZALO:\n",
      "\ture is everything advantageous tpi\t\n",
      "\n",
      "iter:15999/20000 loss:2.6110520899295806\n",
      "generated sequence: enge for me\n",
      "Richard, I bear thy name; I'll venge thy death,\n",
      "Or die renowned by attempting it.\n",
      "\n",
      "EDWARD:\n",
      "His name that valiant duk\t\ti\tb\t\tfbf\n",
      "\n",
      "iter:16199/20000 loss:2.5944006025791166\n",
      "generated sequence: fortunes forth of France,\n",
      "And heap'd sedition on his crown at home.\n",
      "For what hath broach'd this tumult but thy pride?\n",
      "Hadst thou\t\t\ti\t\t\t\ti\t\n",
      "\n",
      "iter:16399/20000 loss:2.6068154621124267\n",
      "generated sequence: d you passing gentle.\n",
      "'Twas told me you were rough and coy and sullen,\n",
      "And now I find report a very liar;\n",
      "For thou are pleasant,\tb\t\t\tbfu\t\t\n",
      "\n",
      "iter:16599/20000 loss:2.5769711577892305\n",
      "generated sequence: r she mistook her frets,\n",
      "And bow'd her hand to teach her fingering;\n",
      "When, with a most impatient devilish spirit,\n",
      "'Frets, call yofi\tf\tift\ti\n",
      "\n",
      "iter:16799/20000 loss:2.6119443106651308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: roubled,\n",
      "Muddy, ill-seeming, thick, bereft of beauty;\n",
      "And while it is so, none so dry or thirsty\n",
      "Will deign to sip or touch one f\t\tfm\t\t\tJp\n",
      "\n",
      "iter:16999/20000 loss:2.594443371295929\n",
      "generated sequence: ng she's your wife,\n",
      "And loves not me, be you, good lord, assured\n",
      "I hate not you for her proud arrogance.\n",
      "\n",
      "DERBY:\n",
      "I do beseech yo\tii\t\t\t\t\ti\t\n",
      "\n",
      "iter:17199/20000 loss:2.5924130380153656\n",
      "generated sequence: don, you shall bear my standard.\n",
      "Give me some ink and paper in my tent\n",
      "I'll draw the form and model of our battle,\n",
      "Limit each le\t\t\t\tu\t\t\tu\t\n",
      "\n",
      "iter:17399/20000 loss:2.580211330652237\n",
      "generated sequence: et distinctly ranges,\n",
      "In heaps and piles of ruin.\n",
      "\n",
      "SICINIUS:\n",
      "This deserves death.\n",
      "\n",
      "BRUTUS:\n",
      "Or let us stand to our authority,\n",
      "Or \tib\tt\tit\tp\n",
      "\n",
      "iter:17599/20000 loss:2.590569498538971\n",
      "generated sequence:  death, but body's banishment.\n",
      "\n",
      "ROMEO:\n",
      "Ha, banishment! be merciful, say 'death;'\n",
      "For exile hath more terror in his look,\n",
      "Much moi\t\tui\t\tif\t\n",
      "\n",
      "iter:17799/20000 loss:2.584612877368927\n",
      "generated sequence: ch if thou respect,\n",
      "Show a fair presence and put off these frowns,\n",
      "And ill-beseeming semblance for a feast.\n",
      "\n",
      "TYBALT:\n",
      "It fits, whpfit\tiif\ts\n",
      "\n",
      "iter:17999/20000 loss:2.5870790672302246\n",
      "generated sequence: venom'd spear,\n",
      "The which no balm can cure but his heart-blood\n",
      "Which breathed this poison.\n",
      "\n",
      "KING RICHARD II:\n",
      "Rage must be withstof\t\t\tfe\ti\tf\n",
      "\n",
      "iter:18199/20000 loss:2.6006366276741026\n",
      "generated sequence: d Northumberland.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "The commons will not then be satisfied.\n",
      "\n",
      "KING RICHARD II:\n",
      "They shall be satisfied: I'll read \tbJ\tfifsff\n",
      "\n",
      "iter:18399/20000 loss:2.5747843635082246\n",
      "generated sequence: nsul that will from them take\n",
      "Their liberties; make them of no more voice\n",
      "Than dogs that are as often beat for barking\n",
      "As theref\t\t\t\tii\tuii\n",
      "\n",
      "iter:18599/20000 loss:2.578177262544632\n",
      "generated sequence: nd, indeed, with most painful\n",
      "feeling of thy speech: I will, out of thine own\n",
      "confession, learn to begin thy health; but, whilst\t\t\tut\t\t\t\t\t\n",
      "\n",
      "iter:18799/20000 loss:2.56772274017334\n",
      "generated sequence: thou that talk'st of kings and queens?\n",
      "\n",
      "KING HENRY VI:\n",
      "More than I seem, and less than I was born to:\n",
      "A man at least, for less Ii\t\t\tu\t\tu\tu\n",
      "\n",
      "iter:18999/20000 loss:2.579897712469101\n",
      "generated sequence: rged the contrary.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "The king! why, who's that?\n",
      "\n",
      "BRAKENBURY:\n",
      "I cry you mercy: I mean the lord protector.\n",
      "\n",
      "QUEEN fi\t\tii\t\tip\n",
      "\n",
      "iter:19199/20000 loss:2.5744286799430847\n",
      "generated sequence:  wore them, these base slaves,\n",
      "Ere yet the fight be done, pack up: down with them!\n",
      "And hark, what noise the general makes! To hii\t\tf\tii\t\tf\n",
      "\n",
      "iter:19399/20000 loss:2.575195380449295\n",
      "generated sequence: is Lord Stanley quarter'd, dost thou know?\n",
      "\n",
      "BLUNT:\n",
      "Unless I have mista'en his colours much,\n",
      "Which well I am assured I have not dt\tiB\tf\tipi\n",
      "\n",
      "iter:19599/20000 loss:2.548758865594864\n",
      "generated sequence: ring forth\n",
      "A bird that will revenge upon you all:\n",
      "And in that hope I throw mine eyes to heaven,\n",
      "Scorning whate'er you can afflicft\tii\t\tfi\t\n",
      "\n",
      "iter:19799/20000 loss:2.557193319797516\n",
      "generated sequence: en a tardy sluggard here.\n",
      "\n",
      "LORDS:\n",
      "How have you slept, my lord?\n",
      "\n",
      "RICHMOND:\n",
      "The sweetest sleep, and fairest-boding dreams\n",
      "That eve\t\tbobiof\t\t\n",
      "\n",
      "iter:19999/20000 loss:2.547936410903931\n",
      "generated sequence: ,\n",
      "whipping, and hanging.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Slandering a prince deserves it.\n",
      "She, Claudio, that you wrong'd, look you restore.\n",
      "Joy\tJ\t\ttfft\ti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,target,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ful head is on!\\n\\nTYRREL:\\nThe tyrannous and bloody deed is done.\\nThe most arch of piteous massacre\\nThat ever yet this land was gu\\t\\t\\tb\\t\\to\\tbt\\tb\\t\\t\\rJJipJJOB\\rJi\\t\\tb\\t\\t\\tu\\t\\t\\t\\t\\tbu\\t\\tbf\\t\\t\\t\\t\\ti\\t\\t\\t\\tit\\ti\\t\\t\\t\\t\\rJi\\t\\ti\\t\\t\\t\\ti\\t\\tp\\ti\\t\\tipt\\t\\t\\t\\t\\ti\\t\\t\\t\\t\\tp\\t\\tUi\\t\\t\\ti\\tf\\t\\ti\\t\\t\\ti\\t\\t\\t\\ti\\t\\t\\t\\ti\\t\\t\\ti\\t\\tiii\\tii\\ti\\t\\ti\\tiiU\\t\\t\\t\\t\\t\\t\\t\\tU\\t\\tii\\tiii\\tiiiii\\t\\tii\\t\\tiiiii\\tiiii\\t\\ti\\tiiiiU\\t\\tii\\tiiii\\tii\\ti\\tii\\t\\t\\tiiiii\\tiiiii\\tiii\\tiii\\ti\\tii\\tiii\\tiiii\\tiiii\\tiii\\tii\\t\\t\\ti\\t\\ti\\tii\\ti\\t\\tiiiiiiiiiiii\\t\\ti\\t\\t\\ti\\t\\t\\t\\t\\tii\\t\\tii\\t\\t\\t\\t\\ti\\t\\t\\t\\tii\\ti\\t\\t\\t\\tiii\\t\\ti\\t\\t\\t\\ti\\t\\ti\\ti\\t\\tiii\\t\\t\\t\\t\\ti\\t\\t\\t\\t\\ti\\t\\t\\ti\\t\\t\\ti\\ti\\t\\ti\\t\\t\\ti\\t\\t\\t\\ti\\t\\t\\t\\ti\\t\\t\\ti\\t\\tiii\\tii\\ti\\t\\ti\\tii\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tii\\tiii\\tiiiii\\t\\tii\\t\\tiiiii\\tiiii\\t\\ti\\tiiii\\t\\t\\tii\\tiiii\\tii\\ti\\tii\\t\\t\\tiiiii\\tiiiii\\tiii\\tiii\\ti\\tii\\tiii\\tiiii\\tiiii\\tiii\\tii\\t\\t\\ti\\t\\ti\\tii\\ti\\t\\tiiiiiiiiiiii\\t\\ti\\t\\t\\ti\\t\\t\\t\\t\\tii\\t\\tii\\t\\t\\t\\t\\ti\\t\\t\\t\\tii\\ti\\t\\t\\t\\tiii\\t\\ti\\t\\t\\t\\ti\\t\\ti\\ti\\t\\tiii\\t\\t\\t\\t\\t'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In attempting to printing the output of the current model, the main change was for the model to pass in the input twice,since the target gave away the answers. This prevented the model from generalizing to other input and thus had bad behavior in printing words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
