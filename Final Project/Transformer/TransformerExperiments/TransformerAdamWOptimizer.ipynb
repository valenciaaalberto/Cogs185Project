{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "# d_ff = 2048\n",
    "# d_ff = 128\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='Wha', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:2.8540650606155396\n",
      "generated sequence: ad, but it may well be told.\n",
      "\n",
      "KING RICHARD III:\n",
      "Hoyday, a riddle! neither good nor bad!\n",
      "Why dost thou run so many mile about,\n",
      "Whm\t\tufmiuui\n",
      "\n",
      "iter:399/20000 loss:2.5763925778865815\n",
      "generated sequence: nd Clarence. O, what cause have I,\n",
      "Thine being but a moiety of my grief,\n",
      "To overgo thy plaints and drown thy cries!\n",
      "\n",
      "Boy:\n",
      "Good ae\tnI\to\t\tep\n",
      "\n",
      "iter:599/20000 loss:2.525914455652237\n",
      "generated sequence: at, were I crown'd the most imperial monarch,\n",
      "Thereof most worthy, were I the fairest youth\n",
      "That ever made eye swerve, had forceu\t\tuj\tf\tu\t\n",
      "\n",
      "iter:799/20000 loss:2.4601682674884797\n",
      "generated sequence:  praise us, as little accuse\n",
      "us.\n",
      "\n",
      "CAMILLO:\n",
      "You pay a great deal too dear for what's given freely.\n",
      "\n",
      "ARCHIDAMUS:\n",
      "Believe me, I speuffot\t\tus\t\n",
      "\n",
      "iter:999/20000 loss:2.4101247107982635\n",
      "generated sequence: on and whose heart together\n",
      "Affliction alters.\n",
      "\n",
      "PERDITA:\n",
      "One of these is true:\n",
      "I think affliction may subdue the cheek,\n",
      "But not \thuuh\tuif\t\n",
      "\n",
      "iter:1199/20000 loss:2.358192108273506\n",
      "generated sequence: OWBRAY:\n",
      "However God or fortune cast my lot,\n",
      "There lives or dies, true to King Richard's throne,\n",
      "A loyal, just and upright gentle;iFJ;B\tTB\t\n",
      "\n",
      "iter:1399/20000 loss:2.3161898016929627\n",
      "generated sequence: STER:\n",
      "Sprawl'st thou? take that, to end thy agony.\n",
      "\n",
      "CLARENCE:\n",
      "And there's for twitting me with perjury.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "JBffollBBOJ\n",
      "\n",
      "iter:1599/20000 loss:2.2623984545469282\n",
      "generated sequence:  a smoke raised with the fume of sighs;\n",
      "Being purged, a fire sparkling in lovers' eyes;\n",
      "Being vex'd a sea nourish'd with lovers'ioi\tfv\t\tif\n",
      "\n",
      "iter:1799/20000 loss:2.2339606142044066\n",
      "generated sequence: , when sawest thou the Prince Florizel, my\n",
      "son? Kings are no less unhappy, their issue not\n",
      "being gracious, than they are in losi\tti\t\t\ttfsi\n",
      "\n",
      "iter:1999/20000 loss:2.2141509073972703\n",
      "generated sequence: r it.\n",
      "\n",
      "BUCKINGHAM:\n",
      "What says your highness to my just demand?\n",
      "\n",
      "KING RICHARD III:\n",
      "As I remember, Henry the Sixth\n",
      "QQ\tLProphesy tha\tuo\t\n",
      "\n",
      "iter:2199/20000 loss:2.1697819060087205\n",
      "generated sequence: s.\n",
      "\n",
      "LUCIO:\n",
      "I grant; as there may between the lists and the\n",
      "velvet. Thou art the list.\n",
      "\n",
      "First Gentleman:\n",
      "CCVoV\t\tu the velvet: thof\n",
      "\n",
      "iter:2399/20000 loss:2.134694065451622\n",
      "generated sequence:  yes, here it is.\n",
      "'They have press'd a power, but it is not known\n",
      "Whether for east or west: the dearth is great;\n",
      "uf\tf\teople mutiu\t\t\t\n",
      "\n",
      "iter:2599/20000 loss:2.1142565482854843\n",
      "generated sequence: n a stain\n",
      "As passes colouring.\n",
      "Dear gentlewoman,\n",
      "How fares our gracious lady?\n",
      "\n",
      "EMILIA:\n",
      "As well as one so great and so forlorn\n",
      "Ma\tuuuu\tuo\tJ\n",
      "\n",
      "iter:2799/20000 loss:2.0732492572069168\n",
      "generated sequence: we do, if we perceive\n",
      "Lord Hastings will not yield to our complots?\n",
      "\n",
      "GLOUCESTER:\n",
      "Chop off his head, man; somewhat we will do:\n",
      "Anj\tu\ts\tuo\tu\n",
      "\n",
      "iter:2999/20000 loss:2.0513169986009596\n",
      "generated sequence: entle Northumberland,\n",
      "If thy offences were upon record,\n",
      "Would it not shame thee in so fair a troop\n",
      "To read a lecture of them? If\tp\tf\tuFsf\t\n",
      "\n",
      "iter:3199/20000 loss:2.016780767440796\n",
      "generated sequence: her'd.\n",
      "My charity is outrage, life my shame\n",
      "And in that shame still live my sorrow's rage.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Have done, have done.\n",
      "\n",
      "Uz\tu\t\t\n",
      "\n",
      "iter:3399/20000 loss:2.014008703827858\n",
      "generated sequence: IO:\n",
      "And I am one that love Bianca more\n",
      "Than words can witness, or your thoughts can guess.\n",
      "\n",
      "GREMIO:\n",
      "ofpu\tuing, thou canst not lo\t;\n",
      "\n",
      "iter:3599/20000 loss:1.9839773452281952\n",
      "generated sequence: lord, your son was gone before I came.\n",
      "\n",
      "DUKE OF YORK:\n",
      "He was? Why, so! go all which way it will!\n",
      "The nobles they are fled, the cpvf\t\tu\tvuf\n",
      "\n",
      "iter:3799/20000 loss:1.9580225622653962\n",
      "generated sequence: your highness to resolve me now;\n",
      "And what your pleasure is, shall satisfy me.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "CLARENCE:\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "KING EDWARD \tsspufoffp\n",
      "\n",
      "iter:3999/20000 loss:1.9061289101839065\n",
      "generated sequence: d, brother, die:\n",
      "More than our brother is our chastity.\n",
      "I'll tell him yet of Angelo's request,\n",
      "uf\t\ti\t\t\this mind to death, for hi\t\n",
      "\n",
      "iter:4199/20000 loss:1.9287447434663774\n",
      "generated sequence: er thou art most ignorant by age,\n",
      "Or thou wert born a fool. Camillo's flight,\n",
      "Added to their familiarity,\n",
      "Which was as gross as s\tu\tf\ttuo\t\n",
      "\n",
      "iter:4399/20000 loss:1.895769322514534\n",
      "generated sequence: t. Is not a\n",
      "comondy a Christmas gambold or a tumbling-trick?\n",
      "\n",
      "Page:\n",
      "No, my good lord; it is more pleasing stuff.\n",
      "\n",
      "SLY:\n",
      "u\t\tu\tviuui\n",
      "\n",
      "iter:4599/20000 loss:1.889157766699791\n",
      "generated sequence: y, sir, I will detest myself also, as well as\n",
      "she, that this house, if it be not a bawd's house,\n",
      "it is pity of her life, for it \t\tu\ttf\tu;u\n",
      "\n",
      "iter:4799/20000 loss:1.8752857053279877\n",
      "generated sequence: ly,\n",
      "That would unseen be wicked? is this nothing?\n",
      "Why, then the world and all that's in't is nothing;\n",
      "The covering sky is nothin\t\t\tDibo\tuJ\n",
      "\n",
      "iter:4999/20000 loss:1.850145581960678\n",
      "generated sequence: d'st!\n",
      "\n",
      "AUFIDIUS:\n",
      "You keep a constant temper.\n",
      "\n",
      "First Senator:\n",
      "Now, sir, is your name Menenius?\n",
      "\n",
      "Second Senator:\n",
      "UUoT\ta spell, youfufi\n",
      "\n",
      "iter:5199/20000 loss:1.8316339719295502\n",
      "generated sequence: ter; grace my mournings here;\n",
      "In weeping after this untimely bier.\n",
      "\n",
      "\n",
      "SAMPSON:\n",
      "Gregory, o' my word, we'll not carry coals.\n",
      "\n",
      "GREGO\t\tf\tu\tfuf\t\n",
      "\n",
      "iter:5399/20000 loss:1.8286016702651977\n",
      "generated sequence: precious book of love, this unbound lover,\n",
      "To beautify him, only lacks a cover:\n",
      "The fish lives in the sea, and 'tis much pride\n",
      "Fpfobons\tuf\n",
      "\n",
      "iter:5599/20000 loss:1.8680610167980194\n",
      "generated sequence: er is toward.\n",
      "\n",
      "GREMIO:\n",
      "They're busy within; you were best knock louder.\n",
      "\n",
      "Pedant:\n",
      "What's he that knocks as he would beat down the\tfuo\tu\t\tfo\n",
      "\n",
      "iter:5799/20000 loss:1.8124750167131425\n",
      "generated sequence: s against my oath.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Were you sworn to the duke, or to the deputy?\n",
      "\n",
      "Provost:\n",
      "To him, and to his substitutes.\n",
      "\n",
      "DUK\tuu\tump\tiu\n",
      "\n",
      "iter:5999/20000 loss:1.7888919627666473\n",
      "generated sequence: nk so twenty years together!\n",
      "No settled senses of the world can match\n",
      "The pleasure of that madness. Let 't alone.\n",
      "\n",
      "PAULINA:\n",
      "I amefu\tsu\t\t\te\n",
      "\n",
      "iter:6199/20000 loss:1.7926732605695725\n",
      "generated sequence: ther, this shall slay them both:\n",
      "Therefore, out of thy long-experienced time,\n",
      "Give me some present counsel, or, behold,\n",
      "'Twixt mib\tf\tuibo\t\n",
      "\n",
      "iter:6399/20000 loss:1.792151010632515\n",
      "generated sequence: ment King Henry's corse.\n",
      "\n",
      "GLOUCESTER:\n",
      "Stay, you that bear the corse, and set it down.\n",
      "\n",
      "LADY ANNE:\n",
      "What black magician conjures uz\thiuJoh\tu\n",
      "\n",
      "iter:6599/20000 loss:1.7753305119276046\n",
      "generated sequence: a face of her own.\n",
      "\n",
      "CURTIS:\n",
      "Who knows not that?\n",
      "\n",
      "GRUMIO:\n",
      "Thou, it seems, that calls for company to\n",
      "countenance her.\n",
      "\n",
      "CURTIS:\n",
      "I cmufmfsu\tfu\n",
      "\n",
      "iter:6799/20000 loss:1.796968538761139\n",
      "generated sequence: ing to't? Would I do this?\n",
      "Could man so blench?\n",
      "\n",
      "CAMILLO:\n",
      "I must believe you, sir:\n",
      "I do; and will fetch off Bohemia for't;\n",
      "urovioe\tu\tvt\t\n",
      "\n",
      "iter:6999/20000 loss:1.7701638573408127\n",
      "generated sequence: h; one who never feels\n",
      "The wanton stings and motions of the sense,\n",
      "But doth rebate and blunt his natural edge\n",
      "With profits of thf\tivp\tiffv\n",
      "\n",
      "iter:7199/20000 loss:1.767257639169693\n",
      "generated sequence: 'I would thou wert the man'\n",
      "That would divorce this terror from my heart;'\n",
      "Meaning the king at Pomfret. Come, let's go:\n",
      "I am theU;uivs\t\tui\n",
      "\n",
      "iter:7399/20000 loss:1.7685116010904312\n",
      "generated sequence:  bid them do: for we bid this be done,\n",
      "When evil deeds have their permissive pass\n",
      "And not the punishment. Therefore indeed, my fufufu\tfofu\n",
      "\n",
      "iter:7599/20000 loss:1.7553895938396453\n",
      "generated sequence:  is install'd;\n",
      "That she, poor wretch, for grief can speak no more;\n",
      "Whiles Warwick tells his title, smooths the wrong,\n",
      "Inferreth uo\tuoe\tium\n",
      "\n",
      "iter:7799/20000 loss:1.7363880586624145\n",
      "generated sequence:  of noble fame and worth:\n",
      "And towards London they do bend their course,\n",
      "If by the way they be not fought withal.\n",
      "\n",
      "DERBY:\n",
      "Return uvpuevf\tsu\n",
      "\n",
      "iter:7999/20000 loss:1.7353475564718246\n",
      "generated sequence: ! Cushions, leaden spoons,\n",
      "Irons of a doit, doublets that hangmen would\n",
      "Bury with those that wore them, these base slaves,\n",
      "uJs\tptsp\t\n",
      "\n",
      "iter:8199/20000 loss:1.7206614160537719\n",
      "generated sequence: lt.\n",
      "\n",
      "GREGORY:\n",
      "They must take it in sense that feel it.\n",
      "\n",
      "SAMPSON:\n",
      "Me they shall feel while I am able to stand: and\n",
      "\tVS\t;known I ap\t\n",
      "\n",
      "iter:8399/20000 loss:1.7115237730741502\n",
      "generated sequence:  will make for Ireland presently.\n",
      "Bushy, what news?\n",
      "\n",
      "BUSHY:\n",
      "Old John of Gaunt is grievous sick, my lord,\n",
      "Suddenly taken; and hatu\to\t\tufu\t\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:1.7120979899168014\n",
      "generated sequence: is hand to wield a sceptre, and himself\n",
      "Likely in time to bless a regal throne.\n",
      "Make much of him, my lords, for this is he\n",
      "Must ofufo\t\tu\t\t\n",
      "\n",
      "iter:8799/20000 loss:1.7391123616695403\n",
      "generated sequence: up to-night.\n",
      "Give me some ink and paper.\n",
      "What, is my beaver easier than it was?\n",
      "And all my armour laid into my tent?\n",
      "\n",
      "CATESBY:\n",
      "etibfs\n",
      "\n",
      "iter:8999/20000 loss:1.7114160394668578\n",
      "generated sequence:  husband and my lord, my lord and husband;\n",
      "I am your wife in all obedience.\n",
      "\n",
      "SLY:\n",
      "I know it well. What must I call her?\n",
      "\n",
      "Lord:\n",
      "Mufuffo\t\tuo\n",
      "\n",
      "iter:9199/20000 loss:1.7198930078744887\n",
      "generated sequence: \n",
      "At that sad stop, my lord,\n",
      "Where rude misgovern'd hands from windows' tops\n",
      "Threw dust and rubbish on King Richard's head.\n",
      "\n",
      "n\tu\tfo\tu\t\n",
      "\n",
      "iter:9399/20000 loss:1.7340651601552963\n",
      "generated sequence:  waters and o'erbear\n",
      "What they are used to bear.\n",
      "\n",
      "MENENIUS:\n",
      "Pray you, be gone:\n",
      "I'll try whether my old wit be in request\n",
      "With thujji\t\t\tuje\n",
      "\n",
      "iter:9599/20000 loss:1.7004930859804153\n",
      "generated sequence: Hath she forgot already that brave prince,\n",
      "Edward, her lord, whom I, some three months since,\n",
      "Stabb'd in my angry mood at Tewksbf\tifuff\tu\t\n",
      "\n",
      "iter:9799/20000 loss:1.6804472285509109\n",
      "generated sequence: ly he is her\n",
      "ape: he so near to Hermione hath done Hermione that\n",
      "they say one would speak to her and stand in hope of\n",
      "answer: th\t-uf\tut\tuf\n",
      "\n",
      "iter:9999/20000 loss:1.682568142414093\n",
      "generated sequence: ution like\n",
      "A twist of rotten silk, never admitting\n",
      "Counsel o' the war, but at his nurse's tears\n",
      "He whined and roar'd away your vs\ttveu\tt\t\t\n",
      "\n",
      "iter:10199/20000 loss:1.6817584592103958\n",
      "generated sequence: d; and, by my soul,\n",
      "If this right hand would buy two hour's life,\n",
      "That I in all despite might rail at him,\n",
      "uue\t\tuf\td should chop\t\n",
      "\n",
      "iter:10399/20000 loss:1.6845804464817047\n",
      "generated sequence: breathe the abundant dolour of the heart.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "Thy grief is but thy absence for a time.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Joy absenffesffeuff\n",
      "\n",
      "iter:10599/20000 loss:1.6998739010095596\n",
      "generated sequence: e precious than the lark,\n",
      "Because his fathers are more beautiful?\n",
      "Or is the adder better than the eel,\n",
      "Because his painted skin \tuff\tfo\t\t\t\n",
      "\n",
      "iter:10799/20000 loss:1.6806802982091904\n",
      "generated sequence: l kingly woe obey.\n",
      "That power I have, discharge; and let them go\n",
      "To ear the land that hath some hope to grow,\n",
      "For I have none: l\tujopi\t\tuj\n",
      "\n",
      "iter:10999/20000 loss:1.6882848715782166\n",
      "generated sequence: ay it please\n",
      "your honour.\n",
      "\n",
      "MISTRESS OVERDONE:\n",
      "My lord, this is one Lucio's information against me.\n",
      "Mistress Kate Keepdown was wio\tuoiuf\t\to\n",
      "\n",
      "iter:11199/20000 loss:1.6697549134492875\n",
      "generated sequence: ll hath held them; that to's power he would\n",
      "Have made them mules, silenced their pleaders and\n",
      "Dispropertied their freedoms, holdppifoifif\t\n",
      "\n",
      "iter:11399/20000 loss:1.6560599941015244\n",
      "generated sequence: \n",
      "with comforts,\n",
      "Constrains them weep and shake with fear and sorrow;\n",
      "Making the mother, wife and child to see\n",
      "The son, the husbaTjoifupvfp\n",
      "\n",
      "iter:11599/20000 loss:1.6679601734876632\n",
      "generated sequence: nger:\n",
      "His horse is slain, and all on foot he fights,\n",
      "Seeking for Richmond in the throat of death.\n",
      "fo\tuue, fair lord, or else thef\t\t\t\n",
      "\n",
      "iter:11799/20000 loss:1.6663920283317566\n",
      "generated sequence: r; then it follows thus;\n",
      "Thou shalt be master, Tranio, in my stead,\n",
      "Keep house and port and servants as I should:\n",
      "I will some ot\t\tuif\tfuoi\n",
      "\n",
      "iter:11999/20000 loss:1.6615023136138916\n",
      "generated sequence: st Citizen:\n",
      "Care for us! True, indeed! They ne'er cared for us\n",
      "yet: suffer us to famish, and their store-houses\n",
      "crammed with gra\tiuZoiof\te\n",
      "\n",
      "iter:12199/20000 loss:1.6620229387283325\n",
      "generated sequence: ds that had struck anointed kings\n",
      "And flourish'd after, I'ld not do't; but since\n",
      "Nor brass nor stone nor parchment bears not one\tbuifuiufu\n",
      "\n",
      "iter:12399/20000 loss:1.6744649857282639\n",
      "generated sequence: ch you gamut in a briefer sort,\n",
      "More pleasant, pithy and effectual,\n",
      "Than hath been taught by any of my trade:\n",
      "And there it is inpju\tvsuis\t\n",
      "\n",
      "iter:12599/20000 loss:1.6620804351568221\n",
      "generated sequence: n sailor on a mast,\n",
      "Ready, with every nod, to tumble down\n",
      "Into the fatal bowels of the deep.\n",
      "\n",
      "LOVEL:\n",
      "Come, come, dispatch; 'tis pu\tso\tvfuv\n",
      "\n",
      "iter:12799/20000 loss:1.64232197701931\n",
      "generated sequence: ath rung, 'tis three o'clock:\n",
      "Look to the baked meats, good Angelica:\n",
      "Spare not for the cost.\n",
      "\n",
      "Nurse:\n",
      "Go, you cot-quean, go,\n",
      "Geto\tjufsff\tu\n",
      "\n",
      "iter:12999/20000 loss:1.6691877007484437\n",
      "generated sequence: ears none.\n",
      "\n",
      "GREMIO:\n",
      "Hortensio, hark:\n",
      "This gentleman is happily arrived,\n",
      "My mind presumes, for his own good and ours.\n",
      "\n",
      "HORTENSIO:\tmf\tufxf\t\n",
      "\n",
      "iter:13199/20000 loss:1.6352706813812257\n",
      "generated sequence: et's march without the noise of threatening drum,\n",
      "That from this castle's tatter'd battlements\n",
      "Our fair appointments may be well\t\tt\tufo\tvf\n",
      "\n",
      "iter:13399/20000 loss:1.647949041724205\n",
      "generated sequence: users;\n",
      "Or, if she be accused in true report,\n",
      "Bear with her weakness, which, I think proceeds\n",
      "Sf\tm wayward sickness, and no grouno\t\tf\t\t\n",
      "\n",
      "iter:13599/20000 loss:1.640668550133705\n",
      "generated sequence: ur meaning, brother\n",
      "Gloucester;\n",
      "You envy my advancement and my friends':\n",
      "God grant we never may have need of you!\n",
      "\n",
      "GLOUCESTER:\n",
      "Ms\tu\t\tueoef\n",
      "\n",
      "iter:13799/20000 loss:1.6361303645372391\n",
      "generated sequence: oe, since fear oppresseth strength,\n",
      "Gives in your weakness strength unto your foe,\n",
      "And so your follies fight against yourself.\n",
      "Fss\tu\tohpsu\n",
      "\n",
      "iter:13999/20000 loss:1.6372067767381668\n",
      "generated sequence:  am no beast.\n",
      "\n",
      "GRUMIO:\n",
      "Am I but three inches? why, thy horn is a foot; and\n",
      "so long am I at the least. But wilt thou make a\n",
      "fire,umfu\tguf\tm\n",
      "\n",
      "iter:14199/20000 loss:1.6396494406461715\n",
      "generated sequence:  not put\n",
      "The dibble in earth to set one slip of them;\n",
      "No more than were I painted I would wish\n",
      "This youth should say 'twere wellu\t\tiuf\tiBi\n",
      "\n",
      "iter:14399/20000 loss:1.6342232114076614\n",
      "generated sequence: t.\n",
      "Let's see for means: O mischief, thou art swift\n",
      "To enter in the thoughts of desperate men!\n",
      "I do remember an apothecary,--\n",
      "B\tituuu\n",
      "\n",
      "iter:14599/20000 loss:1.645977450609207\n",
      "generated sequence: n that do poison need,\n",
      "Nor do I thee: though I did wish him dead,\n",
      "I hate the murderer, love him murdered.\n",
      "The guilt of conscienceuvfuvu\txu\n",
      "\n",
      "iter:14799/20000 loss:1.6368803012371063\n",
      "generated sequence: \n",
      "ROMEO:\n",
      "Alas, that love, whose view is muffled still,\n",
      "Should, without eyes, see pathways to his will!\n",
      "oml;O shall we dine? O me!\n",
      "\n",
      "iter:14999/20000 loss:1.633812356889248\n",
      "generated sequence: s majesty hath straitly given in charge\n",
      "That no man shall have private conference,\n",
      "Of what degree soever, with his brother.\n",
      "\n",
      "GLOpufuftpi\tu\n",
      "\n",
      "iter:15199/20000 loss:1.6214048105478287\n",
      "generated sequence: s and maids their scarfs and handkerchers,\n",
      "Upon him as he pass'd: the nobles bended,\n",
      "As to Jove's statue, and the commons made\n",
      "A\tuoefufoof\n",
      "\n",
      "iter:15399/20000 loss:1.6331343990564346\n",
      "generated sequence: your contracted\n",
      "Heirs of your kingdoms, my poor house to visit,\n",
      "It is a surplus of your grace, which never\n",
      "My life may last to a\t\tsfup\teif\n",
      "\n",
      "iter:15599/20000 loss:1.6052754801511764\n",
      "generated sequence: in the leash,\n",
      "To let him slip at will.\n",
      "\n",
      "COMINIUS:\n",
      "Where is that slave\n",
      "Which told me they had beat you to your trenches?\n",
      "Where iso\tu\tf\tu\t\tm\n",
      "\n",
      "iter:15799/20000 loss:1.6350579571723938\n",
      "generated sequence: dream of what thou wert, a breath, a bubble,\n",
      "A sign of dignity, a garish flag,\n",
      "To be the aim of every dangerous shot,\n",
      "A queen in\t\tsw\tuvpuj\n",
      "\n",
      "iter:15999/20000 loss:1.628087049126625\n",
      "generated sequence: how the young folks lay their heads together!\n",
      "Master, master, look about you: who goes there, ha?\n",
      "\n",
      "HORTENSIO:\n",
      "Peace, Grumio! it f\t\tu\tf\tu\t\t\n",
      "\n",
      "iter:16199/20000 loss:1.6486312812566757\n",
      "generated sequence: ut my heart;\n",
      "With mine own tears I wash away my balm,\n",
      "With mine own hands I give away my crown,\n",
      "With mine own tongue deny my sact\tu\t\tuf\te\t\n",
      "\n",
      "iter:16399/20000 loss:1.6035212224721909\n",
      "generated sequence: ly sometimes,\n",
      "Which after hours give leisure to repent.\n",
      "If I did take the kingdom from your sons,\n",
      "To make amends, Ill give it tom\tuu\tb\tiob\n",
      "\n",
      "iter:16599/20000 loss:1.599365918636322\n",
      "generated sequence: how do you find the prisoner?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "A creature unprepared, unmeet for death;\n",
      "And to transport him in the mind he is\n",
      "Wfvfu\tvu\tvt\n",
      "\n",
      "iter:16799/20000 loss:1.6228361123800277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence:  your time. Proceed.\n",
      "\n",
      "ISABELLA:\n",
      "I went\n",
      "To this pernicious caitiff deputy,--\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "That's somewhat madly spoken.\n",
      "\n",
      "ISABu\tst\tuiu\t\t\n",
      "\n",
      "iter:16999/20000 loss:1.6014473128318787\n",
      "generated sequence: ray, what nobleman is that\n",
      "That with the king here resteth in his tent?\n",
      "\n",
      "First Watchman:\n",
      "'Tis the Lord Hastings, the king's chie\to\t\tubfoiu\n",
      "\n",
      "iter:17199/20000 loss:1.594647770524025\n",
      "generated sequence: tiger's heart wrapt in a woman's hide!\n",
      "How couldst thou drain the life-blood of the child,\n",
      "To bid the father wipe his eyes withaio\t\t\tt\tuf\t\n",
      "\n",
      "iter:17399/20000 loss:1.6286761271953583\n",
      "generated sequence: ee something more than man\n",
      "And after that trust to thee.\n",
      "\n",
      "CAMILLO:\n",
      "Have you thought on\n",
      "A place whereto you'll go?\n",
      "\n",
      "FLORIZEL:\n",
      "Not\t\tu\t\tf\t\tft\n",
      "\n",
      "iter:17599/20000 loss:1.615428059697151\n",
      "generated sequence: ness, the life of Rome!\n",
      "Call all your tribes together, praise the gods,\n",
      "And make triumphant fires; strew flowers before them:\n",
      "Une\t\t\t\tuif\tu\n",
      "\n",
      "iter:17799/20000 loss:1.6064280396699906\n",
      "generated sequence: NTIO:\n",
      "Sirrah, come hither: 'tis no time to jest,\n",
      "And therefore frame your manners to the time.\n",
      "N\to\t\tfellow Tranio here, to save \ti\t;\n",
      "\n",
      "iter:17999/20000 loss:1.596231901049614\n",
      "generated sequence: r of his friends:\n",
      "To royalize his blood I spilt mine own.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Yea, and much better blood than his or thine.\n",
      "\n",
      "GLOUCE\tuvpujt\tup\n",
      "\n",
      "iter:18199/20000 loss:1.6056614482402802\n",
      "generated sequence: n say amen?\n",
      "Am I both priest and clerk? well then, amen.\n",
      "God save the king! although I be not he;\n",
      "And yet, amen, if heaven do thfu\tu\tuufqf\n",
      "\n",
      "iter:18399/20000 loss:1.5905084538459777\n",
      "generated sequence: IUS:\n",
      "A hundred thousand welcomes. I could weep\n",
      "And I could laugh, I am light and heavy. Welcome.\n",
      "Bouf\t\te begin at very root on'sOFB\n",
      "\n",
      "iter:18599/20000 loss:1.6011533731222152\n",
      "generated sequence:  of my lambs.\n",
      "But that still use of grief makes wild grief tame,\n",
      "My tongue should to thy ears not name my boys\n",
      "Till that my nailux\tuf\tu\tuf\n",
      "\n",
      "iter:18799/20000 loss:1.5891724556684494\n",
      "generated sequence: ught.\n",
      "\n",
      "First Citizen:\n",
      "He shall well know\n",
      "The noble tribunes are the people's mouths,\n",
      "And we their hands.\n",
      "\n",
      "Citizens:\n",
      "ms\tshall, susifi\n",
      "\n",
      "iter:18999/20000 loss:1.5982294529676437\n",
      "generated sequence: hath set a blot upon my pride.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Comfort, my liege; remember who you are.\n",
      "\n",
      "KING RICHARD II:\n",
      "I had forgot myself;fsifu\t\tius\n",
      "\n",
      "iter:19199/20000 loss:1.6108232468366623\n",
      "generated sequence: CIO:\n",
      "Why, 'tis not amiss, Pompey. Farewell: go, say I\n",
      "sent thee thither. For debt, Pompey? or how?\n",
      "\n",
      "ELBOW:\n",
      "if\t\tueing a bawd, forB\t;\n",
      "\n",
      "iter:19399/20000 loss:1.5644733726978302\n",
      "generated sequence: ords and threats\n",
      "Shall be the war that Henry means to use.\n",
      "Thou factious Duke of York, descend my throne,\n",
      "and kneel for grace an\tff\tuuhfu\t\n",
      "\n",
      "iter:19599/20000 loss:1.591207286119461\n",
      "generated sequence: :\n",
      "Is this your speeding? nay, then, good night our part!\n",
      "\n",
      "PETRUCHIO:\n",
      "Be patient, gentlemen; I choose her for myself:\n",
      "O\tu\t\tu\tund \n",
      "\n",
      "iter:19799/20000 loss:1.5845177918672562\n",
      "generated sequence: And take our friendly senators by the hands;\n",
      "Who now are here, taking their leaves of me,\n",
      "Who am prepared against your territoriSh\tu\too\tug\n",
      "\n",
      "iter:19999/20000 loss:1.5930415397882463\n",
      "generated sequence: ue below the city; and from thence,\n",
      "By cold gradation and well-balanced form,\n",
      "We shall proceed with Angelo.\n",
      "\n",
      "Provost:\n",
      "Here is thtsufsbsju\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,target,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ng spawn how can he flatter--\\nThat's thousand to one good one--when you now see\\nHe had rather venture all his limbs for honour\\nTe\\tu\\tfojeubsjuuoeubsufbo\\t\\tsfiiXibo\\t\\t\\tu\\tbst\\toe\\tu\\tsusesu\\tss\\tusesiijbseu\\tstuesju\\tssXFsubo\\tufo\\tbsfufse\\ttfsuobbubo\\tuboff\\tufsfubsestfXi\\tu\\tuseo\\t\\tofo\\t\\te\\t\\tof\\tsoeuufsbbiboeuuu\\tuof\\tue\\tu\\tuf\\tf\\tf\\tuffu\\tf\\tfbboof\\t\\tuf\\t\\t\\tfo\\tuffiOf\\toeu\\tseuofs\\tsf\\tu\\tsf\\teoo\\toeu\\toessu\\tsfs\\tof\\tf\\tsibu\\tu\\tf\\teuueseuu\\tuuesufe\\t\\t\\tsfooboe\\t\\t\\t\\tu\\tesu\\t\\tu\\tu\\tsususu\\tss\\tususooeesuu\\tsuuuseu\\tssbpsue\\t\\tuf\\t\\tesfufsu\\tufsu\\teeue\\t\\tue\\tff\\tufsfuesusufbo\\tu\\tusu\\t\\t\\t\\tf\\t\\t\\tu\\t\\t\\tf\\ts\\tuuufseeoe\\tuuuu\\tu\\tf\\tuu\\tu\\tuf\\tf\\tf\\tuffu\\tf\\tfee\\t\\tf\\t\\tuf\\t\\t\\tf\\t\\tuffosf\\t\\tuu\\tsuu\\tfs\\tsf\\tu\\tsf\\tu\\t\\t\\t\\tuu\\t\\tussu\\tsfs\\t\\tf\\tf\\tsoeu\\tu\\tf\\tuuuusuuu\\tuuusufu\\t\\t\\tsf\\t\\te\\tu\\t\\t\\t\\tu\\tusu\\t\\tu\\tu\\tsususu\\tss\\tusus\\t\\tuusuu\\tsuuusuu\\tssefsuu\\t\\tuf\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In attempting to printing the output of the current model, the main change was for the model to pass in the input twice,since the target gave away the answers. This prevented the model from generalizing to other input and thus had bad behavior in printing words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
