{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='W', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:4.040567826032639\n",
      "generated sequence:  in his nonage council under him,\n",
      "And in his full and ripen'd years himself,\n",
      "No doubt, shall then and till then govern well.\n",
      "\n",
      "Fi\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:399/20000 loss:3.593242596387863\n",
      "generated sequence: \n",
      "To tell, he longs to see his son, were strong:\n",
      "But let him say so then, and let him go;\n",
      "But let him swear so, and he shall not \t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:599/20000 loss:3.4805766093730925\n",
      "generated sequence: those physicians that first wounded thee:\n",
      "A thousand flatterers sit within thy crown,\n",
      "Whose compass is no bigger than thy head;\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:799/20000 loss:3.3886917889118195\n",
      "generated sequence: .\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Good aunt, stand up.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "I do not sue to stand;\n",
      "Pardon is all the suit I have in hand.\n",
      "\n",
      "HENR\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:999/20000 loss:3.350062971115112\n",
      "generated sequence:  how the bear tore out his\n",
      "shoulder-bone; how he cried to me for help and said\n",
      "his name was Antigonus, a nobleman. But to make a\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:1199/20000 loss:3.3073685252666474\n",
      "generated sequence: o, we are the grains:\n",
      "You are the musty chaff; and you are smelt\n",
      "Above the moon: we must be burnt for you.\n",
      "\n",
      "SICINIUS:\n",
      "Nay, pray,\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:1399/20000 loss:3.32357390165329\n",
      "generated sequence: as this, that was so full of his ropery?\n",
      "\n",
      "ROMEO:\n",
      "A gentleman, nurse, that loves to hear himself talk,\n",
      "and will speak more in a m\t\tu\t\t\t\t\tu\t\n",
      "\n",
      "iter:1599/20000 loss:3.277175406217575\n",
      "generated sequence: e fowl of season: shall we serve heaven\n",
      "With less respect than we do minister\n",
      "To our gross selves? Good, good my lord, bethink y\tu\t\t\t\tu\t\tu\n",
      "\n",
      "iter:1799/20000 loss:3.236892329454422\n",
      "generated sequence: n R.\n",
      "\n",
      "Nurse:\n",
      "Ah. mocker! that's the dog's name; R is for\n",
      "the--No; I know it begins with some other\n",
      "letter:--and she hath the pre\tu\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:1999/20000 loss:3.232560080289841\n",
      "generated sequence: \n",
      "\n",
      "NORFOLK:\n",
      "I go, my lord.\n",
      "\n",
      "KING RICHARD III:\n",
      "Stir with the lark to-morrow, gentle Norfolk.\n",
      "\n",
      "NORFOLK:\n",
      "I warrant you, my lord.\n",
      "\n",
      "KI\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:2199/20000 loss:3.1712913370132445\n",
      "generated sequence: p these cares on me?\n",
      "I am unfit for state and majesty;\n",
      "I do beseech you, take it not amiss;\n",
      "I cannot nor I will not yield to you\tu\tf\t\t\tu\t\t\n",
      "\n",
      "iter:2399/20000 loss:3.1757770681381228\n",
      "generated sequence:  of bitter words let's smother\n",
      "My damned son, which thy two sweet sons smother'd.\n",
      "I hear his drum: be copious in exclaims.\n",
      "\n",
      "KINGu\t\tu\tf\t\t\t\t\n",
      "\n",
      "iter:2599/20000 loss:3.1185067892074585\n",
      "generated sequence: If I did stay to look on his intents.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Stay, then; I'll go alone. Fear comes upon me:\n",
      "O, much I fear some ill un\t\tu\tu\tf\tu\t\n",
      "\n",
      "iter:2799/20000 loss:3.1262333846092223\n",
      "generated sequence: ord, bethink you;\n",
      "Who is it that hath died for this offence?\n",
      "There's many have committed it.\n",
      "\n",
      "LUCIO:\n",
      "\n",
      "ANGELO:\n",
      "The law hath not b\t\t\t\tu\t\tiff\n",
      "\n",
      "iter:2999/20000 loss:3.1279947793483736\n",
      "generated sequence: the English crown.\n",
      "\n",
      "KING HENRY VI:\n",
      "My lords, look where the sturdy rebel sits,\n",
      "Even in the chair of state: belike he means,\n",
      "Backif\tu\t\t\t\to\t\n",
      "\n",
      "iter:3199/20000 loss:3.070069546699524\n",
      "generated sequence: way.\n",
      "\n",
      "A Patrician:\n",
      "This man has marr'd his fortune.\n",
      "\n",
      "MENENIUS:\n",
      "His nature is too noble for the world:\n",
      "\t\t\tu\told not flatter Neptu\to\t\n",
      "\n",
      "iter:3399/20000 loss:3.0520107090473174\n",
      "generated sequence:  makes the maid to answer 'Whoop, do me\n",
      "no harm, good man;' puts him off, slights him, with\n",
      "'Whoop, do me no harm, good man.'\n",
      "\n",
      "Pufo\t\t\tuif\t\n",
      "\n",
      "iter:3599/20000 loss:3.027102952003479\n",
      "generated sequence: to crush? Why, had your bodies\n",
      "No heart among you? or had you tongues to cry\n",
      "Against the rectorship of judgment?\n",
      "\n",
      "SICINIUS:\n",
      "Havei\tuf\t\t\tf\tu\n",
      "\n",
      "iter:3799/20000 loss:3.0245833027362825\n",
      "generated sequence: .\n",
      "\n",
      "LUCIO:\n",
      "If could speak so wisely under an arrest, I would\n",
      "send for certain of my creditors: and yet, to say\n",
      "\t\t\t\t\t\tuth, I had a\n",
      "\n",
      "iter:3999/20000 loss:3.0160361170768737\n",
      "generated sequence:  your wedding-day:\n",
      "First were we sad, fearing you would not come;\n",
      "Now sadder, that you come so unprovided.\n",
      "Fie, doff this habit,u\t\t\t\tu\t\t\t\t\n",
      "\n",
      "iter:4199/20000 loss:2.9766268944740295\n",
      "generated sequence: y see my shadow as I pass.\n",
      "\n",
      "RIVERS:\n",
      "Have patience, madam: there's no doubt his majesty\n",
      "Will soon recover his accustom'd health.\n",
      "\tu\t\t\tuf\tu\t\n",
      "\n",
      "iter:4399/20000 loss:2.964600775241852\n",
      "generated sequence: mberland,\n",
      "Whose warlike ears could never brook retreat,\n",
      "Cheer'd up the drooping army; and himself,\n",
      "Lord Clifford and Lord Staffof\t\t\t\toe\t\t\n",
      "\n",
      "iter:4599/20000 loss:2.9654839301109313\n",
      "generated sequence: t.\n",
      "\n",
      "MERCUTIO:\n",
      "And so did I.\n",
      "\n",
      "ROMEO:\n",
      "Well, what was yours?\n",
      "\n",
      "MERCUTIO:\n",
      "That dreamers often lie.\n",
      "\n",
      "ROMEO:\n",
      "\t\t\t\t\t\t asleep, while they i\n",
      "\n",
      "iter:4799/20000 loss:2.9189567089080812\n",
      "generated sequence: \n",
      "the provost.\n",
      "\n",
      "ESCALUS:\n",
      "In very good time: speak not you to him till we\n",
      "call upon you.\n",
      "\n",
      "LUCIO:\n",
      "Mum.\n",
      "\n",
      "ESCALUS:\n",
      "if\tu\t\tvfv: did you\n",
      "\n",
      "iter:4999/20000 loss:2.9323556196689604\n",
      "generated sequence:  his fear, I'll be thy death.\n",
      "King Henry and the prince his son are gone:\n",
      "Clarence, thy turn is next, and then the rest,\n",
      "Countinufo\tu\t\to\t\t\n",
      "\n",
      "iter:5199/20000 loss:2.904810392856598\n",
      "generated sequence: ay the lords you talk of are beheaded.\n",
      "\n",
      "LORD STANLEY:\n",
      "They, for their truth, might better wear their heads\n",
      "Than some that have ao\tuif\tu\tv\t\n",
      "\n",
      "iter:5399/20000 loss:2.869005461931229\n",
      "generated sequence: ears of my son's exile:\n",
      "But little vantage shall I reap thereby;\n",
      "For, ere the six years that he hath to spend\n",
      "Can change their m\to\t\tuv\tuf\t\n",
      "\n",
      "iter:5599/20000 loss:2.877842974662781\n",
      "generated sequence: n thy head;\n",
      "And yet, incaged in so small a verge,\n",
      "The waste is no whit lesser than thy land.\n",
      "O, had thy grandsire with a propheteuif\tuf\to\t\n",
      "\n",
      "iter:5799/20000 loss:2.869037605524063\n",
      "generated sequence: e.\n",
      "\n",
      "Nurse:\n",
      "Faith, here it is.\n",
      "Romeo is banish'd; and all the world to nothing,\n",
      "That he dares ne'er come back to challenge you;\n",
      "\t\t\t\t\t\t\n",
      "\n",
      "iter:5999/20000 loss:2.855986260175705\n",
      "generated sequence: worn\n",
      "These dangerous unsafe lunes i' the king,\n",
      "beshrew them!\n",
      "He must be told on't, and he shall: the office\n",
      "\tf\t\t\tes a woman best\tv\te\n",
      "\n",
      "iter:6199/20000 loss:2.8453465521335604\n",
      "generated sequence:  blades,\n",
      "Of healths five-fathom deep; and then anon\n",
      "Drums in his ear, at which he starts and wakes,\n",
      "\tnd being thus frighted sweauf\to\t\t\t\t\n",
      "\n",
      "iter:6399/20000 loss:2.843645486831665\n",
      "generated sequence: ry those vapours up,\n",
      "For every cloud engenders not a storm.\n",
      "\n",
      "GLOUCESTER:\n",
      "The queen is valued thirty thousand strong,\n",
      "And Somerse\t\tuifv\t\tuf\n",
      "\n",
      "iter:6599/20000 loss:2.8454973912239074\n",
      "generated sequence:  in heaven forbid\n",
      "We should infringe the holy privilege\n",
      "Of blessed sanctuary! not for all this land\n",
      "Would I be guilty of so deepuoeuf\tof\te\n",
      "\n",
      "iter:6799/20000 loss:2.831062717437744\n",
      "generated sequence: ealing away from his father with his\n",
      "clog at his heels: if I thought it were a piece of\n",
      "honesty to acquaint the king withal, I w\to\toe\tuo\to\n",
      "\n",
      "iter:6999/20000 loss:2.8049722826480865\n",
      "generated sequence: e.\n",
      "\n",
      "SEBASTIAN:\n",
      "No marrying 'mong his subjects?\n",
      "\n",
      "ANTONIO:\n",
      "None, man; all idle: whores and knaves.\n",
      "\n",
      "GONZALO:\n",
      "p\t\t\tpid with such per\t\n",
      "\n",
      "iter:7199/20000 loss:2.826730567216873\n",
      "generated sequence: .\n",
      "\n",
      "POMPEY:\n",
      "I do desire to learn, sir: and I hope, if you have\n",
      "occasion to use me for your own turn, you shall find\n",
      "\t\t\t\t\tpe; for \n",
      "\n",
      "iter:7399/20000 loss:2.7958331263065337\n",
      "generated sequence: e no commodity:\n",
      "The crown and comfort of my life, your favour,\n",
      "I do give lost; for I do feel it gone,\n",
      "But know not how it went. \tuevuivffv\n",
      "\n",
      "iter:7599/20000 loss:2.7980824446678163\n",
      "generated sequence: n window of the east,\n",
      "A troubled mind drave me to walk abroad;\n",
      "Where, underneath the grove of sycamore\n",
      "That westward rooteth froeu\toe\tv\tuv\n",
      "\n",
      "iter:7799/20000 loss:2.790161432027817\n",
      "generated sequence: hat's not so.\n",
      "\n",
      "MERCUTIO:\n",
      "I mean, sir, in delay\n",
      "We waste our lights in vain, like lamps by day.\n",
      "Take our good meaning, for our jufoi\t\tueviu\n",
      "\n",
      "iter:7999/20000 loss:2.778080267906189\n",
      "generated sequence:  tribunes,\n",
      "It is the humane way: the other course\n",
      "Will prove too bloody, and the end of it\n",
      "Unknown to the beginning.\n",
      "\n",
      "SICINIUS:\n",
      "ui\tofse\t\t\t\n",
      "\n",
      "iter:8199/20000 loss:2.7749236953258514\n",
      "generated sequence:  overlook the town of York.\n",
      "3 KING HENRY VI\n",
      "\n",
      "EDWARD:\n",
      "I wonder how our princely father 'scaped,\n",
      "Or whether he be 'scaped away or uvf\t\t\tvvfu\n",
      "\n",
      "iter:8399/20000 loss:2.772070302963257\n",
      "generated sequence: f thee\n",
      "As thou hast made me by my dear lord's death!\n",
      "Lo, ere I can repeat this curse again,\n",
      "\t\tun in so short a space, my woman's\tuif\t\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:2.759845929145813\n",
      "generated sequence: rable load,\n",
      "If honour may be shrouded in a hearse,\n",
      "Whilst I awhile obsequiously lament\n",
      "The untimely fall of virtuous Lancaster.\n",
      "\tof\t\tu\tvo\t\n",
      "\n",
      "iter:8799/20000 loss:2.7410199284553527\n",
      "generated sequence: t thou thy oaths,\n",
      "Though they would swear down each particular saint,\n",
      "Were testimonies against his worth and credit\n",
      "That's seal'iuifvsuif\t\n",
      "\n",
      "iter:8999/20000 loss:2.7298953998088837\n",
      "generated sequence: monstrance of my hidden power\n",
      "Than let him so be lost. O most kind maid,\n",
      "It was the swift celerity of his death,\n",
      "Which I did thifve\ti\toei\t\n",
      "\n",
      "iter:9199/20000 loss:2.7302746200561523\n",
      "generated sequence: order else have died,\n",
      "I have reserved alive.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What's he?\n",
      "\n",
      "Provost:\n",
      "His name is Barnardine.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I wov\t\t\t\tu\t\t\t\t\n",
      "\n",
      "iter:9399/20000 loss:2.746117025613785\n",
      "generated sequence: ime,\n",
      "For what he did before Corioli, call him,\n",
      "With all the applause and clamour of the host,\n",
      "CAIUS MARCIUS CORIOLANUS! Bear\n",
      "\tv\tu\t\t\t\n",
      "\n",
      "iter:9599/20000 loss:2.7340470802783967\n",
      "generated sequence: ks to thee?\n",
      "Dark cloudy death o'ershades his beams of life,\n",
      "And he nor sees nor hears us what we say.\n",
      "\n",
      "RICHARD:\n",
      "O, would he did!\t\tuivuif\t\t\n",
      "\n",
      "iter:9799/20000 loss:2.711579203605652\n",
      "generated sequence:  a bigger.\n",
      "\n",
      "KATHARINA:\n",
      "I'll have no bigger: this doth fit the time,\n",
      "And gentlewomen wear such caps as these\n",
      "\n",
      "PETRUCHIO:\n",
      "When youuoufoff\t\t\n",
      "\n",
      "iter:9999/20000 loss:2.6977099668979645\n",
      "generated sequence: I, sir; and now 'tis plotted.\n",
      "\n",
      "LUCENTIO:\n",
      "I have it, Tranio.\n",
      "\n",
      "TRANIO:\n",
      "Master, for my hand,\n",
      "Both our inventions meet and jump in o\t\tu\to\t\tuoe\n",
      "\n",
      "iter:10199/20000 loss:2.6870457530021667\n",
      "generated sequence: to ask it kindly.\n",
      "\n",
      "CORIOLANUS:\n",
      "Kindly! Sir, I pray, let me ha't: I have wounds to\n",
      "show you, which shall be yours in private. Youivuo\t\tuoiu\n",
      "\n",
      "iter:10399/20000 loss:2.7158052468299867\n",
      "generated sequence: Destruction straight shall dog them at the heels.\n",
      "Good uncle, help to order several powers\n",
      "To Oxford, or where'er these traitors\t\t\ti\tsiitv\n",
      "\n",
      "iter:10599/20000 loss:2.6817573487758635\n",
      "generated sequence: ne\n",
      "Since I heard thence; these are the words: I think\n",
      "I have the letter here; yes, here it is.\n",
      "ptei\tu\tave press'd a power, but ie\t\n",
      "\n",
      "iter:10799/20000 loss:2.687703312635422\n",
      "generated sequence: 'd in our aim, which was\n",
      "To take in many towns ere almost Rome\n",
      "Should know we were afoot.\n",
      "\n",
      "Second Senator:\n",
      "Noble Aufidius,\n",
      "Take e\tuteuvs\tu\n",
      "\n",
      "iter:10999/20000 loss:2.691671085357666\n",
      "generated sequence: throw; and in his praise\n",
      "Have almost stamp'd the leasing: therefore, fellow,\n",
      "I must have leave to pass.\n",
      "\n",
      "First Senator:\n",
      "Faith, sif\tv\t\tuoe\t\n",
      "\n",
      "iter:11199/20000 loss:2.6916022753715514\n",
      "generated sequence: atue of her mother.\n",
      "\n",
      "PAULINA:\n",
      "As she lived peerless,\n",
      "So her dead likeness, I do well believe,\n",
      "Excels whatever yet you look'd upoo\ts\tuv\tuf\t\n",
      "\n",
      "iter:11399/20000 loss:2.6811612105369567\n",
      "generated sequence: es or his usual pain?\n",
      "Then give me leave to read philosophy,\n",
      "And while I pause, serve in your harmony.\n",
      "\n",
      "HORTENSIO:\n",
      "Sirrah, I wil\t\tuv\tuft\tu\n",
      "\n",
      "iter:11599/20000 loss:2.674608597755432\n",
      "generated sequence: heart, not on my head;\n",
      "Not decked with diamonds and Indian stones,\n",
      "Nor to be seen: my crown is called content:\n",
      "A crown it is thaf\to\t\t\tuev\t\n",
      "\n",
      "iter:11799/20000 loss:2.667014892101288\n",
      "generated sequence: at for what contains it. Boy! O slave!\n",
      "Pardon me, lords, 'tis the first time that ever\n",
      "I was forced to scold. Your judgments, myo\tu\tv\tu\tfo\n",
      "\n",
      "iter:11999/20000 loss:2.693432494401932\n",
      "generated sequence: t repose and rest\n",
      "Come to thy heart as that within my breast!\n",
      "\n",
      "ROMEO:\n",
      "O, wilt thou leave me so unsatisfied?\n",
      "\n",
      "JULIET:\n",
      "What satisfiu\t\tbv\t\tuo\n",
      "\n",
      "iter:12199/20000 loss:2.6640332067012786\n",
      "generated sequence:  and succeed thy weakness.\n",
      "\n",
      "ANGELO:\n",
      "Nay, women are frail too.\n",
      "\n",
      "ISABELLA:\n",
      "Ay, as the glasses where they view themselves;\n",
      "Which aruoe\tu\tsii\t\n",
      "\n",
      "iter:12399/20000 loss:2.6458830893039704\n",
      "generated sequence: reason;\n",
      "If not, my senses, better pleased with madness,\n",
      "Do bid it welcome.\n",
      "\n",
      "CAMILLO:\n",
      "This is desperate, sir.\n",
      "\n",
      "FLORIZEL:\n",
      "\t\t call \t\to\tve\t\n",
      "\n",
      "iter:12599/20000 loss:2.6515505933761596\n",
      "generated sequence: sty and honour from\n",
      "The access of gentle visitors!\n",
      "Is't lawful, pray you,\n",
      "To see her women? any of them? Emilia?\n",
      "\n",
      "Gaoler:\n",
      "So ple\t\t\tuoe\tufv\n",
      "\n",
      "iter:12799/20000 loss:2.656005809307098\n",
      "generated sequence: ve thousand fighting men!\n",
      "To-day, to-day, unhappy day, too late,\n",
      "O'erthrows thy joys, friends, fortune and thy state:\n",
      "For all thf\tuifvs\toe\n",
      "\n",
      "iter:12999/20000 loss:2.661592324972153\n",
      "generated sequence: aze where you will you shall not house with me:\n",
      "Look to't, think on't, I do not use to jest.\n",
      "Thursday is near; lay hand on heartof\tu\tf\t\t\tu\n",
      "\n",
      "iter:13199/20000 loss:2.64657550573349\n",
      "generated sequence:  that here thou take an oath\n",
      "To cease this civil war, and, whilst I live,\n",
      "To honour me as thy king and sovereign,\n",
      "And neither byuifo\tuf\t\t\t\n",
      "\n",
      "iter:13399/20000 loss:2.640406686067581\n",
      "generated sequence: night: and then I loved thee\n",
      "And show'd thee all the qualities o' the isle,\n",
      "The fresh springs, brine-pits, barren place and fertetffi\tuoe\t\n",
      "\n",
      "iter:13599/20000 loss:2.6552549242973327\n",
      "generated sequence: country\n",
      "As he began, and not unknit himself\n",
      "The noble knot he made.\n",
      "\n",
      "BRUTUS:\n",
      "I would he had.\n",
      "\n",
      "VOLUMNIA:\n",
      "o\t would he had'! 'Twas ivse\t\t\t\n",
      "\n",
      "iter:13799/20000 loss:2.6319411039352416\n",
      "generated sequence: and give thee half,\n",
      "It is too little, helping him to all;\n",
      "And he shall think that thou, which know'st the way\n",
      "To plant unrightfuo\t\tu\ttf\tui\n",
      "\n",
      "iter:13999/20000 loss:2.6361854135990144\n",
      "generated sequence:  his wife;\n",
      "Who, as I hear, mean to solicit him\n",
      "For mercy to his country. Therefore, let's hence,\n",
      "And with our fair entreaties hauft\tuit\t\t\t\n",
      "\n",
      "iter:14199/20000 loss:2.6451404452323914\n",
      "generated sequence: one to Friar Laurence?\n",
      "\n",
      "Nurse:\n",
      "Ay, forsooth.\n",
      "\n",
      "CAPULET:\n",
      "Well, he may chance to do some good on her:\n",
      "A peevish self-will'd harlotrve\tu\tvu\t\tt\n",
      "\n",
      "iter:14399/20000 loss:2.6345012724399566\n",
      "generated sequence: ow away on slaves,\n",
      "Wooing poor craftsmen with the craft of smiles\n",
      "And patient underbearing of his fortune,\n",
      "As 'twere to banish tviuoio\tuve\n",
      "\n",
      "iter:14599/20000 loss:2.6352791714668276\n",
      "generated sequence: ruchio, will you go with us,\n",
      "Or shall I send my daughter Kate to you?\n",
      "\n",
      "PETRUCHIO:\n",
      "I pray you do.\n",
      "I will attend her here,\n",
      "And woo\tsi\ttv\tu\tt\n",
      "\n",
      "iter:14799/20000 loss:2.6144173181056978\n",
      "generated sequence:  still, which will have matter to\n",
      "rehearse, though credit be asleep and not an ear\n",
      "open. He was torn to pieces with a bear: thisu\t\tt\t\t\tu\tf\n",
      "\n",
      "iter:14999/20000 loss:2.615440263748169\n",
      "generated sequence: all temperance. But leave we him to\n",
      "his events, with a prayer they may prove prosperous;\n",
      "and let me desire to know how you find o\t\tu\t\tfb\t\t\n",
      "\n",
      "iter:15199/20000 loss:2.6228599429130552\n",
      "generated sequence: hat art\n",
      "Which you say adds to nature, is an art\n",
      "That nature makes. You see, sweet maid, we marry\n",
      "ifgentler scion to the wildest fo\tuo\t\t\n",
      "\n",
      "iter:15399/20000 loss:2.6315439903736113\n",
      "generated sequence: ll I see more joy!\n",
      "\n",
      "RICHARD:\n",
      "I cannot weep; for all my body's moisture\n",
      "Scarce serves to quench my furnace-burning heart:\n",
      "Nor can\t\tu\tu\t\t\tuf\n",
      "\n",
      "iter:15599/20000 loss:2.63151287317276\n",
      "generated sequence: ed your powers.\n",
      "\n",
      "CORIOLANUS:\n",
      "Traitor! how now!\n",
      "\n",
      "AUFIDIUS:\n",
      "Ay, traitor, Marcius!\n",
      "\n",
      "CORIOLANUS:\n",
      "Marcius!\n",
      "\n",
      "AUFIDIUS:\n",
      "Ay, Marcius, Ca\t\tu\tvs\tusv\n",
      "\n",
      "iter:15799/20000 loss:2.6060206651687623\n",
      "generated sequence: uy for our sheep-shearing feast? Three pound\n",
      "of sugar, five pound of currants, rice,--what will\n",
      "this sister of mine do with rices\tu\tv\tuvs\t\n",
      "\n",
      "iter:15999/20000 loss:2.5985588812828064\n",
      "generated sequence:  ladies like a crow-keeper;\n",
      "Nor no without-book prologue, faintly spoke\n",
      "After the prompter, for our entrance:\n",
      "But let them measuumo\tt\t\tumt\n",
      "\n",
      "iter:16199/20000 loss:2.605560448169708\n",
      "generated sequence: e,\n",
      "Upon the part o' the people, in whose power\n",
      "We were elected theirs, Marcius is worthy\n",
      "Of present death.\n",
      "\n",
      "SICINIUS:\n",
      "Tfveu\tfre \t\t\n",
      "\n",
      "iter:16399/20000 loss:2.58801282286644\n",
      "generated sequence: \n",
      "\n",
      "EXETER:\n",
      "Away! for vengeance comes along with them:\n",
      "Nay, stay not to expostulate, make speed;\n",
      "O\tOiOJ\t come after: I'll away bef\n",
      "\n",
      "iter:16599/20000 loss:2.6064898002147676\n",
      "generated sequence: t rise, unless your highness grant.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Then speak at once what is it thou demand'st.\n",
      "\n",
      "DORSET:\n",
      "The forfeit, soverei\tu\tt\t\t\tus\t\n",
      "\n",
      "iter:16799/20000 loss:2.5998373568058013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: e shame most patiently.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I'll teach you how you shall arraign your conscience,\n",
      "And try your penitence, if it be \tu\tfof\tuf\t\n",
      "\n",
      "iter:16999/20000 loss:2.61076474905014\n",
      "generated sequence: uthful blood,\n",
      "She would be as swift in motion as a ball;\n",
      "My words would bandy her to my sweet love,\n",
      "And his to me:\n",
      "But old folkss\t\t\ts\tuf\t\t\n",
      "\n",
      "iter:17199/20000 loss:2.6033183574676513\n",
      "generated sequence: I live she will be only mine.\n",
      "\n",
      "TRANIO:\n",
      "That 'only' came well in. Sir, list to me:\n",
      "I am my father's heir and only son:\n",
      "If I may h\tu\ttf\tu\t\t\t\n",
      "\n",
      "iter:17399/20000 loss:2.6104770457744597\n",
      "generated sequence: ept,\n",
      "And mountainous error be too highly heapt\n",
      "For truth to o'er-peer. Rather than fool it so,\n",
      "o\t\tufhe high office and the honou\tb\t\t\n",
      "\n",
      "iter:17599/20000 loss:2.578788591623306\n",
      "generated sequence: , young sister, but one word.\n",
      "\n",
      "ISABELLA:\n",
      "What is your will?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Might you dispense with your leisure, I would by an\tu\t\ts\tfu\tt\n",
      "\n",
      "iter:17799/20000 loss:2.5845780193805696\n",
      "generated sequence: oo hot to do somebody good,\n",
      "That is too cold in thinking of it now.\n",
      "Marry, as for Clarence, he is well repaid,\n",
      "He is frank'd up \t\tu\t\t\tu\t\tu\n",
      "\n",
      "iter:17999/20000 loss:2.5795539164543153\n",
      "generated sequence: re for as much.\n",
      "\n",
      "LUCENTIO:\n",
      "Preposterous ass, that never read so far\n",
      "To know the cause why music was ordain'd!\n",
      "Was it not to refr\t\tu\t\t\tuo\tu\n",
      "\n",
      "iter:18199/20000 loss:2.5818535220623016\n",
      "generated sequence: first head and spring.\n",
      "Further I say and further will maintain\n",
      "Upon his bad life to make all this good,\n",
      "That he did plot the Duk\tt\t\t\tu\t\to\t\n",
      "\n",
      "iter:18399/20000 loss:2.5775728642940523\n",
      "generated sequence: s promised them against the feast; but they come\n",
      "not too late now.\n",
      "\n",
      "DORCAS:\n",
      "He hath promised you more than that, or there be lia\tub\t\tft\t\t\t\n",
      "\n",
      "iter:18599/20000 loss:2.5806342470645904\n",
      "generated sequence: hall be the messenger.\n",
      "\n",
      "EXETER:\n",
      "And I, I hope, shall reconcile them all.\n",
      "3 KING HENRY VI\n",
      "\n",
      "RICHARD:\n",
      "Brother, though I be youngestfo\t\tuf\tu\tf\n",
      "\n",
      "iter:18799/20000 loss:2.588528698682785\n",
      "generated sequence: He would not answer to: forbad all names;\n",
      "He was a kind of nothing, titleless,\n",
      "Till he had forged himself a name o' the fire\n",
      "Of p\tui\ts\t\tu\t\n",
      "\n",
      "iter:18999/20000 loss:2.576359283924103\n",
      "generated sequence:  scarce, they are seldom spent in vain,\n",
      "For they breathe truth that breathe their words in pain.\n",
      "He that no more must say is lisu\tio\ti\t\tu\t\n",
      "\n",
      "iter:19199/20000 loss:2.582018301486969\n",
      "generated sequence: ee lead on this preparation\n",
      "Whither 'tis bent: most likely 'tis for you:\n",
      "Consider of it.'\n",
      "\n",
      "First Senator:\n",
      "Our army's in the fiel\t\tu\t\to\tu\t\t\n",
      "\n",
      "iter:19399/20000 loss:2.5705630493164064\n",
      "generated sequence: s rest?\n",
      "\n",
      "CAPULET:\n",
      "What should it be, that they so shriek abroad?\n",
      "\n",
      "LADY CAPULET:\n",
      "The people in the street cry Romeo,\n",
      "Fome Juliet,\tu\t\t\t\t\n",
      "\n",
      "iter:19599/20000 loss:2.577041063308716\n",
      "generated sequence: \n",
      "CURTIS:\n",
      "They are.\n",
      "\n",
      "GRUMIO:\n",
      "Call them forth.\n",
      "\n",
      "CURTIS:\n",
      "Do you hear, ho? you must meet my master to\n",
      "countenance my mistress.\n",
      "\n",
      "GRUMJFTJiO;\tJi\n",
      "\n",
      "iter:19799/20000 loss:2.573848226070404\n",
      "generated sequence: d:\n",
      "I hope all's for the best.\n",
      "\n",
      "KING LEWIS XI:\n",
      "Warwick, what are thy news? and yours, fair queen?\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Mine, such as \t\tJ\tu\t\ts\tu\n",
      "\n",
      "iter:19999/20000 loss:2.581763200759888\n",
      "generated sequence:  thus he pass'd along.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Alack, poor Richard! where rode he the whilst?\n",
      "\n",
      "DUKE OF YORK:\n",
      "As in a theatre, the eyesu\tfs\tuf\tus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.ASGD(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,input,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'; for I have about me many parcels of charge.\\n\\nClown:\\nWhat hast here? ballads?\\n\\nMOPSA:\\nPray now, buy some: I love a ballad in pr\\tu\\t\\t\\tu\\tu\\tof\\tuof\\ts\\tuf\\tufo\\t\\tubo\\ti\\t\\t\\tu\\t\\tui\\to\\tf\\t\\r\\r\\rF\\t\\ti\\t\\t\\ri\\to\\tu\\to\\t\\tu\\t\\t\\t\\t\\rufo\\t\\to\\t\\t\\r\\r\\r\\t\\t\\t\\to\\t\\r\\t\\to\\tu\\t\\t\\t\\tuf\\t\\tu\\t\\t\\t\\t\\tu\\tu\\t\\tf\\tuoufo\\t\\to\\tuo\\tu\\t\\tu\\tuuu\\tu\\tu\\t\\tu\\t\\t\\tu\\tu\\t\\tu\\t\\t\\tuu\\t\\t\\tu\\tuuu\\tuu\\t\\tu\\tu\\tu\\r\\r\\rOuu\\tuu\\r\\tu\\tu\\tu\\tuu\\tuuuu\\r\\t\\t\\tuu\\tuu\\r\\r\\ruuuu\\tu\\ruu\\tu\\tuuuu\\t\\tuu\\tuuuuu\\tu\\tuu\\tu\\t\\t\\t\\t\\tuu\\tu\\t\\tu\\tuu\\tu\\t\\t\\tu\\tu\\tuu\\tuuu\\tu\\tuu\\tuuu\\t\\tuuu\\tu\\t\\t\\tu\\t\\tuu\\tu\\tu\\t\\r\\r\\rp\\t\\tu\\t\\t\\ru\\tu\\tu\\tu\\t\\tu\\t\\t\\t\\t\\ruuu\\t\\tu\\t\\t\\r\\r\\r\\t\\t\\t\\tu\\t\\r\\t\\tu\\tu\\t\\t\\t\\tuu\\t\\tu\\t\\t\\t\\t\\tu\\tu\\t\\tu\\tuuuuu\\t\\tu\\tuu\\tu\\t\\tu\\tuuu\\tu\\tu\\t\\tu\\t\\t\\tu\\tu\\t\\tu\\t\\t\\tuu\\t\\t\\tu\\tuuu\\tuu\\t\\tu\\tu\\tu\\r\\r\\r\\tuu\\tuu\\r\\tu\\tu\\tu\\tuu\\tuuuu\\r\\t\\t\\tuu\\tuu\\r\\r\\ruuuu\\tu\\ruu\\tu\\tuuuu\\t\\tuu\\tuuuuu\\tu\\tuu\\tu\\t\\t\\t\\t\\tuu\\tu\\t\\tu\\tuu\\tu\\t\\t\\tu\\tu\\tuu\\tuuu\\tu\\tuu\\tuuu\\t\\tuuu\\tu\\t\\t\\tu\\t\\tuu\\tu\\tu\\t\\r\\r\\ru\\t\\tu\\t\\t\\ru\\tu\\tu\\tu\\t\\tu\\t\\t\\t\\t\\ruuu\\t\\tu\\t\\t\\r\\r\\r\\t\\t\\t\\tu\\t\\r\\t'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "Follows the updated baseline, but uses ASGD optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
