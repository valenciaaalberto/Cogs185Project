{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='W', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:3.075556308031082\n",
      "generated sequence:  sweet friend,\n",
      "To strew him o'er and o'er!\n",
      "\n",
      "FLORIZEL:\n",
      "What, like a corse?\n",
      "\n",
      "PERDITA:\n",
      "No, like a bank for love to lie and play on;b\tf\t\tib\t\to\n",
      "\n",
      "iter:399/20000 loss:2.7251744556427\n",
      "generated sequence: acquaintance, and the drops\n",
      "That we have bled together. Coriolanus\n",
      "He would not answer to: forbad all names;\n",
      "He was a kind of noof\t\tooe\toe\n",
      "\n",
      "iter:599/20000 loss:2.6500955855846406\n",
      "generated sequence: he least.\n",
      "\n",
      "CLARENCE:\n",
      "That's a day longer than a wonder lasts.\n",
      "\n",
      "GLOUCESTER:\n",
      "By so much is the wonder in extremes.\n",
      "\n",
      "BING EDWARD IVf\tu\t\to\t\t\n",
      "\n",
      "iter:799/20000 loss:2.605051374435425\n",
      "generated sequence: spair not, madam.\n",
      "\n",
      "QUEEN:\n",
      "Who shall hinder me?\n",
      "I will despair, and be at enmity\n",
      "With cozening hope: he is a flatterer,\n",
      "A parasit\tfoofb\t\t\t\t\n",
      "\n",
      "iter:999/20000 loss:2.56330295920372\n",
      "generated sequence: ee hath left us royal fruit,\n",
      "Which, mellow'd by the stealing hours of time,\n",
      "Will well become the seat of majesty,\n",
      "And make, no d\t\tufo\tfu\t\t\n",
      "\n",
      "iter:1199/20000 loss:2.570627499818802\n",
      "generated sequence:  and tell her that Paris is the properer\n",
      "man; but, I'll warrant you, when I say so, she looks\n",
      "as pale as any clout in the versalbo\t\tb\t\t\t\tb\n",
      "\n",
      "iter:1399/20000 loss:2.52721351146698\n",
      "generated sequence: ope with him.\n",
      "\n",
      "CLIFFORD:\n",
      "Had thy brethren here, their lives and thine\n",
      "Were not revenge sufficient for me;\n",
      "No, if I digg'd up thy\tf\tu\to\tfuf\n",
      "\n",
      "iter:1599/20000 loss:2.5190547251701356\n",
      "generated sequence: ntenance, sir.\n",
      "Signior Baptista, you are happily met.\n",
      "Sir, this is the gentleman I told you of:\n",
      "I pray you stand good father to e\t\teoep\t\tb\n",
      "\n",
      "iter:1799/20000 loss:2.506820878982544\n",
      "generated sequence: ot so, not so; his life is parallel'd\n",
      "Even with the stroke and line of his great justice:\n",
      "He doth with holy abstinence subdue\n",
      "Th\t\tj\t\t\tj\t\t\t\n",
      "\n",
      "iter:1999/20000 loss:2.5046181786060333\n",
      "generated sequence:  amendment,\n",
      "Are come to play a pleasant comedy;\n",
      "For so your doctors hold it very meet,\n",
      "Seeing too much sadness hath congeal'd yopof\t\t\tf\t\t\t\n",
      "\n",
      "iter:2199/20000 loss:2.4935181832313535\n",
      "generated sequence: s all the suit I have in hand.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "I pardon him, as God shall pardon me.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "O happy vantage of a \tb\t\t\tb\t\t\tb\n",
      "\n",
      "iter:2399/20000 loss:2.486277494430542\n",
      "generated sequence: bt, my lord.\n",
      "\n",
      "KING RICHARD III:\n",
      "O Ratcliff, I fear, I fear,--\n",
      "\n",
      "RATCLIFF:\n",
      "Nay, good my lord, be not afraid of shadows.\n",
      "\n",
      "KING RICHf\t\tbf\tb\t\t\t\n",
      "\n",
      "iter:2599/20000 loss:2.48071901679039\n",
      "generated sequence: a house of tears.\n",
      "Now, sir, her father counts it dangerous\n",
      "That she doth give her sorrow so much sway,\n",
      "And in his wisdom hastes tp\t\t\t\t\tp\t\t\n",
      "\n",
      "iter:2799/20000 loss:2.4537154638767245\n",
      "generated sequence: \n",
      "Second Senator:\n",
      "The worthy fellow is our general: he's the rock, the\n",
      "oak not to be wind-shaken.\n",
      "\n",
      "CORIOLANUS:\n",
      "We will before theB;\tf\t\t\tp;\t\n",
      "\n",
      "iter:2999/20000 loss:2.4559395861625672\n",
      "generated sequence: rehearsed,\n",
      "That ever Katharina will be woo'd;\n",
      "Therefore this order hath Baptista ta'en,\n",
      "That none shall have access unto Bianca\n",
      "f\tf\tof\t\t\t\t\n",
      "\n",
      "iter:3199/20000 loss:2.458875625133514\n",
      "generated sequence: n an hour before his\n",
      "entering, that if any crave redress of injustice,\n",
      "they should exhibit their petitions in the street?\n",
      "\n",
      "ESCAL\tjo\tjfssfj\n",
      "\n",
      "iter:3399/20000 loss:2.4424503326416014\n",
      "generated sequence: t me live.\n",
      "\n",
      "CLIFFORD:\n",
      "In vain thou speak'st, poor boy; my father's blood\n",
      "Hath stopp'd the passage where thy words should enter.\n",
      "\tpf\tp\ttf\t\n",
      "\n",
      "iter:3599/20000 loss:2.430221700668335\n",
      "generated sequence:  it is!\n",
      "\n",
      "GRUMIO:\n",
      "O this woodcock, what an ass it is!\n",
      "\n",
      "PETRUCHIO:\n",
      "Peace, sirrah!\n",
      "\n",
      "HORTENSIO:\n",
      "JJ;mio, mum! God save you, Signior Gbt\tbt\t\n",
      "\n",
      "iter:3799/20000 loss:2.436901103258133\n",
      "generated sequence: S:\n",
      "Adieu, sir.\n",
      "\n",
      "FLORIZEL:\n",
      "O Perdita, what have we twain forgot!\n",
      "Pray you, a word.\n",
      "\n",
      "CAMILLO:\n",
      "\n",
      "FLORIZEL:\n",
      "Fortune speed us!\n",
      "JSft\ts\tb\n",
      "\n",
      "iter:3999/20000 loss:2.421204391717911\n",
      "generated sequence: gross is writ on Juliet.\n",
      "\n",
      "LUCIO:\n",
      "With child, perhaps?\n",
      "\n",
      "CLAUDIO:\n",
      "Unhappily, even so.\n",
      "And the new deputy now for the duke--\n",
      "Whetheifo\t\tuo\tu\t\n",
      "\n",
      "iter:4199/20000 loss:2.4034150004386903\n",
      "generated sequence: e\n",
      "Our tradesmen with in their shops and going\n",
      "About their functions friendly.\n",
      "\n",
      "BRUTUS:\n",
      "We stood to't in good time.\n",
      "Is this Menen\tJ;tjjijo\t\n",
      "\n",
      "iter:4399/20000 loss:2.403551449775696\n",
      "generated sequence: n him, his sons, his favourites and his friends.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "If I be not, heavens be revenged on me!\n",
      "\n",
      "CLIFFORD:\n",
      "The hope th\tiftf\tiftf\n",
      "\n",
      "iter:4599/20000 loss:2.4094091510772704\n",
      "generated sequence: \n",
      "The manage of my state; as at that time\n",
      "Through all the signories it was the first\n",
      "And Prospero the prime duke, being so reputeJif\tufu\tuf\n",
      "\n",
      "iter:4799/20000 loss:2.4009187531471254\n",
      "generated sequence: ARD IV:\n",
      "You cavil, widow: I did mean, my queen.\n",
      "\n",
      "LADY GREY:\n",
      "'Twill grieve your grace my sons should call you father.\n",
      "\n",
      "J;\tG EDWARSJpp\tJ\n",
      "\n",
      "iter:4999/20000 loss:2.389232757091522\n",
      "generated sequence: est advantage will deceive the time,\n",
      "And aid thee in this doubtful shock of arms:\n",
      "But on thy side I may not be too forward\n",
      "Lest,\t\t\tpu\tfu\t\t\n",
      "\n",
      "iter:5199/20000 loss:2.3969758129119874\n",
      "generated sequence: erritories; and have already\n",
      "O'erborne their way, consumed with fire, and took\n",
      "What lay before them.\n",
      "\n",
      "COMINIUS:\n",
      "O, you have madesfftisftsf\n",
      "\n",
      "iter:5399/20000 loss:2.3947815096378324\n",
      "generated sequence:  live an unstain'd wife to my sweet love.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Hold, then; go home, be merry, give consent\n",
      "To marry Paris: Wednesdaybftf\tbo\tbt\n",
      "\n",
      "iter:5599/20000 loss:2.3917350125312806\n",
      "generated sequence: uldst thou have laugh'd had I come coffin'd home,\n",
      "That weep'st to see me triumph? Ay, my dear,\n",
      "Such eyes the widows in Corioli w\t\t\t\tiii\t\t\t\n",
      "\n",
      "iter:5799/20000 loss:2.3794236469268797\n",
      "generated sequence: ey? or how?\n",
      "\n",
      "ELBOW:\n",
      "For being a bawd, for being a bawd.\n",
      "\n",
      "LUCIO:\n",
      "Well, then, imprison him: if imprisonment be the\n",
      "j\t\tj\t\t\ta bawd, \t\t\n",
      "\n",
      "iter:5999/20000 loss:2.3805479681491852\n",
      "generated sequence: e says he is, say that he dreams,\n",
      "For he is nothing but a mighty lord.\n",
      "This do and do it kindly, gentle sirs:\n",
      "It will be pastime\tj\tu\t\tj\t\tj\n",
      "\n",
      "iter:6199/20000 loss:2.381777534484863\n",
      "generated sequence: house.\n",
      "\n",
      "Third Servant:\n",
      "Why, sir, you know no house nor no such maid,\n",
      "Nor no such men as you have reckon'd up,\n",
      "BBiftephen Sly andfvt\t\t\n",
      "\n",
      "iter:6399/20000 loss:2.3604619938135145\n",
      "generated sequence:  find report a very liar;\n",
      "For thou are pleasant, gamesome, passing courteous,\n",
      "But slow in speech, yet sweet as spring-time floweppt\tfpf\tfs\n",
      "\n",
      "iter:6599/20000 loss:2.359442037343979\n",
      "generated sequence: ter sums than I have promised.\n",
      "So shall you quietly enjoy your hope,\n",
      "And marry sweet Bianca with consent.\n",
      "\n",
      "LUCENTIO:\n",
      "Were it noti\tfp\ttf\tpi\n",
      "\n",
      "iter:6799/20000 loss:2.3772306191921233\n",
      "generated sequence: nt,\n",
      "God knows I will not do it, to the death.\n",
      "\n",
      "CATESBY:\n",
      "God keep your lordship in that gracious mind!\n",
      "\n",
      "HASTINGS:\n",
      "But I shall laue\t\tB;\t\tj\t\t\n",
      "\n",
      "iter:6999/20000 loss:2.368141565322876\n",
      "generated sequence: d our good cause fight upon our side;\n",
      "The prayers of holy saints and wronged souls,\n",
      "Like high-rear'd bulwarks, stand before our \tpstpppss\t\n",
      "\n",
      "iter:7199/20000 loss:2.350461382865906\n",
      "generated sequence: ,\n",
      "More sins for this forgiveness prosper may.\n",
      "This fester'd joint cut off, the rest rest sound;\n",
      "This let alone will all the rest\tUtsf\tu\tt\t\n",
      "\n",
      "iter:7399/20000 loss:2.354360417127609\n",
      "generated sequence:  resident in men like one another\n",
      "And not in me: I am myself alone.\n",
      "Clarence, beware; thou keep'st me from the light:\n",
      "But I willnf\t\to\t\t\t\tn\n",
      "\n",
      "iter:7599/20000 loss:2.3345126378536225\n",
      "generated sequence: ' the body of the weal; and now, arriving\n",
      "A place of potency and sway o' the state,\n",
      "If he should still malignantly remain\n",
      "Fast feb\tb\tbfs\t\t\n",
      "\n",
      "iter:7799/20000 loss:2.352619078159332\n",
      "generated sequence:  garments, being, as they were, drenched in\n",
      "the sea, hold notwithstanding their freshness and\n",
      "glosses, being rather new-dyed thauioffteif\t\n",
      "\n",
      "iter:7999/20000 loss:2.329102649688721\n",
      "generated sequence:  din of war gan pierce\n",
      "His ready sense; then straight his doubled spirit\n",
      "Re-quicken'd what in flesh was fatigate,\n",
      "And to the batb\to\tbs\tbju\n",
      "\n",
      "iter:8199/20000 loss:2.3370140159130095\n",
      "generated sequence: nce, I pray you; 'twas a fault unwilling.\n",
      "\n",
      "PETRUCHIO:\n",
      "A whoreson beetle-headed, flap-ear'd knave!\n",
      "Come, Kate, sit down; I know yeb\t\tb\tbffo\n",
      "\n",
      "iter:8399/20000 loss:2.342219651341438\n",
      "generated sequence: om would to God I had\n",
      "well knock'd at first, Then had not Grumio come by the worst.\n",
      "\n",
      "PETRUCHIO:\n",
      "A senseless villain! Good Horten\tfp\t\t\t\t\tp\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:2.3231722033023834\n",
      "generated sequence:  thee on with full as many lies\n",
      "As may be holloa'd in thy treacherous ear\n",
      "From sun to sun: there is my honour's pawn;\n",
      "Engage it uif\t\tbv\tb\t\n",
      "\n",
      "iter:8799/20000 loss:2.3429966628551484\n",
      "generated sequence: ngman:\n",
      "Do't! he will do't; for, look you, sir, he has as\n",
      "many friends as enemies; which friends, sir, as it\n",
      "Bpst, durst not, loo\tifo\t\n",
      "\n",
      "iter:8999/20000 loss:2.308393493890762\n",
      "generated sequence: ILLO:\n",
      "There is a sickness\n",
      "Which puts some of us in distemper, but\n",
      "I cannot name the disease; and it is caught\n",
      "Bif\tfu that yet ar\tJJ;\n",
      "\n",
      "iter:9199/20000 loss:2.3055120277404786\n",
      "generated sequence: \n",
      "I pray thee, gentle keeper, stay by me;\n",
      "My soul is heavy, and I fain would sleep.\n",
      "\n",
      "BRAKENBURY:\n",
      "I will, my lord: God give your gB\tzffo\tz\tf\n",
      "\n",
      "iter:9399/20000 loss:2.3162673354148864\n",
      "generated sequence: Nor with thy sweets comfort his ravenous sense;\n",
      "But let thy spiders, that suck up thy venom,\n",
      "And heavy-gaited toads lie in theirpufuttifui\n",
      "\n",
      "iter:9599/20000 loss:2.307602438926697\n",
      "generated sequence: breast,\n",
      "Or, by Saint Paul, I'll strike thee to my foot,\n",
      "And spurn upon thee, beggar, for thy boldness.\n",
      "\n",
      "LADY ANNE:\n",
      "What, do you ff\to\t\t\tB;f\n",
      "\n",
      "iter:9799/20000 loss:2.313354263305664\n",
      "generated sequence: lsehood.\n",
      "\n",
      "Servant:\n",
      "My lord the king, the king!\n",
      "\n",
      "LEONTES:\n",
      "What is the business?\n",
      "\n",
      "Servant:\n",
      "O sir, I shall be hated to report it!\n",
      "BBu\tfss\t\n",
      "\n",
      "iter:9999/20000 loss:2.290875598192215\n",
      "generated sequence: tent\n",
      "To dash our late decree in parliament\n",
      "Touching King Henry's oath and your succession.\n",
      "Short tale to make, we at Saint Albani\t\t\tBisb\to\n",
      "\n",
      "iter:10199/20000 loss:2.2905791223049166\n",
      "generated sequence: t I am in\n",
      "So far in blood that sin will pluck on sin:\n",
      "Tear-falling pity dwells not in this eye.\n",
      "Is thy name Tyrrel?\n",
      "\n",
      "TYRREL:\n",
      "Jam\tb\tbofbo\tB\n",
      "\n",
      "iter:10399/20000 loss:2.2854753398895262\n",
      "generated sequence: Phaethon would whip you to the west,\n",
      "And bring in cloudy night immediately.\n",
      "Spread thy close curtain, love-performing night,\n",
      "Thajfo\tifoeuj\n",
      "\n",
      "iter:10599/20000 loss:2.2817922341823578\n",
      "generated sequence: emn hymns to sullen dirges change,\n",
      "Our bridal flowers serve for a buried corse,\n",
      "And all things change them to the contrary.\n",
      "\n",
      "FRIsf\tuf\tfe\tu\n",
      "\n",
      "iter:10799/20000 loss:2.29247908949852\n",
      "generated sequence: ok'd my mind to answer it.\n",
      "I have no brother, I am like no brother;\n",
      "And this word 'love,' which graybeards call divine,\n",
      "Be resids\te\tuf\tufo\n",
      "\n",
      "iter:10999/20000 loss:2.283562481403351\n",
      "generated sequence: the service, you\n",
      "will be considered.\n",
      "\n",
      "MISTRESS OVERDONE:\n",
      "What's to do here, Thomas tapster? let's withdraw.\n",
      "\n",
      "POMPEY:\n",
      "Here comes if\tuu\tfftp\n",
      "\n",
      "iter:11199/20000 loss:2.2763594830036165\n",
      "generated sequence: s request,\n",
      "And fit his mind to death, for his soul's rest.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "So then you hope of pardon from Lord Angelo?\n",
      "\n",
      "CLAUDI\tuf\tvt\t\t\t\t\n",
      "\n",
      "iter:11399/20000 loss:2.262233355641365\n",
      "generated sequence:  love myself.\n",
      "\n",
      "KING EDWARD IV:\n",
      "And would you not do much to do them good?\n",
      "\n",
      "LADY GREY:\n",
      "To do them good, I would sustain some harmnp\tf\tnf\t\t\t\n",
      "\n",
      "iter:11599/20000 loss:2.258779601454735\n",
      "generated sequence: t was your garland. What's the matter,\n",
      "That in these several places of the city\n",
      "You cry against the noble senate, who,\n",
      "Under theiuiuuu\tsuf\n",
      "\n",
      "iter:11799/20000 loss:2.2722472447156905\n",
      "generated sequence: our crest? a coxcomb?\n",
      "\n",
      "PETRUCHIO:\n",
      "A combless cock, so Kate will be my hen.\n",
      "\n",
      "KATHARINA:\n",
      "No cock of mine; you crow too like a crav\t\tpnpp\t\t\t\n",
      "\n",
      "iter:11999/20000 loss:2.264157806634903\n",
      "generated sequence: ere died this morning of a cruel fever\n",
      "One Ragozine, a most notorious pirate,\n",
      "A man of Claudio's years; his beard and head\n",
      "Just \tf\tp\to\t\tp\t\n",
      "\n",
      "iter:12199/20000 loss:2.255955158472061\n",
      "generated sequence: ar a burthen like an ass,\n",
      "Spurr'd, gall'd and tired by jouncing Bolingbroke.\n",
      "\n",
      "Keeper:\n",
      "Fellow, give place; here is no longer stayofbobfsfff\n",
      "\n",
      "iter:12399/20000 loss:2.2669007641077044\n",
      "generated sequence: g in Verona streets:\n",
      "Hold, Tybalt! good Mercutio!\n",
      "\n",
      "MERCUTIO:\n",
      "I am hurt.\n",
      "A plague o' both your houses! I am sped.\n",
      "Is he gone, andputeuJ\tfve\n",
      "\n",
      "iter:12599/20000 loss:2.2354070848226546\n",
      "generated sequence: ess course\n",
      "To cut off those that have offended him.\n",
      "\n",
      "First Murderer:\n",
      "Who made thee, then, a bloody minister,\n",
      "When gallant-spring\tuuupsufu\t\n",
      "\n",
      "iter:12799/20000 loss:2.2661091721057893\n",
      "generated sequence: ly?\n",
      "\n",
      "BAPTISTA:\n",
      "Faith, gentlemen, now I play a merchant's part,\n",
      "And venture madly on a desperate mart.\n",
      "\n",
      "TRANIO:\n",
      "BBvo;i; commodityb\t\n",
      "\n",
      "iter:12999/20000 loss:2.2283815860748293\n",
      "generated sequence: heir hearts.\n",
      "\n",
      "LORD WILLOUGHBY:\n",
      "And daily new exactions are devised,\n",
      "As blanks, benevolences, and I wot not what:\n",
      "But what, o' Gof\tofufoof\t\n",
      "\n",
      "iter:13199/20000 loss:2.2337095975875854\n",
      "generated sequence: ated\n",
      "To buy and sell with groats, to show bare heads\n",
      "In congregations, to yawn, be still and wonder,\n",
      "When one but of my ordinanco\t\t\tUpouft\n",
      "\n",
      "iter:13399/20000 loss:2.2174214351177217\n",
      "generated sequence:  hands.\n",
      "But who comes here? the new-deliver'd Hastings?\n",
      "\n",
      "HASTINGS:\n",
      "Good time of day unto my gracious lord!\n",
      "\n",
      "GLOUCESTER:\n",
      "Bvumuch ufoe\tu\n",
      "\n",
      "iter:13599/20000 loss:2.225413547754288\n",
      "generated sequence: I cannot go thither.\n",
      "\n",
      "VOLUMNIA:\n",
      "Why, I pray you?\n",
      "\n",
      "VIRGILIA:\n",
      "'Tis not to save labour, nor that I want love.\n",
      "\n",
      "VALERIA:\n",
      "You would b\tupu\t\tsiui\n",
      "\n",
      "iter:13799/20000 loss:2.209427775144577\n",
      "generated sequence: perately; your promise.\n",
      "\n",
      "CORIOLANUS:\n",
      "The fires i' the lowest hell fold-in the people!\n",
      "Call me their traitor! Thou injurious tribfsfmis\t\t\tu\n",
      "\n",
      "iter:13999/20000 loss:2.216452159881592\n",
      "generated sequence: r the purgation.\n",
      "Produce the prisoner.\n",
      "\n",
      "Officer:\n",
      "It is his highness' pleasure that the queen\n",
      "Appear in person here in court. Silfuifsufsff\n",
      "\n",
      "iter:14199/20000 loss:2.210019348859787\n",
      "generated sequence: QUEEN MARGARET:\n",
      "Why, how now, long-tongued Warwick! dare you speak?\n",
      "When you and I met at Saint Alban's last,\n",
      "Your legs did bettVTOOHxFSJ;\n",
      "\n",
      "iter:14399/20000 loss:2.1954416221380235\n",
      "generated sequence: een.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Which for some reasons, sir, I mean to see.\n",
      "I fear, I fear,--\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "What should you fear?\n",
      "JJpDJ;\t\t\t\n",
      "\n",
      "iter:14599/20000 loss:2.18876703619957\n",
      "generated sequence: \n",
      "\n",
      "WARWICK:\n",
      "So much his friend, ay, his unfeigned friend,\n",
      "That, if King Lewis vouchsafe to furnish us\n",
      "With some few bands of chosBBioJi\tip\n",
      "\n",
      "iter:14799/20000 loss:2.1804875206947325\n",
      "generated sequence: thou lovest me, Camillo, wipe not out the rest of\n",
      "thy services by leaving me now: the need I have of\n",
      "thee thine own goodness hatifvtufof\tf\n",
      "\n",
      "iter:14999/20000 loss:2.1691463774442674\n",
      "generated sequence:  and I love him well.\n",
      "If you be hired for meed, go back again,\n",
      "And I will send you to my brother Gloucester,\n",
      "Who shall reward yopme\tp\tp\tsf\n",
      "\n",
      "iter:15199/20000 loss:2.1731744766235352\n",
      "generated sequence: re!\n",
      "As for my country I have shed my blood,\n",
      "Not fearing outward force, so shall my lungs\n",
      "Bo\tu\tsfrds till their decay against thofs\n",
      "\n",
      "iter:15399/20000 loss:2.1729609709978104\n",
      "generated sequence: o in your mouth:\n",
      "Tranio is changed into Lucentio.\n",
      "\n",
      "BIONDELLO:\n",
      "The better for him: would I were so too!\n",
      "\n",
      "TRANIO:\n",
      "So could I, faitvpopu\tvspu\n",
      "\n",
      "iter:15599/20000 loss:2.1737687277793882\n",
      "generated sequence: like a carbon ado.\n",
      "\n",
      "Second Servingman:\n",
      "An he had been cannibally given, he might have\n",
      "broiled and eaten him too.\n",
      "\n",
      "First Servingmbof\tbobbof\n",
      "\n",
      "iter:15799/20000 loss:2.1594814264774325\n",
      "generated sequence: ot hear him plead;\n",
      "For Clarence is well-spoken, and perhaps\n",
      "May move your hearts to pity if you mark him.\n",
      "\n",
      "First Murderer:\n",
      "Tush!siibssfibt\n",
      "\n",
      "iter:15999/20000 loss:2.138473281264305\n",
      "generated sequence: hold you. Their love is not\n",
      "so great, Hortensio, but we may blow our nails\n",
      "together, and fast it fairly out: our cakes dough on\n",
      "us\t\tp\tst\n",
      "\n",
      "iter:16199/20000 loss:2.1335192465782167\n",
      "generated sequence: y on the back of Montague,--\n",
      "And it mis-sheathed in my daughter's bosom!\n",
      "\n",
      "LADY CAPULET:\n",
      "O me! this sight of death is as a bell,\n",
      "\tuo\tuib\tbf\n",
      "\n",
      "iter:16399/20000 loss:2.152719017267227\n",
      "generated sequence: nd liberty plucks justice by the nose;\n",
      "The baby beats the nurse, and quite athwart\n",
      "Goes all decorum.\n",
      "\n",
      "FRIAR THOMAS:\n",
      "It rested in\tfc\ttf\tf\t\t\n",
      "\n",
      "iter:16599/20000 loss:2.115049350261688\n",
      "generated sequence:  is nothing in the between but\n",
      "getting wenches with child, wronging the ancientry,\n",
      "stealing, fighting--Hark you now! Would any buouuuoifou\n",
      "\n",
      "iter:16799/20000 loss:2.130494589805603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: way which, thou dost confess,\n",
      "Were fit for thee to use as they to claim,\n",
      "In asking their good loves, but thou wilt frame\n",
      "Thyselfiu\tuiptpp\t\n",
      "\n",
      "iter:16999/20000 loss:2.0949853551387787\n",
      "generated sequence:  I\n",
      "Have strain'd to appear thus: if one jot beyond\n",
      "The bound of honour, or in act or will\n",
      "That way inclining, harden'd be the heb\tU;of\tb\t\t\n",
      "\n",
      "iter:17199/20000 loss:2.104324763417244\n",
      "generated sequence:  see them spread;\n",
      "And spread they shall be, to thy foul disgrace\n",
      "And utter ruin of the house of York.\n",
      "Thus do I leave thee. Comeuussuifsfb\n",
      "\n",
      "iter:17399/20000 loss:2.099686111807823\n",
      "generated sequence: rd false Clarence?'\n",
      "And so he vanish'd: then came wandering by\n",
      "A shadow like an angel, with bright hair\n",
      "Dabbled in blood; and heffb\to\t\t\tbb\n",
      "\n",
      "iter:17599/20000 loss:2.0999145072698595\n",
      "generated sequence: Are made already mothers: by my count,\n",
      "I was your mother much upon these years\n",
      "That you are now a maid. Thus then in brief:\n",
      "The ;f\tnbs\t\tns\n",
      "\n",
      "iter:17799/20000 loss:2.1068430864810943\n",
      "generated sequence: ow that's bolted\n",
      "By the northern blasts twice o'er.\n",
      "\n",
      "POLIXENES:\n",
      "What follows this?\n",
      "How prettily the young swain seems to wash\n",
      "Thuiuifuiuuu\n",
      "\n",
      "iter:17999/20000 loss:2.086035189628601\n",
      "generated sequence: nour'd to your noses,--\n",
      "\n",
      "MENENIUS:\n",
      "What's the news? what's the news?\n",
      "\n",
      "COMINIUS:\n",
      "Your temples burned in their cement, and\n",
      "Your frpvspt\topoo\n",
      "\n",
      "iter:18199/20000 loss:2.0744462221860887\n",
      "generated sequence: u see me smear'd; if any fear\n",
      "Lesser his person than an ill report;\n",
      "If any think brave death outweighs bad life\n",
      "And that his coutbfssbfsbf\n",
      "\n",
      "iter:18399/20000 loss:2.061743218898773\n",
      "generated sequence:  and timorously confess\n",
      "The manner and the purpose of his treason;\n",
      "That you might well have signified the same\n",
      "Unto the citizensoop\tppofop\n",
      "\n",
      "iter:18599/20000 loss:2.0573599141836167\n",
      "generated sequence: oungest daughter, beautiful Binaca,\n",
      "And her withholds from me and other more,\n",
      "Suitors to her and rivals in my love,\n",
      "Supposing itvuebsuibfu\n",
      "\n",
      "iter:18799/20000 loss:2.0560779464244843\n",
      "generated sequence:  I say.\n",
      "\n",
      "GRUMIO:\n",
      "Knock, sir! whom should I knock? is there man has\n",
      "rebused your worship?\n",
      "\n",
      "PETRUCHIO:\n",
      "DJ;lain, I say, knock me het;t\to\t\n",
      "\n",
      "iter:18999/20000 loss:2.0348757064342498\n",
      "generated sequence:  ever any grudge were lodged between us;\n",
      "Of you, Lord Rivers, and, Lord Grey, of you;\n",
      "That without desert have frown'd on me;\n",
      "Duvsfsfooe\tc\n",
      "\n",
      "iter:19199/20000 loss:2.028054203391075\n",
      "generated sequence: , I'll none of you.\n",
      "\n",
      "First Lady:\n",
      "Why, my sweet lord?\n",
      "\n",
      "MAMILLIUS:\n",
      "You'll kiss me hard and speak to me as if\n",
      "I were a baby still. \to\tmppopop\n",
      "\n",
      "iter:19399/20000 loss:2.0126362669467928\n",
      "generated sequence: y soul to heaven,\n",
      "If heaven will take the present at our hands.\n",
      "But who comes here? the new-deliver'd Hastings?\n",
      "\n",
      "HASTINGS:\n",
      "Good \tpuomfbiob\n",
      "\n",
      "iter:19599/20000 loss:2.0090283298492433\n",
      "generated sequence: ame, forbear this outrage!\n",
      "Tybalt, Mercutio, the prince expressly hath\n",
      "Forbidden bandying in Verona streets:\n",
      "Hold, Tybalt! good sfs\tcssbfs\n",
      "\n",
      "iter:19799/20000 loss:2.0084256148338318\n",
      "generated sequence: US:\n",
      "I am going to visit the prisoner. Fare you well.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Peace be with you!\n",
      "He who the sword of heaven will bear\n",
      "J\tjujjj\n",
      "\n",
      "iter:19999/20000 loss:2.002452629804611\n",
      "generated sequence: Their own particular thrifts, they would do that\n",
      "Which should undo more doing: ay, and thou,\n",
      "His cupbearer,--whom I from meaner ipsopxsbuu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adagrad(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,input,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mself\\neternity and could put breath into his work, would\\nbeguile Nature of her custom, so perfectly he is her\\nape: he so near tofu\\tf\\tU\\t\\t\\tjeo\\t\\tboe\\tvpvu\\t\\tufuiuff\\tuipxo\\tpvxptvppvff\\tvfvsffBf\\tftf\\t\\tvps\\ttf\\tps\\tpf\\tftpt\\tf\\tf\\tp\\t\\tif\\tf\\t\\tf\\t\\t\\tif\\tif\\tif\\tfU\\tf\\t\\tbf\\tb\\t\\tb\\t\\tu\\tf\\t\\t\\t\\tv\\tv\\tvvvo\\t\\tvvu\\t\\tuuvu\\tuu\\t\\t\\tf\\t\\t\\tp\\tfv\\t\\tvv\\t\\tv\\t\\t\\t\\t\\t\\t\\tv\\t\\t\\t\\t\\t\\t\\t\\tp\\t\\t\\tpp\\t\\t\\tp\\t\\tp\\t\\tp\\t\\tf\\t\\t\\t\\ti\\ti\\ti\\tii\\t\\ti\\tii\\tiii\\t\\tb\\t\\tb\\t\\tb\\t\\tb\\tbb\\t\\tb\\tvv\\tvv\\tv\\tvvvv\\tv\\tv\\t\\t\\t\\tvv\\t\\t\\tvv\\t\\t\\t\\tv\\t\\tvvv\\tvvv\\tv\\t\\tvv\\t\\tvv\\tvvvvppp\\tpppppppp\\tppp\\t\\tppi\\tii\\tii\\tii\\tiiii\\ti\\ti\\ti\\t\\tii\\ti\\t\\ti\\t\\t\\tbb\\tbb\\tbb\\tvv\\tv\\t\\tvvvv\\t\\tv\\t\\tv\\tv\\t\\t\\t\\tv\\tv\\tvvvv\\t\\tvvv\\t\\tvvvv\\tvv\\t\\t\\tv\\t\\t\\tv\\tvv\\t\\tvp\\t\\tp\\t\\t\\t\\t\\t\\t\\tp\\t\\t\\t\\t\\t\\t\\t\\ti\\t\\t\\tii\\t\\t\\ti\\t\\ti\\t\\ti\\t\\ti\\t\\t\\t\\ti\\ti\\ti\\tii\\t\\tb\\tbb\\tbbb\\t\\tv\\t\\tv\\t\\tv\\t\\tv\\tvv\\t\\t\\t\\tvv\\tvv\\tv\\tvvvv\\tv\\tv\\t\\t\\t\\tvv\\t\\t\\tvv\\t\\t\\t\\tv\\t\\tvvv\\tvvv\\tv\\t\\tpp\\t\\tpp\\tiiiiiii\\tiiiiiiii\\tiii\\t\\tiii\\tii\\tii\\tii\\tiiii\\ti\\ti\\tb\\t'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_input,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "Follows the updated baseline, but uses adagrad optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
