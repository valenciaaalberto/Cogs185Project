{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='W', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:4.139927043914795\n",
      "generated sequence:  and, as the custom is,\n",
      "In all her best array bear her to church:\n",
      "For though fond nature bids us an lament,\n",
      "Yet nature's tears au\t\t\t\tu\t\tu\t\n",
      "\n",
      "iter:399/20000 loss:3.6312287211418153\n",
      "generated sequence: ain be freely granted:\n",
      "If not, I'll use the advantage of my power\n",
      "And lay the summer's dust with showers of blood\n",
      "Rain'd from th\t\t\tu\t\tu\t\t\t\n",
      "\n",
      "iter:599/20000 loss:3.4772709190845488\n",
      "generated sequence: ave taken treasure from her lips--\n",
      "\n",
      "PAULINA:\n",
      "And left them\n",
      "More rich for what they yielded.\n",
      "\n",
      "LEONTES:\n",
      "Thou speak'st truth.\n",
      "No mo\t\t\tu\t\t\t\t\tu\n",
      "\n",
      "iter:799/20000 loss:3.395506639480591\n",
      "generated sequence: in she delights, I will\n",
      "wish him to her father.\n",
      "\n",
      "HORTENSIO:\n",
      "So will I, Signior Gremio: but a word, I pray.\n",
      "Though the nature of \t\tu\t\t\tu\t\t\t\n",
      "\n",
      "iter:999/20000 loss:3.349065009355545\n",
      "generated sequence: akes of roses,\n",
      "Were thinly scatter'd, to make up a show.\n",
      "Noting this penury, to myself I said\n",
      "'An if a man did need a poison now\t\t\t\tu\t\tu\t\t\n",
      "\n",
      "iter:1199/20000 loss:3.305153908729553\n",
      "generated sequence: t her heart,\n",
      "My will to her consent is but a part;\n",
      "An she agree, within her scope of choice\n",
      "Lies my consent and fair according v\tu\t\t\tu\t\t\t\t\n",
      "\n",
      "iter:1399/20000 loss:3.2835015439987183\n",
      "generated sequence: p before him?\n",
      "\n",
      "CAMILLO:\n",
      "Sent by the king your father\n",
      "To greet him and to give him comforts. Sir,\n",
      "The manner of your bearing towa\tuf\t\t\t\t\tuf\n",
      "\n",
      "iter:1599/20000 loss:3.290080232620239\n",
      "generated sequence: es and tell her that Paris is the properer\n",
      "man; but, I'll warrant you, when I say so, she looks\n",
      "as pale as any clout in the vers\t\tu\tu\tu\t\t\t\n",
      "\n",
      "iter:1799/20000 loss:3.2093437349796297\n",
      "generated sequence: portions\n",
      "Came short of composition, but in chief\n",
      "For that her reputation was disvalued\n",
      "In levity: since which time of five years\t\t\t\t\t\tu\t\t\t\n",
      "\n",
      "iter:1999/20000 loss:3.229618539810181\n",
      "generated sequence: happy masks that kiss fair ladies' brows\n",
      "Being black put us in mind they hide the fair;\n",
      "He that is strucken blind cannot forget\n",
      "f\tmm\tu\t\t\t\t\n",
      "\n",
      "iter:2199/20000 loss:3.1295298314094544\n",
      "generated sequence:  majesty, impute his words\n",
      "To wayward sickliness and age in him:\n",
      "He loves you, on my life, and holds you dear\n",
      "As Harry Duke of Hu\t\t\t\t\t\t\t\tu\n",
      "\n",
      "iter:2399/20000 loss:3.144395488500595\n",
      "generated sequence: e rebels from their ships!\n",
      "\n",
      "STANLEY:\n",
      "No, my good lord, my friends are in the north.\n",
      "\n",
      "KING RICHARD III:\n",
      "Cold friends to Richard: \tu\t\tf\t\t\tu\t\n",
      "\n",
      "iter:2599/20000 loss:3.105220867395401\n",
      "generated sequence: ley.\n",
      "\n",
      "HASTINGS:\n",
      "What is't o'clock?\n",
      "\n",
      "Messenger:\n",
      "Upon the stroke of four.\n",
      "\n",
      "HASTINGS:\n",
      "f\t\t\tot thy master sleep these tedious nights?\t\t\t\n",
      "\n",
      "iter:2799/20000 loss:3.0931598925590515\n",
      "generated sequence:  I am. Condition!\n",
      "What good condition can a treaty find\n",
      "I' the part that is at mercy? Five times, Marcius,\n",
      "u\t\tuve fought with thuuu\t\t\n",
      "\n",
      "iter:2999/20000 loss:3.087698689699173\n",
      "generated sequence: y poor services, i' the love\n",
      "That I have borne your father?\n",
      "\n",
      "FLORIZEL:\n",
      "Very nobly\n",
      "Have you deserved: it is my father's music\n",
      "To \tum\t\t\tu\t\t\t\n",
      "\n",
      "iter:3199/20000 loss:3.0401412403583525\n",
      "generated sequence: ep:\n",
      "I'll to the king; and signify to him\n",
      "That thus I have resign'd my charge to you.\n",
      "\n",
      "First Murderer:\n",
      "u\t\t\tu\t it is a point of wi\tm\t\n",
      "\n",
      "iter:3399/20000 loss:3.0345189332962037\n",
      "generated sequence: perform'd.\n",
      "What sayest thou? speak suddenly; be brief.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Your grace may do your pleasure.\n",
      "\n",
      "KING RICHARD III:\n",
      "Tut, tutm\t\t\t\t\tb\t\t\n",
      "\n",
      "iter:3599/20000 loss:3.0203544294834135\n",
      "generated sequence: e where I expect most love!\n",
      "When I have most need to employ a friend,\n",
      "And most assured that he is a friend\n",
      "Deep, hollow, treache\tu\tf\t\t\tuuu\n",
      "\n",
      "iter:3799/20000 loss:2.9900051140785218\n",
      "generated sequence: ured with brick,\n",
      "Whose western side is with a vineyard back'd;\n",
      "And to that vineyard is a planched gate,\n",
      "That makes his opening w\t\t\t\tu\t\t\tfu\n",
      "\n",
      "iter:3999/20000 loss:2.9702243852615355\n",
      "generated sequence:  still. Is't meet that he\n",
      "Should leave the helm and like a fearful lad\n",
      "With tearful eyes add water to the sea\n",
      "uv\t give more streu\t\tomm\n",
      "\n",
      "iter:4199/20000 loss:2.972568701505661\n",
      "generated sequence:  we stood up about the corn, he\n",
      "himself stuck not to call us the many-headed multitude.\n",
      "\n",
      "Third Citizen:\n",
      "We have been called so ou\t\tu\t\t\t\t\tu\n",
      "\n",
      "iter:4399/20000 loss:2.9402527487277985\n",
      "generated sequence: ?\n",
      "\n",
      "BRUTUS:\n",
      "He's poor in no one fault, but stored with all.\n",
      "\n",
      "SICINIUS:\n",
      "Especially in pride.\n",
      "\n",
      "BRUTUS:\n",
      "\tffpf\tpping all others in bo\t\n",
      "\n",
      "iter:4599/20000 loss:2.9294874095916748\n",
      "generated sequence: he purgation.\n",
      "Produce the prisoner.\n",
      "\n",
      "Officer:\n",
      "It is his highness' pleasure that the queen\n",
      "Appear in person here in court. Silencf\tum\t\t\tu\to\n",
      "\n",
      "iter:4799/20000 loss:2.9072010493278504\n",
      "generated sequence: ust know\n",
      "The value of her own: 'twere a concealment\n",
      "Worse than a theft, no less than a traducement,\n",
      "po hide your doings; and to \t\t\tu\te\t\t\n",
      "\n",
      "iter:4999/20000 loss:2.9058865320682528\n",
      "generated sequence: lked withal. Away with\n",
      "him to prison! Where is the provost? Away with him\n",
      "to prison! lay bolts enough upon him: let him\n",
      "speak nom\t\t\tu\to\tfu\n",
      "\n",
      "iter:5199/20000 loss:2.877211608886719\n",
      "generated sequence: !\n",
      "\n",
      "FLORIZEL:\n",
      "It cannot fail but by\n",
      "The violation of my faith; and then\n",
      "Let nature crush the sides o' the earth together\n",
      "\tfbfvb\t \t\n",
      "\n",
      "iter:5399/20000 loss:2.86871817111969\n",
      "generated sequence:  lords,\n",
      "With thoughts so qualified as your charities\n",
      "Shall best instruct you, measure me; and so\n",
      "The king's will be perform'd!\n",
      "\n",
      "\to\t\t\t\t\t\n",
      "\n",
      "iter:5599/20000 loss:2.857865536212921\n",
      "generated sequence: of my kin,\n",
      "And yet I love him.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Make way, unruly woman!\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "After, Aumerle! mount thee upon his hors\t\tub\tu\toe\t\n",
      "\n",
      "iter:5799/20000 loss:2.8532190418243406\n",
      "generated sequence: who comes here?\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "It is my Lord of Berkeley, as I guess.\n",
      "\n",
      "LORD BERKELEY:\n",
      "My Lord of Hereford, my message is to yoif\tup\tb\t\tu\n",
      "\n",
      "iter:5999/20000 loss:2.835537360906601\n",
      "generated sequence: gainst thee, are all fall'n upon thee;\n",
      "And God, not we, hath plagued thy bloody deed.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "So just is God, to right\tuoe\t\tu\tf\t\n",
      "\n",
      "iter:6199/20000 loss:2.843265036344528\n",
      "generated sequence:  or two with Claudio.\n",
      "\n",
      "Provost:\n",
      "And very welcome. Look, signior, here's your sister.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Provost, a word with you.\n",
      "u\t\tu\ti\tuio\n",
      "\n",
      "iter:6399/20000 loss:2.815305621623993\n",
      "generated sequence: hinking of it now.\n",
      "Marry, as for Clarence, he is well repaid,\n",
      "He is frank'd up to fatting for his pains\n",
      "God pardon them that arefoe\toe\tu\t\t\n",
      "\n",
      "iter:6599/20000 loss:2.818377336263657\n",
      "generated sequence: onsisting equally of horse and foot;\n",
      "Our archers shall be placed in the midst\n",
      "John Duke of Norfolk, Thomas Earl of Surrey,\n",
      "Shall\te\to\t\toe\tb\n",
      "\n",
      "iter:6799/20000 loss:2.7972374081611635\n",
      "generated sequence: oon out of her sphere, if she would continue\n",
      "in it five weeks without changing.\n",
      "\n",
      "SEBASTIAN:\n",
      "We would so, and then go a bat-fowli\t\teu\t\t\tu\t\t\n",
      "\n",
      "iter:6999/20000 loss:2.787902092933655\n",
      "generated sequence: of folly. I shall tell you\n",
      "A pretty tale: it may be you have heard it;\n",
      "But, since it serves my purpose, I will venture\n",
      "uo stale \t\tu\t\tmm\t\n",
      "\n",
      "iter:7199/20000 loss:2.7754486060142516\n",
      "generated sequence:  marry me to a whore.\n",
      "Your highness said even now, I made you a duke:\n",
      "good my lord, do not recompense me in making me a cuckold.bbu\t\t\tbb\tb\n",
      "\n",
      "iter:7399/20000 loss:2.764880635738373\n",
      "generated sequence: e holy\n",
      "Than to rejoice the former queen is well?\n",
      "What holier than, for royalty's repair,\n",
      "ifu present comfort and for future good\tuf\tm\t\n",
      "\n",
      "iter:7599/20000 loss:2.7687333250045776\n",
      "generated sequence:  that fair use\n",
      "Revolts from true birth, stumbling on abuse:\n",
      "Virtue itself turns vice, being misapplied;\n",
      "And vice sometimes by acu\tfu\tu\tuo\t\n",
      "\n",
      "iter:7799/20000 loss:2.7540102338790895\n",
      "generated sequence: re my father's grave\n",
      "Did utter forth a voice. Yes, thou must die:\n",
      "Thou art too noble to conserve a life\n",
      "In base appliances. This\t\tuf\tu\tu\tf\n",
      "\n",
      "iter:7999/20000 loss:2.7599739360809328\n",
      "generated sequence: o supper; and I'll lay\n",
      "A plot shall show us all a merry day.\n",
      "\n",
      "QUEEN:\n",
      "This way the king will come; this is the way\n",
      "To Julius Caes\tb\t\tff\t\t\tb\n",
      "\n",
      "iter:8199/20000 loss:2.751435967683792\n",
      "generated sequence: , the more my grief.\n",
      "\n",
      "PETRUCHIO:\n",
      "I see you do not mean to part with her,\n",
      "Or else you like not of my company.\n",
      "\n",
      "BAPTISTA:\n",
      "Mistake \tu\tf\tub\t\t\t\n",
      "\n",
      "iter:8399/20000 loss:2.7454005694389343\n",
      "generated sequence: ARGARET:\n",
      "\n",
      "WARWICK:\n",
      "\n",
      "QUEEN MARGARET:\n",
      "King Lewis and Lady Bona, hear me speak,\n",
      "Before you answer Warwick. His demand\n",
      "BBrings not fof\tofii\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:2.7304056549072264\n",
      "generated sequence: able abuses!\n",
      "\n",
      "ESCALUS:\n",
      "Such a fellow is not to be talked withal. Away with\n",
      "him to prison! Where is the provost? Away with him\n",
      "toufm\tuuf\t\t\t\n",
      "\n",
      "iter:8799/20000 loss:2.739332219362259\n",
      "generated sequence: l steps?\n",
      "If we prevail, their heads shall pay for it:\n",
      "I warrant they have made peace with Bolingbroke.\n",
      "\n",
      "SIR STEPHEN SCROOP:\n",
      "B\tacmu\t\t\tf\t\n",
      "\n",
      "iter:8999/20000 loss:2.740736712217331\n",
      "generated sequence: w my scandal, Richard, dost thou hear;\n",
      "For thou shalt know this strong right hand of mine\n",
      "Can pluck the diadem from faint Henry'\tuf\tu\tpue\t\n",
      "\n",
      "iter:9199/20000 loss:2.7190542697906492\n",
      "generated sequence:  pardon strong.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "With all my heart\n",
      "I pardon him.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "A god on earth thou art.\n",
      "\n",
      "HENRY BOLINGBROKbbu\t\t\teb\t\t\n",
      "\n",
      "iter:9399/20000 loss:2.7008313333988188\n",
      "generated sequence: eize into our hands\n",
      "His plate, his goods, his money and his lands.\n",
      "\n",
      "DUKE OF YORK:\n",
      "I'll not be by the while: my liege, farewell:\n",
      "\to\t\tboe\t\tb\n",
      "\n",
      "iter:9599/20000 loss:2.710477966070175\n",
      "generated sequence: For sinking under them.\n",
      "\n",
      "SICINIUS:\n",
      "This, as you say, suggested\n",
      "At some time when his soaring insolence\n",
      "Shall touch the people--w\t\t\tu\toe\toe\n",
      "\n",
      "iter:9799/20000 loss:2.7024100577831267\n",
      "generated sequence: ce of his cause.\n",
      "\n",
      "Lord Marshal:\n",
      "What is thy name? and wherefore comest thou hither,\n",
      "Before King Richard in his royal lists?\n",
      "Agaip\tu\t\tufo\tu\n",
      "\n",
      "iter:9999/20000 loss:2.7031565368175507\n",
      "generated sequence: Nay, your wit will not so soon out as another man's\n",
      "will;'tis strongly wedged up in a block-head, but\n",
      "if it were at liberty, 'tw\tu\t\tu\t\t\t\tu\n",
      "\n",
      "iter:10199/20000 loss:2.7114064288139343\n",
      "generated sequence: RIAR LAURENCE:\n",
      "These violent delights have violent ends\n",
      "And in their triumph die, like fire and powder,\n",
      "Which as they kiss consuf\tofufoffi\n",
      "\n",
      "iter:10399/20000 loss:2.708168526887894\n",
      "generated sequence: NTIGONUS:\n",
      "Their sacred wills be done! Go, get aboard;\n",
      "Look to thy bark: I'll not be long before\n",
      "I call upon thee.\n",
      "\n",
      "Mariner:\n",
      "Bake\ti\t\t;\tfp\n",
      "\n",
      "iter:10599/20000 loss:2.673583105802536\n",
      "generated sequence: o, then; for 'tis in vain\n",
      "To seek him here that means not to be found.\n",
      "\n",
      "ROMEO:\n",
      "He jests at scars that never felt a wound.\n",
      "But, s\t\tu\tf\te\tu\t\n",
      "\n",
      "iter:10799/20000 loss:2.686736764907837\n",
      "generated sequence: re,\n",
      "Would she begin a sect, might quench the zeal\n",
      "Of all professors else, make proselytes\n",
      "Of who she but bid follow.\n",
      "\n",
      "PAULINA:\n",
      "H\t\t\tBi\t\tm\tb\n",
      "\n",
      "iter:10999/20000 loss:2.6812752544879914\n",
      "generated sequence: t the rest of the\n",
      "eight. Will you pluck your sword out of his pitcher\n",
      "by the ears? make haste, lest mine be about your\n",
      "ears ere \tu\tf\tu\t\t\t\t\n",
      "\n",
      "iter:11199/20000 loss:2.7094918656349183\n",
      "generated sequence: d me so, he wept,\n",
      "And hugg'd me in his arm, and kindly kiss'd my cheek;\n",
      "Bade me rely on him as on my father,\n",
      "And he would love m\tbf\tb\t\t\tbf\n",
      "\n",
      "iter:11399/20000 loss:2.6594565641880035\n",
      "generated sequence:  off at a blow,\n",
      "And with the other fling it at thy face,\n",
      "Than bear so low a sail, to strike to thee.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Sail how tb\t\t\tbu\tbub\n",
      "\n",
      "iter:11599/20000 loss:2.651235122680664\n",
      "generated sequence: \n",
      "\n",
      "KING HENRY VI:\n",
      "This battle fares like to the morning's war,\n",
      "When dying clouds contend with growing light,\n",
      "What time the shepheBB\t\tJ\tufiJ\n",
      "\n",
      "iter:11799/20000 loss:2.671832264661789\n",
      "generated sequence: KE VINCENTIO:\n",
      "Have you no countermand for Claudio yet,\n",
      "But he must die to-morrow?\n",
      "\n",
      "Provost:\n",
      "None, sir, none.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "AszSb\tOJpSJi\n",
      "\n",
      "iter:11999/20000 loss:2.670009573698044\n",
      "generated sequence: land and himself!\n",
      "\n",
      "WESTMORELAND:\n",
      "Base, fearful and despairing Henry!\n",
      "\n",
      "CLIFFORD:\n",
      "How hast thou injured both thyself and us!\n",
      "\n",
      "WESTmue\tbue\tbf\n",
      "\n",
      "iter:12199/20000 loss:2.6768394541740417\n",
      "generated sequence: ntleman, thy speeches\n",
      "Will bring me to consider that which may\n",
      "Unfurnish me of reason. They are come.\n",
      "Your mother was most true e\tm\tfue\tu\t\n",
      "\n",
      "iter:12399/20000 loss:2.658019152879715\n",
      "generated sequence: e,\n",
      "And tent themselves with death. Of all the horses,\n",
      "Whereof we have ta'en good and good store, of all\n",
      "The treasure in this fie\t\tBoe\tu\t\te\n",
      "\n",
      "iter:12599/20000 loss:2.642621556520462\n",
      "generated sequence: n herself,\n",
      "Too noble for this place.\n",
      "\n",
      "CAMILLO:\n",
      "He tells her something\n",
      "That makes her blood look out: good sooth, she is\n",
      "The queeebf\t\t\t\tm\t\t\n",
      "\n",
      "iter:12799/20000 loss:2.661465916633606\n",
      "generated sequence: bject die\n",
      "For truth, for duty, and for loyalty.\n",
      "\n",
      "GREY:\n",
      "God keep the prince from all the pack of you!\n",
      "A knot you are of damned blf\t\tp\tb\to\tB\n",
      "\n",
      "iter:12999/20000 loss:2.6457579827308653\n",
      "generated sequence: erlasting rest,\n",
      "And shake the yoke of inauspicious stars\n",
      "From this world-wearied flesh. Eyes, look your last!\n",
      "Arms, take your la\t\tmu\t\toepb\n",
      "\n",
      "iter:13199/20000 loss:2.6479806327819824\n",
      "generated sequence: \n",
      "ISABELLA:\n",
      "O, pardon me, my lord; it oft falls out,\n",
      "To have what we would have, we speak not what we mean:\n",
      "I something do excuseB\tpo\tSJJo\n",
      "\n",
      "iter:13399/20000 loss:2.6613943612575532\n",
      "generated sequence: ances,\n",
      "I pray you, tell Signior Lucentio that his father is\n",
      "come from Pisa, and is here at the door to speak with him.\n",
      "\n",
      "Pedant:\n",
      "uep\t\t\tB\tbf\n",
      "\n",
      "iter:13599/20000 loss:2.650451430082321\n",
      "generated sequence: erein thou wrong'st thy children mightily.\n",
      "\n",
      "LADY GREY:\n",
      "Herein your highness wrongs both them and me.\n",
      "But, mighty lord, this merr\t\t\toeu\tf\ts\n",
      "\n",
      "iter:13799/20000 loss:2.628439095020294\n",
      "generated sequence: ht be done, pack up: down with them!\n",
      "And hark, what noise the general makes! To him!\n",
      "There is the man of my soul's hate, Aufidiuf\tbf\tb\t\te\t\n",
      "\n",
      "iter:13999/20000 loss:2.6348518991470335\n",
      "generated sequence: recting thy stout heart,\n",
      "Now humble as the ripest mulberry\n",
      "That will not hold the handling: or say to them,\n",
      "Thou art their soldi\t\tp\toe\tu\tf\n",
      "\n",
      "iter:14199/20000 loss:2.6410713148117066\n",
      "generated sequence:  peace on earth.\n",
      "Rivers and Hastings, take each other's hand;\n",
      "Dissemble not your hatred, swear your love.\n",
      "\n",
      "RIVERS:\n",
      "By heaven, mybf\tup\tb\teb\n",
      "\n",
      "iter:14399/20000 loss:2.6263072896003723\n",
      "generated sequence:  the ground? I thought it would have mounted.\n",
      "See how my sword weeps for the poor king's death!\n",
      "O, may such purple tears be alwab\tf\tb\t\t\t\te\n",
      "\n",
      "iter:14599/20000 loss:2.636590347290039\n",
      "generated sequence: re as he bids us: he was provided to do us good.\n",
      "\n",
      "AUTOLYCUS:\n",
      "If I had a mind to be honest, I see Fortune would\n",
      "not suffer me: sh\t\tbu\tbf\tbf\n",
      "\n",
      "iter:14799/20000 loss:2.6144045293331146\n",
      "generated sequence: nks, it should not,\n",
      "For he hath still been tried a holy man.\n",
      "How if, when I am laid into the tomb,\n",
      "I wake before the time that Re\t\t\tbo\tb\t\t\n",
      "\n",
      "iter:14999/20000 loss:2.627313106060028\n",
      "generated sequence: t\n",
      "That e'er I sigh'd for: pity move my father\n",
      "To be inclined my way!\n",
      "\n",
      "FERDINAND:\n",
      "O, if a virgin,\n",
      "And your affection not gone for\tBifu\tb\tt\t\n",
      "\n",
      "iter:15199/20000 loss:2.607745015621185\n",
      "generated sequence: ise, and make's\n",
      "As fat as tame things: one good deed dying tongueless\n",
      "Slaughters a thousand waiting upon that.\n",
      "Our praises are oo\t\t\tbue\tbf\n",
      "\n",
      "iter:15399/20000 loss:2.6195781099796296\n",
      "generated sequence: oint you where you shall have such receiving\n",
      "As shall become your highness; where you may\n",
      "Enjoy your mistress, from the whom, I \toe\tb\t\tsbj\n",
      "\n",
      "iter:15599/20000 loss:2.6186055195331575\n",
      "generated sequence: l be, in despite of all.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "Thou art deceived: 'tis not thy southern power,\n",
      "Of Essex, Norfolk, Suffolk, nor of Kenmbf\t\tboeb\t\n",
      "\n",
      "iter:15799/20000 loss:2.608929477930069\n",
      "generated sequence: SICINIUS:\n",
      "Go, see him out at gates, and follow him,\n",
      "As he hath followed you, with all despite;\n",
      "Bive him deserved vexation. Let ap\tp\tJ\tfp\n",
      "\n",
      "iter:15999/20000 loss:2.6103056037425993\n",
      "generated sequence: onging,\n",
      "saving your honour's reverence, for stewed prunes;\n",
      "sir, we had but two in the house, which at that very\n",
      "distant time sto\te\toe\t\tB\tu\n",
      "\n",
      "iter:16199/20000 loss:2.6100269412994384\n",
      "generated sequence: ,\n",
      "Scaling his present bearing with his past,\n",
      "That he's your fixed enemy, and revoke\n",
      "Your sudden approbation.\n",
      "\n",
      "BRUTUS:\n",
      "Say, you n\tBppumoe\tb\n",
      "\n",
      "iter:16399/20000 loss:2.595915187597275\n",
      "generated sequence: ing them,\n",
      "Hoisted sail and made away for Brittany.\n",
      "\n",
      "KING RICHARD III:\n",
      "March on, march on, since we are up in arms;\n",
      "If not to figoe\tb\t\t\tf\tB\n",
      "\n",
      "iter:16599/20000 loss:2.6148616909980773\n",
      "generated sequence: Your brother cannot live.\n",
      "\n",
      "ISABELLA:\n",
      "Even so. Heaven keep your honour!\n",
      "\n",
      "ANGELO:\n",
      "Yet may he live awhile; and, it may be,\n",
      "As long \t\ts\tbf\t\t\tf\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:16799/20000 loss:2.5945246148109438\n",
      "generated sequence: irst Senator:\n",
      "So, your opinion is, Aufidius,\n",
      "That they of Rome are entered in our counsels\n",
      "And know how we proceed.\n",
      "\n",
      "AUFIDIUS:\n",
      "Io\t\t\tbp\teu\t\n",
      "\n",
      "iter:16999/20000 loss:2.604461257457733\n",
      "generated sequence: ever.\n",
      "\n",
      "LADY ANNE:\n",
      "What is it?\n",
      "\n",
      "GLOUCESTER:\n",
      "That it would please thee leave these sad designs\n",
      "BBJ;\tm that hath more cause to be a\tf\t\t\n",
      "\n",
      "iter:17199/20000 loss:2.583492238521576\n",
      "generated sequence: y against our faces,\n",
      "Awaked the sleeping rheum, and so by chance\n",
      "Did grace our hollow parting with a tear.\n",
      "\n",
      "KING RICHARD II:\n",
      "Wha\tbu\tuoe\t\tb\n",
      "\n",
      "iter:17399/20000 loss:2.5989856719970703\n",
      "generated sequence: .\n",
      "\n",
      "EMILIA:\n",
      "Most worthy madam,\n",
      "Your honour and your goodness is so evident\n",
      "That your free undertaking cannot miss\n",
      "BBS\tOJOong issu\n",
      "\n",
      "iter:17599/20000 loss:2.607635314464569\n",
      "generated sequence: t,\n",
      "I have a king here to my flatterer.\n",
      "Being so great, I have no need to beg.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Yet ask.\n",
      "\n",
      "KING RICHARD II:\n",
      "And\t\tBOb\tuf\tb\n",
      "\n",
      "iter:17799/20000 loss:2.583098875284195\n",
      "generated sequence: upon my signories,\n",
      "Dispark'd my parks and fell'd my forest woods,\n",
      "From my own windows torn my household coat,\n",
      "Razed out my impresf\tebf\tb\to\n",
      "\n",
      "iter:17999/20000 loss:2.6112551856040955\n",
      "generated sequence: ple men!\n",
      "Yet nature might have made me as these are,\n",
      "Therefore I will not disdain.\n",
      "\n",
      "Clown:\n",
      "This cannot be but a great courtier.\n",
      "fm\tbf\te\tB\t\n",
      "\n",
      "iter:18199/20000 loss:2.5865639674663545\n",
      "generated sequence: Are servanted to others: though I owe\n",
      "My revenge properly, my remission lies\n",
      "In Volscian breasts. That we have been familiar,\n",
      "Ino\t\tb\t\t\tfue\n",
      "\n",
      "iter:18399/20000 loss:2.5998293602466584\n",
      "generated sequence: geance proud, and\n",
      "loves not the common people.\n",
      "\n",
      "Second Officer:\n",
      "Faith, there had been many great men that have\n",
      "flattered the peof\tuep\tuf\t\t\n",
      "\n",
      "iter:18599/20000 loss:2.5761983489990232\n",
      "generated sequence: ings serious, thou must\n",
      "know the king is full of grief.\n",
      "\n",
      "Shepard:\n",
      "So 'tis said, sir; about his son, that should have\n",
      "married a soe\t\tb\t\t\to\t\n",
      "\n",
      "iter:18799/20000 loss:2.5897002696990965\n",
      "generated sequence: r it was bad enough before their spite.\n",
      "\n",
      "PARIS:\n",
      "Thou wrong'st it, more than tears, with that report.\n",
      "\n",
      "JULIET:\n",
      "That is no slander\tbo\tbju\tbf\n",
      "\n",
      "iter:18999/20000 loss:2.583990453481674\n",
      "generated sequence: ge to my sinful soul!\n",
      "Now, lords, take leave until we meet again,\n",
      "Where'er it be, in heaven or in earth.\n",
      "\n",
      "RICHARD:\n",
      "Brother, givef\tu\t\tuf\tu\t\n",
      "\n",
      "iter:19199/20000 loss:2.582927553653717\n",
      "generated sequence: remes?\n",
      "Ah, wretched man! would I had died a maid\n",
      "And never seen thee, never borne thee son,\n",
      "Bof\tng thou hast proved so unnatural\t\tf\t\t\n",
      "\n",
      "iter:19399/20000 loss:2.5739325094223022\n",
      "generated sequence: , divine perfection of a woman,\n",
      "Of these supposed-evils, to give me leave,\n",
      "By circumstance, but to acquit myself.\n",
      "\n",
      "LADY ANNE:\n",
      "Vo\tu\tofoe\tuf\n",
      "\n",
      "iter:19599/20000 loss:2.5701375758647917\n",
      "generated sequence: reply.\n",
      "Farewell, my sovereign.\n",
      "\n",
      "KING HENRY VI:\n",
      "Farewell, my Hector, and my Troy's true hope.\n",
      "\n",
      "CLARENCE:\n",
      "B\tu\tign of truth, I kiss\t\tfm\t\n",
      "\n",
      "iter:19799/20000 loss:2.579923861026764\n",
      "generated sequence: d men may talk of kings, and why not I?\n",
      "\n",
      "Second Keeper:\n",
      "Ay, but thou talk'st as if thou wert a king.\n",
      "\n",
      "KING HENRY VI:\n",
      "Why, so I a\tb\t\teb\tu\tb\n",
      "\n",
      "iter:19999/20000 loss:2.5921884274482725\n",
      "generated sequence: NIO:\n",
      "O, widow Dido! ay, widow Dido.\n",
      "\n",
      "GONZALO:\n",
      "Is not, sir, my doublet as fresh as the first day I\n",
      "wore it? I mean, in a sort.\n",
      "\n",
      "B;\tb\to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,input,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhat, shall we stab him as he sleeps?\\n\\nFirst Murderer:\\nNo; then he will say 'twas done cowardly, when he wakes.\\n\\nSecond MurdereBifu\\t\\tu\\tfummuf\\tu\\t\\tufufofuu\\tuf\\tu\\tm\\t\\tf\\t\\tBBfo\\t\\t\\tu\\t\\t\\t\\t\\t\\t\\t\\t\\tBJ\\t\\tu\\t\\t\\t\\tu\\t\\tu\\to\\t\\tu\\tu\\tu\\t\\t\\tu\\tu\\t\\t\\t\\tuf\\t\\tu\\t\\t\\t\\t\\tu\\t\\t\\t\\tu\\t\\tu\\t\\t\\t\\t\\t\\rBB\\t\\tf\\t\\t\\tu\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tuu\\tu\\t\\t\\t\\t\\t\\tu\\tuu\\t\\t\\t\\t\\t\\t\\t\\tb\\t\\tb\\tb\\tbb\\tbb\\t\\t\\t\\tbbb\\tbbbbbbbbb\\t\\tbb\\tbbbb\\tbb\\tb\\tbb\\tb\\tb\\tbbb\\tb\\tbbbb\\t\\tbb\\tbbbbb\\tbbbb\\tbb\\tbbbbbU\\t\\tbb\\tbbb\\tbbbbbbbbbbb\\t\\tb\\tbbbbbb\\tb\\t\\tbbbbbbbb\\tbb\\tb\\tb\\t\\tb\\t\\tbbbb\\t\\t\\tb\\t\\t\\t\\t\\t\\t\\t\\t\\tbb\\t\\tb\\t\\t\\t\\tb\\t\\tb\\tb\\t\\tb\\tb\\tb\\t\\t\\tb\\tb\\t\\t\\t\\tbb\\t\\tb\\t\\t\\t\\t\\tb\\t\\t\\t\\tb\\t\\tb\\t\\t\\t\\t\\tibb\\t\\tb\\t\\t\\tb\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tbb\\tb\\t\\t\\t\\t\\t\\tb\\tbb\\t\\t\\t\\t\\t\\t\\t\\tb\\t\\tb\\tb\\tbb\\tbb\\t\\t\\t\\tbbb\\tbbbbbbbbb\\t\\tbb\\tbbbb\\tbb\\tb\\tbb\\tb\\tb\\tbbb\\tb\\tbbbb\\t\\tbb\\tbbbbb\\tbbbb\\tbb\\tbbbbb\\t\\t\\tbb\\tbbb\\tbbbbbbbbbbb\\t\\tb\\tbbbbbb\\tb\\t\\tbbbbbbbb\\tbb\\tb\\tb\\t\\tb\\t\\tbbbb\\t\\t\\tb\\t\\t\\t\\t\\t\\t\\t\\t\\tbb\\t\\tb\\t\\t\\t\\tb\\t\\tb\\tb\\t\\tb\\tb\\tb\\t\\t\\tb\\tb\\t\\t\\t\\tb\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "Follows the updated baseline, but uses SGD optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
