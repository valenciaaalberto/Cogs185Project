{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='W', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:2.8716147780418395\n",
      "generated sequence: ds my kinsman's.\n",
      "\n",
      "Clown:\n",
      "Shall I bring thee on the way?\n",
      "\n",
      "AUTOLYCUS:\n",
      "No, good-faced sir; no, sweet sir.\n",
      "\n",
      "Clown:\n",
      "Then fare thee we\t\txj\txjo\t\t\n",
      "\n",
      "iter:399/20000 loss:2.559115982055664\n",
      "generated sequence:  thou couldst not make him live;\n",
      "Therefore, have done: some grief shows much of love;\n",
      "But much of grief shows still some want ofu\t\t\tsuf\ts\t\n",
      "\n",
      "iter:599/20000 loss:2.51359216094017\n",
      "generated sequence: kest thou, will our friends prove all true?\n",
      "\n",
      "RATCLIFF:\n",
      "No doubt, my lord.\n",
      "\n",
      "KING RICHARD III:\n",
      "O Ratcliff, I fear, I fear,--\n",
      "\n",
      "RATCf\t\tiuifvs\t\n",
      "\n",
      "iter:799/20000 loss:2.436847913265228\n",
      "generated sequence: ,\n",
      "Under whose colours he had fought so long.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Why, bishop, is Norfolk dead?\n",
      "\n",
      "BISHOP OF CARLISLE:\n",
      "As surely as\tBT\t\t\tfu\t\t\n",
      "\n",
      "iter:999/20000 loss:2.3829994869232176\n",
      "generated sequence: ings to the bloody king.\n",
      "And here he comes.\n",
      "All hail, my sovereign liege!\n",
      "\n",
      "KING RICHARD III:\n",
      "Kind Tyrrel, am I happy in thy newso\tf\tu\tvu\tf\n",
      "\n",
      "iter:1199/20000 loss:2.361061148643494\n",
      "generated sequence:  part enforced to digress;\n",
      "Which, at more leisure, I will so excuse\n",
      "As you shall well be satisfied withal.\n",
      "But where is Kate? I ufuf\tu\tepv\n",
      "\n",
      "iter:1399/20000 loss:2.290382745862007\n",
      "generated sequence: tell me how I may prevent it:\n",
      "If, in thy wisdom, thou canst give no help,\n",
      "Do thou but call my resolution wise,\n",
      "And with this kni\t\t\t\tuf\tu\tv\n",
      "\n",
      "iter:1599/20000 loss:2.263740296959877\n",
      "generated sequence:  will sure run mad.\n",
      "\n",
      "BENVOLIO:\n",
      "Tybalt, the kinsman of old Capulet,\n",
      "Hath sent a letter to his father's house.\n",
      "\n",
      "MERCUTIO:\n",
      "A challeu\to\t\tufuf\t\n",
      "\n",
      "iter:1799/20000 loss:2.2629930424690246\n",
      "generated sequence:  himself?\n",
      "\n",
      "First Huntsman:\n",
      "Believe me, lord, I think he cannot choose.\n",
      "\n",
      "Second Huntsman:\n",
      "It would seem strange unto him when he ufof\t\tf\t\n",
      "\n",
      "iter:1999/20000 loss:2.1979590964317324\n",
      "generated sequence: ,\n",
      "And in his full and ripen'd years himself,\n",
      "No doubt, shall then and till then govern well.\n",
      "\n",
      "First Citizen:\n",
      "So stood the state \tB;\t\tuo\tuf\n",
      "\n",
      "iter:2199/20000 loss:2.184429467916489\n",
      "generated sequence: en in my mistress' case,\n",
      "Just in her case! O woful sympathy!\n",
      "Piteous predicament! Even so lies she,\n",
      "Blubbering and weeping, weep\tfuofuf\tuf\n",
      "\n",
      "iter:2399/20000 loss:2.1444961541891097\n",
      "generated sequence: KE OF YORK:\n",
      "Give me my boots, I say; saddle my horse.\n",
      "Now, by mine honour, by my life, by my troth,\n",
      "I will appeach the villain.\n",
      ";Ou;Fu\t;;;\n",
      "\n",
      "iter:2599/20000 loss:2.123731600046158\n",
      "generated sequence: Corioli, call him,\n",
      "With all the applause and clamour of the host,\n",
      "CAIUS MARCIUS CORIOLANUS! Bear\n",
      "The addition nobly ever!\n",
      "\n",
      "All:\n",
      "pvftvft\tuf\n",
      "\n",
      "iter:2799/20000 loss:2.0705910080671313\n",
      "generated sequence: y master sleep these tedious nights?\n",
      "\n",
      "Messenger:\n",
      "So it should seem by that I have to say.\n",
      "First, he commends him to your noble l\tubo\t\t\t\tu\t\n",
      "\n",
      "iter:2999/20000 loss:2.039390503168106\n",
      "generated sequence: friend Lucio.\n",
      "\n",
      "LUCIO:\n",
      "Within two hours.\n",
      "\n",
      "CLAUDIO:\n",
      "Come, officer, away!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "No, holy father; throw away that thoughtp\to\tf\tuBtl\n",
      "\n",
      "iter:3199/20000 loss:2.0382136690616606\n",
      "generated sequence: banquet is to close our stomachs up,\n",
      "After our great good cheer. Pray you, sit down;\n",
      "For now we sit to chat as well as eat.\n",
      "\n",
      "PETfuev\t\t\tuo\t\n",
      "\n",
      "iter:3399/20000 loss:2.0235158252716063\n",
      "generated sequence: d, you nod; you do not mind the play.\n",
      "\n",
      "SLY:\n",
      "Yes, by Saint Anne, do I. A good matter, surely:\n",
      "comes there any more of it?\n",
      "\n",
      "Page:\n",
      "\t\tu\t\t\tup\t\t\n",
      "\n",
      "iter:3599/20000 loss:1.9915307742357253\n",
      "generated sequence: thal\n",
      "Your high displeasure: all this uttered\n",
      "With gentle breath, calm look, knees humbly bow'd,\n",
      "Could not take truce with the unifm\tUpvsfu\n",
      "\n",
      "iter:3799/20000 loss:1.968647917509079\n",
      "generated sequence: ing gold\n",
      "Would tempt unto a close exploit of death?\n",
      "\n",
      "Page:\n",
      "My lord, I know a discontented gentleman,\n",
      "Whose humble means match nou\tfufsm\tui\n",
      "\n",
      "iter:3999/20000 loss:1.9323269546031951\n",
      "generated sequence: wore so loud,\n",
      "That, all-amazed, the priest let fall the book;\n",
      "And, as he stoop'd again to take it up,\n",
      "The mad-brain'd bridegroomfo\t\tufou\to\n",
      "\n",
      "iter:4199/20000 loss:1.9351764291524887\n",
      "generated sequence: we part?\n",
      "\n",
      "KING RICHARD II:\n",
      "Ay, hand from hand, my love, and heart from heart.\n",
      "\n",
      "QUEEN:\n",
      "Banish us both and send the king with me.\n",
      "HHufo\ti\n",
      "\n",
      "iter:4399/20000 loss:1.9315488052368164\n",
      "generated sequence:  being a little bad: so may my husband.\n",
      "O Isabel, will you not lend a knee?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "He dies for Claudio's death.\n",
      "\n",
      "ISABEuf\toefuou\t\n",
      "\n",
      "iter:4599/20000 loss:1.8932643842697143\n",
      "generated sequence: ife\n",
      "That thou art malcontent? I will provide thee.\n",
      "\n",
      "CLARENCE:\n",
      "In choosing for yourself, you show'd your judgment,\n",
      "Which being shop\tBiboiui\n",
      "\n",
      "iter:4799/20000 loss:1.877875144481659\n",
      "generated sequence: ling nature,\n",
      "Deformed, unfinish'd, sent before my time\n",
      "Into this breathing world, scarce half made up,\n",
      "And that so lamely and un\to\tiu\tois\t\n",
      "\n",
      "iter:4999/20000 loss:1.8641993486881256\n",
      "generated sequence: ean, in bearing weight of government,\n",
      "While he enjoys the honour and his ease.\n",
      "And, Clarence, now then it is more than needful\n",
      "F\tsu\tuouuf\t\n",
      "\n",
      "iter:5199/20000 loss:1.8608176451921463\n",
      "generated sequence: , but it is not known\n",
      "Whether for east or west: the dearth is great;\n",
      "The people mutinous; and it is rumour'd,\n",
      "Cominius, Marcius \tufmiuoiuo\n",
      "\n",
      "iter:5399/20000 loss:1.8503487676382064\n",
      "generated sequence: angeling:\n",
      "open't. What's within, boy?\n",
      "\n",
      "Clown:\n",
      "You're a made old man: if the sins of your youth\n",
      "Bre forgiven you, you're well to u\t\t\t\tu\t\t\n",
      "\n",
      "iter:5599/20000 loss:1.833314533829689\n",
      "generated sequence: ough thou hast suborn'd these women\n",
      "To accuse this worthy man, but, in foul mouth\n",
      "And in the witness of his proper ear,\n",
      "To call su\tfu\tfsuu\n",
      "\n",
      "iter:5799/20000 loss:1.819174873828888\n",
      "generated sequence:  we both lay in the field\n",
      "Frozen almost to death, how he did lap me\n",
      "Even in his own garments, and gave himself,\n",
      "All thin and nakuo\tufs\tfu\t\n",
      "\n",
      "iter:5999/20000 loss:1.8380569696426392\n",
      "generated sequence: G RICHARD III:\n",
      "But in your daughter's womb I bury them:\n",
      "Where in that nest of spicery they shall breed\n",
      "Selves of themselves, to PuJ\tVfoJpu\n",
      "\n",
      "iter:6199/20000 loss:1.8470537745952607\n",
      "generated sequence: ars,\n",
      "And he will make the face of heaven so fine\n",
      "That all the world will be in love with night\n",
      "And pay no worship to the garish u\tf\tBoefuf\n",
      "\n",
      "iter:6399/20000 loss:1.8130348551273345\n",
      "generated sequence: \n",
      "The hand was fair before! I have put you out:\n",
      "But to your protestation; let me hear\n",
      "What you profess.\n",
      "\n",
      "FLORIZEL:\n",
      "Do, and be witBBf\tufs\t\tu\n",
      "\n",
      "iter:6599/20000 loss:1.8180543065071106\n",
      "generated sequence: clogging burthen of a guilty soul.\n",
      "\n",
      "THOMAS MOWBRAY:\n",
      "No, Bolingbroke: if ever I were traitor,\n",
      "My name be blotted from the book ofpfvffupfuf\n",
      "\n",
      "iter:6799/20000 loss:1.8150688844919205\n",
      "generated sequence:  it you\n",
      "But for my brother not a man would speak,\n",
      "Nor I, ungracious, speak unto myself\n",
      "Fmr him, poor soul. The proudest of you auoiu\tom\n",
      "\n",
      "iter:6999/20000 loss:1.7793281078338623\n",
      "generated sequence: le queen\n",
      "Well struck in years, fair, and not jealous;\n",
      "We say that Shore's wife hath a pretty foot,\n",
      "A cherry lip, a bonny eye, a fsuvusspBi\n",
      "\n",
      "iter:7199/20000 loss:1.7617052906751633\n",
      "generated sequence:  ye; I am resolved:\n",
      "Go in, Bianca:\n",
      "And for I know she taketh most delight\n",
      "In music, instruments and poetry,\n",
      "uPusbumasters will Iu\ts\n",
      "\n",
      "iter:7399/20000 loss:1.754808970093727\n",
      "generated sequence: rther than you should.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Take not, good cousin, further than you should.\n",
      "Lest you mistake the heavens are o'er our \tff\t\tuffo\t\n",
      "\n",
      "iter:7599/20000 loss:1.7682681941986085\n",
      "generated sequence: ou, sir, he has as\n",
      "many friends as enemies; which friends, sir, as it\n",
      "were, durst not, look you, sir, show themselves, as\n",
      "we ter\t\t\tufu\t\tuf\n",
      "\n",
      "iter:7799/20000 loss:1.770442976951599\n",
      "generated sequence: th minister. Go call at Flavius' house,\n",
      "And tell him where I stay: give the like notice\n",
      "To Valentinus, Rowland, and to Crassus,\n",
      "i\tufoho\ti\t\n",
      "\n",
      "iter:7999/20000 loss:1.7623612827062607\n",
      "generated sequence: LAND:\n",
      "Yes, Warwick, I remember it to my grief;\n",
      "And, by his soul, thou and thy house shall rue it.\n",
      "\n",
      "WESTMORELAND:\n",
      "\t\t\t\ttagenet, ofBOJF\n",
      "\n",
      "iter:8199/20000 loss:1.7822056877613068\n",
      "generated sequence: help\n",
      "will serve; for once we stood up about the corn, he\n",
      "himself stuck not to call us the many-headed multitude.\n",
      "\n",
      "Third Citizen:\t\tm\tUjommu\n",
      "\n",
      "iter:8399/20000 loss:1.7425881159305572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence:  away.\n",
      "\n",
      "KING HENRY VI:\n",
      "Exeter, so will I.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Nay, go not from me; I will follow thee.\n",
      "\n",
      "KING HENRY VI:\n",
      "F\t patient, uopo\t\n",
      "\n",
      "iter:8599/20000 loss:1.7401128244400024\n",
      "generated sequence: oltheads and unmanner'd slaves!\n",
      "What, do you grumble? I'll be with you straight.\n",
      "\n",
      "KATHARINA:\n",
      "I pray you, husband, be not so disqv\tifso\t\tuo\n",
      "\n",
      "iter:8799/20000 loss:1.7295327126979827\n",
      "generated sequence: his manner to do so.\n",
      "\n",
      "Provost:\n",
      "His friends still wrought reprieves for him: and,\n",
      "indeed, his fact, till now in the government offd\tu\toee\t\t\n",
      "\n",
      "iter:8999/20000 loss:1.7293397122621537\n",
      "generated sequence: ll on thee.\n",
      "Farewell, York's wife, and queen of sad mischance:\n",
      "These English woes will make me smile in France.\n",
      "\n",
      "QUEEN ELIZABETH\t\tu\tfuif\t\t\n",
      "\n",
      "iter:9199/20000 loss:1.7266394859552383\n",
      "generated sequence: ee, how beastly she doth court him!\n",
      "\n",
      "HORTENSIO:\n",
      "Would all the world but he had quite forsworn!\n",
      "For me, that I may surely keep mi\t\t\tufofuf\t\n",
      "\n",
      "iter:9399/20000 loss:1.7242347472906112\n",
      "generated sequence: te and grinning at his pomp,\n",
      "Allowing him a breath, a little scene,\n",
      "To monarchize, be fear'd and kill with looks,\n",
      "Infusing him wb\tuou\tubft\n",
      "\n",
      "iter:9599/20000 loss:1.717454143166542\n",
      "generated sequence: peasant.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "My lord,--\n",
      "\n",
      "KING RICHARD II:\n",
      "No lord of thine, thou haught insulting man,\n",
      "Nor no man's lord; I have no\t\tu\tu\ti\n",
      "\n",
      "iter:9799/20000 loss:1.7060880547761916\n",
      "generated sequence: .\n",
      "\n",
      "PAULINA:\n",
      "Good my lord, forbear:\n",
      "The ruddiness upon her lip is wet;\n",
      "You'll mar it if you kiss it, stain your own\n",
      "BBfOTp\tFO pai\n",
      "\n",
      "iter:9999/20000 loss:1.718493435382843\n",
      "generated sequence: from the ends of opposed\n",
      "winds. The heavens continue their loves!\n",
      "\n",
      "ARCHIDAMUS:\n",
      "I think there is not in the world either malice offvfu\tf\tu\t\n",
      "\n",
      "iter:10199/20000 loss:1.6975013369321823\n",
      "generated sequence: d oft to kingly sepulchres;\n",
      "For who lived king, but I could dig his grave?\n",
      "And who durst mine when Warwick bent his brow?\n",
      "Lo, no\tugj\tu\tguf\n",
      "\n",
      "iter:10399/20000 loss:1.7285635447502137\n",
      "generated sequence: S:\n",
      "I shall, sir. Fare you well.\n",
      "\n",
      "ANGELO:\n",
      "Good night.\n",
      "This deed unshapes me quite, makes me unpregnant\n",
      "\tu\tfu\t\tl to all proceeding;\n",
      "\n",
      "iter:10599/20000 loss:1.6841872423887252\n",
      "generated sequence: his is known, then to divide the times:\n",
      "So many hours must I tend my flock;\n",
      "So many hours must I take my rest;\n",
      "So many hours musfu\tuu\tu\t\te\n",
      "\n",
      "iter:10799/20000 loss:1.6974555081129075\n",
      "generated sequence: \n",
      "man and his son aboard the prince: told him I heard\n",
      "them talk of a fardel and I know not what: but he\n",
      "fu\tuu\t\tupime, overfond of\n",
      "\n",
      "iter:10999/20000 loss:1.668693136572838\n",
      "generated sequence: instant of their master's death and\n",
      "in the view of the shepherd: so that all the\n",
      "instruments which aided to expose the child wero\t\tio\tiuvp\n",
      "\n",
      "iter:11199/20000 loss:1.6691780960559846\n",
      "generated sequence:  hath the prettiest sententious of\n",
      "it, of you and rosemary, that it would do you good\n",
      "to hear it.\n",
      "\n",
      "ROMEO:\n",
      "Commend me to thy ladyubo\tbu\tb\tu\n",
      "\n",
      "iter:11399/20000 loss:1.7065754699707032\n",
      "generated sequence:  dissolution hangeth over him.\n",
      "\n",
      "LORD ROSS:\n",
      "He hath not money for these Irish wars,\n",
      "His burthenous taxations notwithstanding,\n",
      "Butu\tw\t\tvjmiw\n",
      "\n",
      "iter:11599/20000 loss:1.6996458178758622\n",
      "generated sequence: terrors to\n",
      "me: for the life to come, I sleep out the thought\n",
      "of it. A prize! a prize!\n",
      "\n",
      "Clown:\n",
      "Let me see: every 'leven wether to\t\t\t\tv\t\tu\tv\n",
      "\n",
      "iter:11799/20000 loss:1.6778281486034394\n",
      "generated sequence: beg of God,\n",
      "When I am cold in zeal to yours.\n",
      "\n",
      "KING EDWARD IV:\n",
      "A pleasing cordial, princely Buckingham,\n",
      "is this thy vow unto my sf\tfuspuZs\t\n",
      "\n",
      "iter:11999/20000 loss:1.6700532579421996\n",
      "generated sequence: Is't meet that he\n",
      "Should leave the helm and like a fearful lad\n",
      "With tearful eyes add water to the sea\n",
      "And give more strength to \t\tt\tt;\t\t\tt\n",
      "\n",
      "iter:12199/20000 loss:1.676688923239708\n",
      "generated sequence: nder'd friends should dwell upon:\n",
      "God give us leisure for these rites of love!\n",
      "Once more, adieu: be valiant, and speed well!\n",
      "\n",
      "RIe\t\t\tt\tuj\to\n",
      "\n",
      "iter:12399/20000 loss:1.6775812590122223\n",
      "generated sequence: elf disposed to sleep.\n",
      "\n",
      "ANTONIO:\n",
      "Nor I; my spirits are nimble.\n",
      "They fell together all, as by consent;\n",
      "They dropp'd, as by a thun\tp\tuftffvf\n",
      "\n",
      "iter:12599/20000 loss:1.6712847781181335\n",
      "generated sequence: 's life:\n",
      "Might there not be a charity in sin\n",
      "To save this brother's life?\n",
      "\n",
      "ISABELLA:\n",
      "Please you to do't,\n",
      "b'll take it as a perile\tufup\t\t\n",
      "\n",
      "iter:12799/20000 loss:1.6544450312852859\n",
      "generated sequence: Happy, indeed, as we have spent the day.\n",
      "Brother, we done deeds of charity;\n",
      "Made peace enmity, fair love of hate,\n",
      "Between these boppp\tuo\t\t\n",
      "\n",
      "iter:12999/20000 loss:1.6360522001981734\n",
      "generated sequence: efits to thee, for I will fight\n",
      "Against my canker'd country with the spleen\n",
      "Of all the under fiends. But if so be\n",
      "Thou darest no\t\toi\tui\tui\n",
      "\n",
      "iter:13199/20000 loss:1.6341787046194076\n",
      "generated sequence: here was left by the sailors. Thou, my slave,\n",
      "As thou report'st thyself, wast then her servant;\n",
      "And, for thou wast a spirit too b\t\t\tu\topuz\n",
      "\n",
      "iter:13399/20000 loss:1.6586083436012269\n",
      "generated sequence: of me.\n",
      "\n",
      "PETRUCHIO:\n",
      "Why, true; he means to make a puppet of thee.\n",
      "\n",
      "Tailor:\n",
      "She says your worship means to make\n",
      "a puppet of her.\n",
      "\n",
      "sOuf\t\n",
      "\n",
      "iter:13599/20000 loss:1.6360487419366836\n",
      "generated sequence: s foul murder comes.\n",
      "\n",
      "First Watchman:\n",
      "Here is a friar, and slaughter'd Romeo's man;\n",
      "With instruments upon them, fit to open\n",
      "Thes\tu\tes\tuzs\t\n",
      "\n",
      "iter:13799/20000 loss:1.6434365355968474\n",
      "generated sequence: \n",
      "As is the spring to the earth. And hath he too\n",
      "Exposed this paragon to the fearful usage,\n",
      "o\tuo\tu\tjsungentle, of the dreadful Ne\n",
      "\n",
      "iter:13999/20000 loss:1.634923050403595\n",
      "generated sequence: ding-hearts; thereon engrave\n",
      "Edward and York; then haply she will weep:\n",
      "Therefore present to her--as sometime Margaret\n",
      "Did to th\toufif\to\ti\n",
      "\n",
      "iter:14199/20000 loss:1.6454864674806595\n",
      "generated sequence: \n",
      "\n",
      "EXETER:\n",
      "They seek revenge and therefore will not yield.\n",
      "\n",
      "KING HENRY VI:\n",
      "Ah, Exeter!\n",
      "\n",
      "WARWICK:\n",
      "Why should you sigh, my lord?\n",
      "\n",
      ";J;i;B\n",
      "\n",
      "iter:14399/20000 loss:1.640064268708229\n",
      "generated sequence: ers.\n",
      "The earth that's nature's mother is her tomb;\n",
      "What is her burying grave that is her womb,\n",
      "Up\t\tu\tom her womb children of div\tf\t\n",
      "\n",
      "iter:14599/20000 loss:1.6058974194526672\n",
      "generated sequence: ld.\n",
      "\n",
      "DORCAS:\n",
      "Bless me from marrying a usurer!\n",
      "\n",
      "AUTOLYCUS:\n",
      "Here's the midwife's name to't, one Mistress\n",
      "pSJJSporter, and five or \t\t\n",
      "\n",
      "iter:14799/20000 loss:1.660889823436737\n",
      "generated sequence: e speak.\n",
      "\n",
      "First Lord:\n",
      "O Tullus,--\n",
      "\n",
      "Second Lord:\n",
      "Thou hast done a deed whereat valour will weep.\n",
      "\n",
      "Third Lord:\n",
      "Tread not upon him.\tu\tb\tsf\n",
      "\n",
      "iter:14999/20000 loss:1.6259252035617828\n",
      "generated sequence: nvious worm,\n",
      "Ere he can spread his sweet leaves to the air,\n",
      "Or dedicate his beauty to the sun.\n",
      "Could we but learn from whence hihfov\t\tiiv\t\n",
      "\n",
      "iter:15199/20000 loss:1.6365996688604354\n",
      "generated sequence: h these my proper hands\n",
      "Shall I dash out. Go, take it to the fire;\n",
      "For thou set'st on thy wife.\n",
      "\n",
      "ANTIGONUS:\n",
      "I did not, sir:\n",
      "Thesfu\tf\t\t\tub\t\n",
      "\n",
      "iter:15399/20000 loss:1.626577659845352\n",
      "generated sequence:  shall mingle tears with smiles,\n",
      "Where great patricians shall attend and shrug,\n",
      "I' the end admire, where ladies shall be frighteu\tfs\t\tufoe\n",
      "\n",
      "iter:15599/20000 loss:1.6462505680322648\n",
      "generated sequence: sed this paragon to the fearful usage,\n",
      "At least ungentle, of the dreadful Neptune,\n",
      "To greet a man not worth her pains, much less\t\tfuifo\tup\n",
      "\n",
      "iter:15799/20000 loss:1.6254859471321106\n",
      "generated sequence: be low.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "My gracious lord, I come but for mine own.\n",
      "\n",
      "KING RICHARD II:\n",
      "UU;r own is yours, and I am yours, and f\tu\t\tj\n",
      "\n",
      "iter:15999/20000 loss:1.625109521150589\n",
      "generated sequence: ashamed that women are so simple\n",
      "To offer war where they should kneel for peace;\n",
      "Or seek for rule, supremacy and sway,\n",
      "When theys\tfsfs\tu\tf\n",
      "\n",
      "iter:16199/20000 loss:1.5948173892498017\n",
      "generated sequence:  and four wanton springs\n",
      "End in a word: such is the breath of kings.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "I thank my liege, that in regard of me\n",
      "He suo\t\tujv\t\tu\n",
      "\n",
      "iter:16399/20000 loss:1.599037799835205\n",
      "generated sequence: ll not do't,\n",
      "Lest I surcease to honour mine own truth\n",
      "And by my body's action teach my mind\n",
      "A most inherent baseness.\n",
      "\n",
      "VOLUMNIA:mmueviu\tve\n",
      "\n",
      "iter:16599/20000 loss:1.642386301755905\n",
      "generated sequence:  a kiss 'twas made.\n",
      "Part us, Northumberland; I toward the north,\n",
      "Where shivering cold and sickness pines the clime;\n",
      "My wife to Fuou\to\t\tuei\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:16799/20000 loss:1.6092392069101333\n",
      "generated sequence: GLOUCESTER:\n",
      "Look to the drawbridge there!\n",
      "\n",
      "BUCKINGHAM:\n",
      "Hark! a drum.\n",
      "\n",
      "GLOUCESTER:\n",
      "Catesby, o'erlook the walls.\n",
      "\n",
      "BUCKINGHAM:\n",
      "LordIP\tqBU;pUJ\n",
      "\n",
      "iter:16999/20000 loss:1.6091356152296066\n",
      "generated sequence: I have a husband for the elder:\n",
      "If either of you both love Katharina,\n",
      "Because I know you well and love you well,\n",
      "Leave shall youJufofououf\n",
      "\n",
      "iter:17199/20000 loss:1.6020760571956634\n",
      "generated sequence: yself;\n",
      "And so, have at thee!\n",
      "\n",
      "RICHARD:\n",
      "Nay Warwick, single out some other chase;\n",
      "For I myself will hunt this wolf to death.\n",
      "o\t\tI\t\t\tep\t\n",
      "\n",
      "iter:17399/20000 loss:1.611564952135086\n",
      "generated sequence: k'd the dead bones that lay scatter'd by.\n",
      "\n",
      "BRAKENBURY:\n",
      "Had you such leisure in the time of death\n",
      "To gaze upon the secrets of theju\tu\tb\tu\t\t\n",
      "\n",
      "iter:17599/20000 loss:1.6052068042755128\n",
      "generated sequence: this news\n",
      "which is called true is so like an old tale, that\n",
      "the verity of it is in strong suspicion: has the king\n",
      "found his heirift\tuu\tj\t\n",
      "\n",
      "iter:17799/20000 loss:1.601696194410324\n",
      "generated sequence: r reign our king;\n",
      "But we will plant some other in the throne,\n",
      "To the disgrace and downfall of your house:\n",
      "And in this resolution\tu\t\tof\tuou\n",
      "\n",
      "iter:17999/20000 loss:1.6123298969864845\n",
      "generated sequence:  soul so blind,\n",
      "That thou wilt war with God by murdering me?\n",
      "Ah, sirs, consider, he that set you on\n",
      "To do this deed will hate you\t\ttfu\t\tuf\n",
      "\n",
      "iter:18199/20000 loss:1.583240116238594\n",
      "generated sequence: ore many gentlemen, myself being one,\n",
      "In hand and hope of action: but we do learn\n",
      "By those that know the very nerves of state,\n",
      "Hs\t\tuzze\tu\t\n",
      "\n",
      "iter:18399/20000 loss:1.5913790452480316\n",
      "generated sequence: e night's black mantle,\n",
      "At unawares may beat down Edward's guard\n",
      "And seize himself; I say not, slaughter him,\n",
      "For I intend but o\tu\to\tf\tt\tu\n",
      "\n",
      "iter:18599/20000 loss:1.5817081719636916\n",
      "generated sequence: y, but not frighted me; therefore I'll sleep again.\n",
      "\n",
      "PETRUCHIO:\n",
      "Nay, that you shall not: since you have begun,\n",
      "Have at you for a\t\ttfu\tt\tv\t\n",
      "\n",
      "iter:18799/20000 loss:1.585128076672554\n",
      "generated sequence: serve, love and obey.\n",
      "Why are our bodies soft and weak and smooth,\n",
      "Unapt to toil and trouble in the world,\n",
      "But that our soft con\t\t\tf\t\tu\t\tf\n",
      "\n",
      "iter:18999/20000 loss:1.5905480057001113\n",
      "generated sequence: tice of your dealing?\n",
      "\n",
      "Provost:\n",
      "But what likelihood is in that?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Not a resemblance, but a certainty. Yet since Iiof\tuv\tu\tv\n",
      "\n",
      "iter:19199/20000 loss:1.5744314110279083\n",
      "generated sequence: uctions dangerous,\n",
      "By drunken prophecies, libels and dreams,\n",
      "To set my brother Clarence and the king\n",
      "In deadly hate the one agaiufiove\tu\tu\n",
      "\n",
      "iter:19399/20000 loss:1.5722975957393646\n",
      "generated sequence: ad midnight.\n",
      "Cold fearful drops stand on my trembling flesh.\n",
      "What do I fear?  myself?  there's none else by:\n",
      "Richard loves Richas\tufo\t\toi\t\n",
      "\n",
      "iter:19599/20000 loss:1.580447678565979\n",
      "generated sequence: truth\n",
      "To God, my king and my succeeding issue,\n",
      "Against the Duke of Hereford that appeals me\n",
      "Jvu\t by the grace of God and this mi\t\ts\t\t\n",
      "\n",
      "iter:19799/20000 loss:1.5896363952755928\n",
      "generated sequence:  ever dragon keep so fair a cave?\n",
      "Beautiful tyrant! fiend angelical!\n",
      "Dove-feather'd raven! wolvish-ravening lamb!\n",
      "Despised substu\tf\tfu\tfsf\n",
      "\n",
      "iter:19999/20000 loss:1.5619075584411621\n",
      "generated sequence:  his man.\n",
      "\n",
      "MERCUTIO:\n",
      "Ah, that same pale hard-hearted wench, that Rosaline.\n",
      "Torments him so, that he will sure run mad.\n",
      "\n",
      "BENVOLIOubu\tu\toe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,input,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first merriment hath made thee jealous.\\n\\nHORTENSIO:\\nWell, Petruchio, this has put me in heart.\\nHave to my widow! and if she be f\\tu\\t\\t\\tu\\t\\t\\t\\tu\\t\\te\\tubo\\tbu\\to\\t\\tu\\tb\\t\\tup\\to\\tvs\\t\\r\\r\\rfMFiMHi\\tM\\r\\ri\\t\\t\\t\\tub\\t\\t\\tslbuv\\tu\\tbu\\tubo\\tubs\\tu\\t\\tuueub\\to\\t\\t\\r\\rfof\\tu\\tvu\\t\\tuju\\tvj\\ruoe\\tuu\\tu\\tb\\tub\\tu\\tu\\tuuu\\tuuuu\\tuu\\tu\\toeuo\\tueuu\\tuouu\\tvueus\\tu\\r\\r\\r\\tPMbP\\tbuP\\r\\rbuuuu\\touuu\\t\\to\\tsu\\tuo\\tu\\toeu\\to\\tu\\tuu\\t\\t\\t\\toueuu\\r\\r\\te\\tu\\tus\\tuu\\tu\\tusu\\r\\te\\tu\\t\\tu\\tuou\\tou\\tu\\tu\\t\\t\\tu\\t\\t\\t\\tu\\t\\tu\\tue\\t\\teu\\t\\t\\t\\tu\\te\\t\\tus\\t\\t\\t\\tu\\t\\r\\r\\ruMPoMuo\\tM\\r\\ro\\t\\t\\t\\tue\\t\\t\\tuueu\\t\\tu\\teu\\tue\\t\\tueu\\tu\\t\\tuuuue\\t\\t\\t\\t\\r\\ru\\tu\\tu\\t\\tu\\t\\tu\\tu\\t\\t\\t\\ru\\tu\\tuu\\tu\\te\\tue\\tu\\tu\\tuuu\\tuuuu\\tuu\\tu\\t\\tuu\\t\\tuuuu\\tu\\tuu\\t\\tuuuu\\tu\\r\\r\\r\\tPMeP\\teuP\\r\\reuuuu\\t\\tuuu\\t\\t\\t\\tuu\\tu\\t\\tu\\t\\tuu\\t\\t\\tu\\tuu\\t\\t\\t\\t\\tuuuu\\r\\r\\tu\\tu\\tuu\\tuu\\tu\\tuuu\\r\\tu\\tu\\t\\tu\\tu\\tu\\t\\tu\\tu\\tu\\t\\t\\tu\\t\\t\\t\\tu\\t\\tu\\tuu\\t\\tuu\\t\\t\\t\\tu\\tu\\t\\tuu\\t\\t\\t\\tu\\t\\r\\r\\ruMP\\tMu\\t\\tM\\r\\r\\t\\t\\t\\t\\tuu\\t\\t\\tuuuu\\t\\tu\\tuu\\tuu\\t\\tuuu\\tu\\t\\tuuuu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_target,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "Follows the updated baseline, but uses AdamW optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
