{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = src_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "# d_ff = 2048\n",
    "# d_ff = 128\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='Wha', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:3.086785043478012\n",
      "generated sequence: sooner confess: perchance, publicly,\n",
      "she'll be ashamed.\n",
      "\n",
      "ESCALUS:\n",
      "I will go darkly to work with her.\n",
      "\n",
      "LUCIO:\n",
      "That's the way; for\tvve\t\tuive\n",
      "\n",
      "iter:399/20000 loss:2.713742332458496\n",
      "generated sequence: tion, wheresoe'er I meet thee--\n",
      "As I will meet thee, if thou stir abroad--\n",
      "To plague thee for thy foul misleading me.\n",
      "And so, priov\t\tuff\t\t\n",
      "\n",
      "iter:599/20000 loss:2.622328419685364\n",
      "generated sequence: hou, Angelo?\n",
      "Dost thou desire her foully for those things\n",
      "That make her good? O, let her brother live!\n",
      "Thieves for their robberyfv\t\tio\ti\t\t\n",
      "\n",
      "iter:799/20000 loss:2.573958104848862\n",
      "generated sequence: h, like unruly children, make their sire\n",
      "Stoop with oppression of their prodigal weight:\n",
      "Give some supportance to the bending twf\tu\to\t\tu\t\t\n",
      "\n",
      "iter:999/20000 loss:2.5554305708408354\n",
      "generated sequence: wers\n",
      "Are enter'd in the Roman territories,\n",
      "And with the deepest malice of the war\n",
      "Destroy what lies before 'em.\n",
      "\n",
      "MENENIUS:\n",
      "'Tis f\tf\tBof\tu\t\n",
      "\n",
      "iter:1199/20000 loss:2.537337634563446\n",
      "generated sequence: de: O that you\n",
      "could turn your eyes toward the napes of your necks,\n",
      "and make but an interior survey of your good selves!\n",
      "p;p\t\to\t\t\t\n",
      "\n",
      "iter:1399/20000 loss:2.55004718542099\n",
      "generated sequence: im hence;\n",
      "And once again proclaim us King of England.\n",
      "You are the fount that makes small brooks to flow:\n",
      "Now stops thy spring; mozub\tei\t\tB\n",
      "\n",
      "iter:1599/20000 loss:2.527719122171402\n",
      "generated sequence: when 'tis back'd with France.\n",
      "\n",
      "HASTINGS:\n",
      "'Tis better using France than trusting France:\n",
      "Let us be back'd with God and with the s\t\t\t\tue\to\tu\n",
      "\n",
      "iter:1799/20000 loss:2.5190836250782014\n",
      "generated sequence: rgundy will yield him help,\n",
      "And we shall have more wars before 't be long.\n",
      "As Henry's late presaging prophecy\n",
      "Did glad my heart \t\tse\t\ti\to\t\n",
      "\n",
      "iter:1999/20000 loss:2.517367205619812\n",
      "generated sequence: this while hath revell'd in the night\n",
      "Whilst we were wandering with the antipodes,\n",
      "Shall see us rising in our throne, the east,\n",
      "ifo\tijfof\t\n",
      "\n",
      "iter:2199/20000 loss:2.4869439601898193\n",
      "generated sequence: !\n",
      "\n",
      "HORTENSIO:\n",
      "Would all the world but he had quite forsworn!\n",
      "For me, that I may surely keep mine oath,\n",
      "BBB;JiO\t; married to a we\n",
      "\n",
      "iter:2399/20000 loss:2.471198732852936\n",
      "generated sequence: queen of sad mischance:\n",
      "These English woes will make me smile in France.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "O thou well skill'd in curses, stay av\t\t\t\tu\t\tu\t\n",
      "\n",
      "iter:2599/20000 loss:2.474139837026596\n",
      "generated sequence: g.\n",
      "\n",
      "MERCUTIO:\n",
      "Thou art like one of those fellows that when he\n",
      "enters the confines of a tavern claps me his sword\n",
      "BBJOJFTi table i\n",
      "\n",
      "iter:2799/20000 loss:2.45435776591301\n",
      "generated sequence: bed, and like the owl by day,\n",
      "If he arise, be mock'd and wonder'd at.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Thanks, gentle Somerset; sweet Oxford, thf\t\t\tuoe\tuf\n",
      "\n",
      "iter:2999/20000 loss:2.451379323005676\n",
      "generated sequence: irt\n",
      "to pluck him off me, how he swore, how she prayed,\n",
      "that never prayed before, how I cried, how the\n",
      "horses ran away, how her bt\tiUi\tif\t\t\n",
      "\n",
      "iter:3199/20000 loss:2.4534104084968567\n",
      "generated sequence: nd Cytherea all in sedges hid,\n",
      "Which seem to move and wanton with her breath,\n",
      "Even as the waving sedges play with wind.\n",
      "\n",
      "Lord:\n",
      "We\tiF\tif\tf\t\n",
      "\n",
      "iter:3399/20000 loss:2.4491422069072724\n",
      "generated sequence: hout\n",
      "bawdry, which is strange; with such delicate\n",
      "burthens of dildos and fadings, 'jump her and thump\n",
      "her;' and where some stretfvsiUfoj\tf\n",
      "\n",
      "iter:3599/20000 loss:2.4524659061431886\n",
      "generated sequence: nour, O, that ever I\n",
      "Had squared me to thy counsel! then, even now,\n",
      "I might have look'd upon my queen's full eyes,\n",
      "Have taken tr\tvuf\tu;\tu\t\n",
      "\n",
      "iter:3799/20000 loss:2.424152811765671\n",
      "generated sequence: Nay, but hear me.\n",
      "Your sense pursues not mine: either you are ignorant,\n",
      "Or seem so craftily; and that's not good.\n",
      "\n",
      "ISABELLA:\n",
      "Let\to\t\tpfs\tpf\n",
      "\n",
      "iter:3999/20000 loss:2.4374083948135374\n",
      "generated sequence: st thing.\n",
      "\n",
      "SICINIUS:\n",
      "This is most likely!\n",
      "\n",
      "BRUTUS:\n",
      "Raised only, that the weaker sort may wish\n",
      "Good Marcius home again.\n",
      "\n",
      "BICINIUS\tiuibtei\n",
      "\n",
      "iter:4199/20000 loss:2.426863032579422\n",
      "generated sequence: ONSO:\n",
      "You cram these words into mine ears against\n",
      "The stomach of my sense. Would I had never\n",
      "Married my daughter there! for, com;\t;;\tB\tvsp\n",
      "\n",
      "iter:4399/20000 loss:2.41280368745327\n",
      "generated sequence: ill be there, I know.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "If God prevent not, I purpose so.\n",
      "\n",
      "DUKE OF YORK:\n",
      "What seal is that, that hangs without tu\t\tuf\tu\tf\t\n",
      "\n",
      "iter:4599/20000 loss:2.4144055855274202\n",
      "generated sequence: holy to your business,\n",
      "Not changing heart with habit, I am still\n",
      "Attorney'd at your service.\n",
      "\n",
      "ISABELLA:\n",
      "O, give me pardon,\n",
      "That bvj\tuivu\tv\n",
      "\n",
      "iter:4799/20000 loss:2.4169335532188416\n",
      "generated sequence: the state, who care for you like fathers,\n",
      "When you curse them as enemies.\n",
      "\n",
      "First Citizen:\n",
      "Care for us! True, indeed! They ne'er if\tufioi\t\t\n",
      "\n",
      "iter:4999/20000 loss:2.406933591365814\n",
      "generated sequence: nd that the Lord of Westmoreland shall maintain.\n",
      "\n",
      "WARWICK:\n",
      "And Warwick shall disprove it. You forget\n",
      "That we are those which chae\tuibuiuib\n",
      "\n",
      "iter:5199/20000 loss:2.415013142824173\n",
      "generated sequence:  loss, the gain, the ordering on't, is all\n",
      "Properly ours.\n",
      "\n",
      "ANTIGONUS:\n",
      "And I wish, my liege,\n",
      "You had only in your silent judgmentufo\t\t\tu\tf\t\n",
      "\n",
      "iter:5399/20000 loss:2.4023242557048796\n",
      "generated sequence: reat\n",
      "difference betwixt our Bohemia and your Sicilia.\n",
      "\n",
      "CAMILLO:\n",
      "I think, this coming summer, the King of Sicilia\n",
      "means to pay Boj\tujB\tojj\t\n",
      "\n",
      "iter:5599/20000 loss:2.400699961185455\n",
      "generated sequence: t, sir. You denied to fight with me\n",
      "this other day, because I was no gentleman born.\n",
      "upv you these clothes? say you see them not\t\tufof\n",
      "\n",
      "iter:5799/20000 loss:2.3898589396476746\n",
      "generated sequence: TES:\n",
      "Cease; no more.\n",
      "You smell this business with a sense as cold\n",
      "As is a dead man's nose: but I do see't and feel't\n",
      "As you feelpO;\tBF\to\t\t\n",
      "\n",
      "iter:5999/20000 loss:2.386166853904724\n",
      "generated sequence: been\n",
      "Deceived in thy integrity, deceived\n",
      "In that which seems so.\n",
      "\n",
      "CAMILLO:\n",
      "Be it forbid, my lord!\n",
      "\n",
      "LEONTES:\n",
      "To bide upon't, thouf\t\teB\t\tf\tu\n",
      "\n",
      "iter:6199/20000 loss:2.3854970002174376\n",
      "generated sequence: ll believe thee, Isabel?\n",
      "My unsoil'd name, the austereness of my life,\n",
      "My vouch against you, and my place i' the state,\n",
      "Will so ffuf\tft\tf\t\n",
      "\n",
      "iter:6399/20000 loss:2.376372448205948\n",
      "generated sequence: py time;\n",
      "The rather for I have some sport in hand\n",
      "Wherein your cunning can assist me much.\n",
      "There is a lord will hear you play tob\tiiof\t\tUi\n",
      "\n",
      "iter:6599/20000 loss:2.3818966507911683\n",
      "generated sequence: d yet go current from suspicion!\n",
      "\n",
      "DORSET:\n",
      "A boon, my sovereign, for my service done!\n",
      "\n",
      "KING EDWARD IV:\n",
      "I pray thee, peace: my sou\tu\t\t\tufsuf\n",
      "\n",
      "iter:6799/20000 loss:2.379058847427368\n",
      "generated sequence: hough I cannot,\n",
      "Myself to be a marvellous proper man.\n",
      "I'll be at charges for a looking-glass,\n",
      "And entertain some score or two offssffp\tpfo\n",
      "\n",
      "iter:6999/20000 loss:2.3820368099212645\n",
      "generated sequence: g Richard down.\n",
      "Post you to London, and you will find it so;\n",
      "I speak no more than every one doth know.\n",
      "\n",
      "QUEEN:\n",
      "Nimble mischance,ppJopfop\tp\n",
      "\n",
      "iter:7199/20000 loss:2.368713220357895\n",
      "generated sequence: our purpose.'\n",
      "\n",
      "KING RICHARD III:\n",
      "He was in the right; and so indeed it is.\n",
      "Ten the clock there. Give me a calendar.\n",
      "Who saw the \t\tfuf\tff\t\t\n",
      "\n",
      "iter:7399/20000 loss:2.375953905582428\n",
      "generated sequence: ; go:\n",
      "Be quiet, or--More light, more light! For shame!\n",
      "I'll make you quiet. What, cheerly, my hearts!\n",
      "\n",
      "TYBALT:\n",
      "UFsuvnce perforce\tufs\n",
      "\n",
      "iter:7599/20000 loss:2.36144566655159\n",
      "generated sequence: am sure, thou art:\n",
      "If murdering innocents be executing,\n",
      "Why, then thou art an executioner.\n",
      "\n",
      "GLOUCESTER:\n",
      "Thy son I kill'd for hisofufsfs\tui\n",
      "\n",
      "iter:7799/20000 loss:2.3629815405607224\n",
      "generated sequence: ' take heed\n",
      "he hear us not, 'regia,' presume not, 'celsa senis,'\n",
      "despair not.\n",
      "\n",
      "HORTENSIO:\n",
      "Madam, 'tis now in tune.\n",
      "\n",
      "LUCENTIO:\n",
      "Altufof\tuf\t\t\n",
      "\n",
      "iter:7999/20000 loss:2.3537666463851927\n",
      "generated sequence: ering\n",
      "Becomes not Rome, nor has Coriolanus\n",
      "Deserved this so dishonour'd rub, laid falsely\n",
      "I' the plain way of his merit.\n",
      "\n",
      "CORIOL\tfopiBF\tis\n",
      "\n",
      "iter:8199/20000 loss:2.3510732674598693\n",
      "generated sequence: ery well.\n",
      "\n",
      "ANTONIO:\n",
      "And most chirurgeonly.\n",
      "\n",
      "GONZALO:\n",
      "It is foul weather in us all, good sir,\n",
      "When you are cloudy.\n",
      "\n",
      "SEBASTIAN:\n",
      "Bo\tf\tuj\t\t\t\n",
      "\n",
      "iter:8399/20000 loss:2.3412775814533235\n",
      "generated sequence: seal'd up,\n",
      "Shall the contents discover, something rare\n",
      "Even then will rush to knowledge. Go: fresh horses!\n",
      "And gracious be the if\tofe\tusf\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8599/20000 loss:2.3293500101566313\n",
      "generated sequence: IOLANUS:\n",
      "I'll give my reasons,\n",
      "More worthier than their voices. They know the corn\n",
      "Was not our recompense, resting well assured\n",
      "U\tpopT;\n",
      "\n",
      "iter:8799/20000 loss:2.3389035832881926\n",
      "generated sequence: ul old master? yes, marry, sir:\n",
      "see where he looks out of the window.\n",
      "\n",
      "VINCENTIO:\n",
      "Is't so, indeed.\n",
      "\n",
      "BIONDELLO:\n",
      "Help, help, help!sfusf\tufuf\n",
      "\n",
      "iter:8999/20000 loss:2.3217834562063215\n",
      "generated sequence: l perform.\n",
      "\n",
      "WARWICK:\n",
      "Long live King Henry! Plantagenet embrace him.\n",
      "\n",
      "KING HENRY VI:\n",
      "And long live thou and these thy forward sonfuf\tf\toff\n",
      "\n",
      "iter:9199/20000 loss:2.3152702754735945\n",
      "generated sequence: o cure that blow of thine.\n",
      "Hath any well-advised friend proclaim'd\n",
      "Reward to him that brings the traitor in?\n",
      "\n",
      "Third Messenger:\n",
      "Ssuisjsuibu\n",
      "\n",
      "iter:9399/20000 loss:2.3292511093616484\n",
      "generated sequence: ormer; but she shall be such\n",
      "As, walk'd your first queen's ghost,\n",
      "it should take joy\n",
      "To see her in your arms.\n",
      "\n",
      "LEONTES:\n",
      "My true vf\t\tf\tuft\t\n",
      "\n",
      "iter:9599/20000 loss:2.310695180892944\n",
      "generated sequence: h cloud my joys with danger and with sorrow.\n",
      "\n",
      "KING EDWARD IV:\n",
      "My love, forbear to fawn upon their frowns:\n",
      "What danger or what sobxi\tss\tx\t\t\n",
      "\n",
      "iter:9799/20000 loss:2.3133067029714582\n",
      "generated sequence: :\n",
      "The appellant in all duty greets your highness,\n",
      "And craves to kiss your hand and take his leave.\n",
      "\n",
      "KING RICHARD II:\n",
      "We will des\tBif\tbobb\t\n",
      "\n",
      "iter:9999/20000 loss:2.313435015678406\n",
      "generated sequence:  pleasing treaty, and have hearts\n",
      "Inclinable to honour and advance\n",
      "The theme of our assembly.\n",
      "\n",
      "BRUTUS:\n",
      "Which the rather\n",
      "We shallibfsofofii\n",
      "\n",
      "iter:10199/20000 loss:2.309015222787857\n",
      "generated sequence: eath,\n",
      "And I in better state than e'er I was.\n",
      "\n",
      "Pursuivant:\n",
      "God hold it, to your honour's good content!\n",
      "\n",
      "HASTINGS:\n",
      "Gramercy, fellosu\tf\tUo\t\tu\n",
      "\n",
      "iter:10399/20000 loss:2.3040338695049285\n",
      "generated sequence: urt not but omit, my fortunes\n",
      "Will ever after droop. Here cease more questions:\n",
      "Thou art inclined to sleep; 'tis a good dulness,sf\tu\ts\tufs\n",
      "\n",
      "iter:10599/20000 loss:2.295070116519928\n",
      "generated sequence: s well.\n",
      "\n",
      "GLOUCESTER:\n",
      "Well, your imprisonment shall not be long;\n",
      "Meantime, have patience.\n",
      "\n",
      "CLARENCE:\n",
      "I must perforce. Farewell.\n",
      "\n",
      "BBBsff\n",
      "\n",
      "iter:10799/20000 loss:2.289343169927597\n",
      "generated sequence: ld stand alone; nay, by the rood,\n",
      "She could have run and waddled all about;\n",
      "For even the day before, she broke her brow:\n",
      "And thef\tb\tioe\tbo\n",
      "\n",
      "iter:10999/20000 loss:2.3058263093233107\n",
      "generated sequence: race thee with that robbery, thy stol'n name\n",
      "Coriolanus in Corioli?\n",
      "You lords and heads o' the state, perfidiously\n",
      "He has betrayjui\tuibssu\n",
      "\n",
      "iter:11199/20000 loss:2.2864479386806487\n",
      "generated sequence: mine eldest daughter and my joy\n",
      "To him forthwith in holy wedlock bands.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Yes, I agree, and thank you for your mozoe\tu\t\t\t\t\t\n",
      "\n",
      "iter:11399/20000 loss:2.2966862082481385\n",
      "generated sequence: to his house, and pluck him thence:\n",
      "Lest his infection, being of catching nature,\n",
      "Spread further.\n",
      "\n",
      "MENENIUS:\n",
      "One word more, one ivufofufvo\n",
      "\n",
      "iter:11599/20000 loss:2.2898614764213563\n",
      "generated sequence: e's reported?\n",
      "\n",
      "GRUMIO:\n",
      "She was, good Curtis, before this frost: but, thou\n",
      "knowest, winter tames man, woman and beast; for it\n",
      "hat\teuuf\tbsf\t\n",
      "\n",
      "iter:11799/20000 loss:2.2738191652297974\n",
      "generated sequence: g out a suit;\n",
      "And sometime comes she with a tithe-pig's tail\n",
      "Tickling a parson's nose as a' lies asleep,\n",
      "Then dreams, he of anotfbvtibobft\n",
      "\n",
      "iter:11999/20000 loss:2.279192532300949\n",
      "generated sequence: s are too shallow and too quick.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "O no, my reasons are too deep and dead;\n",
      "Too deep and dead, poor infants, in t\tbof\tb\teeb\n",
      "\n",
      "iter:12199/20000 loss:2.271302876472473\n",
      "generated sequence:  it blows,\n",
      "Commanded always by the greater gust;\n",
      "Such is the lightness of you common men.\n",
      "But do not break your oaths; for of thuoiufpv\t\t\t\n",
      "\n",
      "iter:12399/20000 loss:2.281721848845482\n",
      "generated sequence: ars to live.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "But not a minute, king, that thou canst give:\n",
      "Shorten my days thou canst with sullen sorrow,\n",
      "And ploj\tu\tvu\tof\n",
      "\n",
      "iter:12599/20000 loss:2.27596311211586\n",
      "generated sequence: \n",
      "You are married?\n",
      "\n",
      "FLORIZEL:\n",
      "We are not, sir, nor are we like to be;\n",
      "The stars, I see, will kiss the valleys first:\n",
      "The odds forB\tssusfsuf\n",
      "\n",
      "iter:12799/20000 loss:2.276540444493294\n",
      "generated sequence:  further deed to have them at\n",
      "an into their estimation and report: but he hath so\n",
      "planted his honours in their eyes, and his actu\tufif\tfu\t\n",
      "\n",
      "iter:12999/20000 loss:2.279141185283661\n",
      "generated sequence: h.\n",
      "\n",
      "COMINIUS:\n",
      "I think 'twill serve, if he\n",
      "Can thereto frame his spirit.\n",
      "\n",
      "VOLUMNIA:\n",
      "He must, and will\n",
      "UUF;J\t;\tnow, say you will, f\n",
      "\n",
      "iter:13199/20000 loss:2.2737675952911376\n",
      "generated sequence: ull of sin.\n",
      "\n",
      "LADY CAPULET:\n",
      "What, are you busy, ho? need you my help?\n",
      "\n",
      "JULIET:\n",
      "No, madam; we have cull'd such necessaries\n",
      "As are \t\t\tiv\ti\tt\t\n",
      "\n",
      "iter:13399/20000 loss:2.253381702899933\n",
      "generated sequence:  the cheek,\n",
      "But not take in the mind.\n",
      "\n",
      "CAMILLO:\n",
      "Yea, say you so?\n",
      "There shall not at your father's house these\n",
      "seven years\n",
      "Be boruif\tuff\t\tf\n",
      "\n",
      "iter:13599/20000 loss:2.2492025369405746\n",
      "generated sequence: s a subtle orator,\n",
      "And Lewis a prince soon won with moving words.\n",
      "By this account then Margaret may win him;\n",
      "For she's a woman t\tuou\tsf\t\t\t\n",
      "\n",
      "iter:13799/20000 loss:2.256979053616524\n",
      "generated sequence:  the sin you carry?\n",
      "\n",
      "JULIET:\n",
      "I do; and bear the shame most patiently.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I'll teach you how you shall arraign youru\tb\tb\to\tb\t\n",
      "\n",
      "iter:13999/20000 loss:2.252425059080124\n",
      "generated sequence: !\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Urge it no more, my Lord Northumberland.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "The commons will not then be satisfied.\n",
      "\n",
      "J\tnF RI\n",
      "\n",
      "iter:14199/20000 loss:2.250393296480179\n",
      "generated sequence:  and then I lost--\n",
      "All mine own folly--the society,\n",
      "Amity too, of your brave father, whom,\n",
      "Though bearing misery, I desire my liuup\tuif\tpu\n",
      "\n",
      "iter:14399/20000 loss:2.242008658647537\n",
      "generated sequence:  love lord marquess.\n",
      "\n",
      "DORSET:\n",
      "This interchange of love, I here protest,\n",
      "Upon my part shall be unviolable.\n",
      "\n",
      "HASTINGS:\n",
      "And so sweaupsfsufsff\n",
      "\n",
      "iter:14599/20000 loss:2.2463166564702988\n",
      "generated sequence: s foreign power.\n",
      "3 KING HENRY VI\n",
      "\n",
      "WARWICK:\n",
      "Trust me, my lord, all hitherto goes well;\n",
      "The common people by numbers swarm to us.\n",
      "\tn\tsf\tmi\tn\n",
      "\n",
      "iter:14799/20000 loss:2.2388329064846038\n",
      "generated sequence: well furnish'd by the Duke of Bretagne\n",
      "With eight tall ships, three thousand men of war,\n",
      "Are making hither with all due expedienj\tffu\tuf\to\n",
      "\n",
      "iter:14999/20000 loss:2.227744680047035\n",
      "generated sequence: rit there with beauty's pen;\n",
      "Examine every married lineament,\n",
      "And see how one another lends content\n",
      "And what obscured in this fafoiuifsfsu\n",
      "\n",
      "iter:15199/20000 loss:2.21739645421505\n",
      "generated sequence: x or seven winters more respect\n",
      "Than a perpetual honour. Darest thou die?\n",
      "The sense of death is most in apprehension;\n",
      "And the pofusfufsfsf\n",
      "\n",
      "iter:15399/20000 loss:2.206369558572769\n",
      "generated sequence: ther; but I would not have it so.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Why, my young cousin, it is good to grow.\n",
      "\n",
      "YORK:\n",
      "Grandam, one night, as we d\t\t\t\t\tuf\t\tu\n",
      "\n",
      "iter:15599/20000 loss:2.2207280874252318\n",
      "generated sequence: ns about,\n",
      "And but attended by a simple guard,\n",
      "We may surprise and take him at our pleasure?\n",
      "Our scouts have found the adventure e\tbofvs\t\tU\n",
      "\n",
      "iter:15799/20000 loss:2.197198936343193\n",
      "generated sequence: hand,\n",
      "Thou dost confirm his happiness for ever.\n",
      "\n",
      "LADY ANNE:\n",
      "What is it?\n",
      "\n",
      "GLOUCESTER:\n",
      "That it would please thee leave these sad dfoe\t\tBpfvt\n",
      "\n",
      "iter:15999/20000 loss:2.2003155905008316\n",
      "generated sequence: e comes, and in the gown of humility: mark his\n",
      "behavior. We are not to stay all together, but to\n",
      "come by him where he stands, by\tui\t\t\t\t\tuu\n",
      "\n",
      "iter:16199/20000 loss:2.1951950687170028\n",
      "generated sequence: :\n",
      "No, sir, God forbid; but ashamed to kiss.\n",
      "\n",
      "PETRUCHIO:\n",
      "Why, then let's home again. Come, sirrah, let's away.\n",
      "\n",
      "KATHARINA:\n",
      "B;s\tu\ttp\t\n",
      "\n",
      "iter:16399/20000 loss:2.1927582675218584\n",
      "generated sequence: road they purchase great alliance?\n",
      "To prove him tyrant this reason may suffice,\n",
      "That Henry liveth still: but were he dead,\n",
      "Yet hbsu\tuibs\tu\n",
      "\n",
      "iter:16599/20000 loss:2.1994419395923615\n",
      "generated sequence:  spread;\n",
      "And spread they shall be, to thy foul disgrace\n",
      "And utter ruin of the house of York.\n",
      "Thus do I leave thee. Come, son, leufbf\te\t\tBo\n",
      "\n",
      "iter:16799/20000 loss:2.179663146138191\n",
      "generated sequence: sir, leave me your snatches, and yield me a\n",
      "direct answer. To-morrow morning are to die Claudio\n",
      "and Barnardine. Here is in our pfsf\tbf\tof\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:16999/20000 loss:2.1653819489479065\n",
      "generated sequence: so out of love\n",
      "with life that I will sue to be rid of it.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Hold you there: farewell.\n",
      "Provost, a word with you!\n",
      "\n",
      "\t\tuv\t\tuv\tu\n",
      "\n",
      "iter:17199/20000 loss:2.1691345089673995\n",
      "generated sequence: teous, liberal, full of spirit.\n",
      "While you are thus employ'd, what resteth more,\n",
      "But that I seek occasion how to rise,\n",
      "And yet thisvmf\tmjmf\n",
      "\n",
      "iter:17399/20000 loss:2.171998274922371\n",
      "generated sequence: ing, Grumio?\n",
      "\n",
      "GRUMIO:\n",
      "O, ay, Curtis, ay: and therefore fire, fire; cast\n",
      "on no water.\n",
      "\n",
      "CURTIS:\n",
      "Is she so hot a shrew as she's repo-s\tgPjszt\n",
      "\n",
      "iter:17599/20000 loss:2.15235287129879\n",
      "generated sequence: at out my brains with billets: I will not\n",
      "consent to die this day, that's certain.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "O, sir, you must: and therefu\tusu\tuj\tu\n",
      "\n",
      "iter:17799/20000 loss:2.167033225297928\n",
      "generated sequence: ;\n",
      "But you have power in me as in a kinsman.\n",
      "\n",
      "YORK:\n",
      "I pray you, uncle, give me this dagger.\n",
      "\n",
      "GLOUCESTER:\n",
      "My dagger, little cousin\tBf\t\tb\t\t\tb\n",
      "\n",
      "iter:17999/20000 loss:2.143063577413559\n",
      "generated sequence: re the people, hoping\n",
      "To purge herself with words: dispatch.\n",
      "Most welcome!\n",
      "\n",
      "First Conspirator:\n",
      "How is it with our general?\n",
      "\n",
      "AUFIf\tuif\tuj\ts\n",
      "\n",
      "iter:18199/20000 loss:2.1443149346113204\n",
      "generated sequence: ncholy bells,\n",
      "Our wedding cheer to a sad burial feast,\n",
      "Our solemn hymns to sullen dirges change,\n",
      "Our bridal flowers serve for a effvf\txfsf\n",
      "\n",
      "iter:18399/20000 loss:2.1309558176994323\n",
      "generated sequence: sometime his general; who loved him\n",
      "In a most dear particular. He call'd me father:\n",
      "But what o' that? Go, you that banish'd him;\tnf\tiof\tib\n",
      "\n",
      "iter:18599/20000 loss:2.119207204580307\n",
      "generated sequence: \n",
      "Ay, sir; well, well.\n",
      "\n",
      "MENENIUS:\n",
      "'Though all at once cannot\n",
      "See what I do deliver out to each,\n",
      "Yet I can make my audit up, that Bm-\tx\tmf\tx\n",
      "\n",
      "iter:18799/20000 loss:2.1149250745773314\n",
      "generated sequence: ted, crowned, planted many years,\n",
      "Be judged by subject and inferior breath,\n",
      "And he himself not present? O, forfend it, God,\n",
      "Thatis-\tuffefe\n",
      "\n",
      "iter:18999/20000 loss:2.113105616569519\n",
      "generated sequence: \n",
      "The rashness of a woman: he is touch'd\n",
      "To the noble heart. What's gone and what's past help\n",
      "Should be past grief: do not receivUp\t\ti\to\t\t\t\n",
      "\n",
      "iter:19199/20000 loss:2.1113311088085176\n",
      "generated sequence:  hast done me; therefore turn and draw.\n",
      "\n",
      "ROMEO:\n",
      "I do protest, I never injured thee,\n",
      "But love thee better than thou canst devise,ufoffufsfs\n",
      "\n",
      "iter:19399/20000 loss:2.1017528736591338\n",
      "generated sequence: orted by calamity\n",
      "Thither where more attends you, and you slander\n",
      "The helms o' the state, who care for you like fathers,\n",
      "When yosfis\tuf\tub\n",
      "\n",
      "iter:19599/20000 loss:2.089881933927536\n",
      "generated sequence: tleman so hot,\n",
      "As he will lose his head ere give consent\n",
      "His master's son, as worshipful as he terms it,\n",
      "Shall lose the royalty \t\t\t\tt\tt\ttt\n",
      "\n",
      "iter:19799/20000 loss:2.088876791596413\n",
      "generated sequence: te, to make one among these wooers: if\n",
      "thou ask me why, sufficeth, my reasons are both good\n",
      "and weighty.\n",
      "\n",
      "First Servant:\n",
      "My lord\t\t\tp\t\tpfof\n",
      "\n",
      "iter:19999/20000 loss:2.081075029373169\n",
      "generated sequence: throat: I took him;\n",
      "Made him joint-servant with me; gave him way\n",
      "In all his own desires; nay, let him choose\n",
      "n\tn of my files, hiippnui\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adagrad(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,input)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,target,start_seq = input)))\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkSElEQVR4nO3deXiV1bn+8e+TnZ15JAkhDCHMUyqDiAiKihZx9neqUq1j24Na2mrrUFtPWz3n9LSnttap1nLEqtU6YxVrFVEqIioCMs/zGBKmDGRO1u+PvYEQE4jIzkvy3p/rykWy98rOsy5g33nXWu9a5pxDRET8K8rrAkRExFsKAhERn1MQiIj4nIJARMTnFAQiIj4X7XUBX1ZmZqbLy8vzugwRkTZl/vz5u5xzWU091+aCIC8vj3nz5nldhohIm2Jmm5p7TkNDIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicb4JgVUEpv3tnFbvLqrwuRUTkhOKbIFhfVMajM9dSWKogEBFpyDdBEBcTAKC8us7jSkRETiy+CYKEYCgIKmsUBCIiDfknCGJC2yrpikBE5HC+CYL4g0NDtR5XIiJyYvFdEFToikBE5DC+CYIDcwQVmiMQETmMb4IgXquGRESa5JsgiI2OwkxDQyIijfkmCMyMhGBAVwQiIo34JggA4mOiNUcgItKIr4IgISZAhZaPiogcxldBEK+hIRGRL/BXEMQENDQkItJIxILAzOLMbK6ZLTKzZWZ2XxNtzMweNrO1ZrbYzIZFqh44MDSkIBARaSiSVwRVwFjn3GBgCDDezEY2anM+0Cf8MRH4UwTrISFGQ0MiIo1FLAhcSFn4y2D4wzVqdinwTLjtJ0CameVEqqa4oIaGREQai+gcgZkFzGwhUAi865z7tFGTLsCWBl9vDT/W+HUmmtk8M5tXVFR0zPVoaEhE5IsiGgTOuTrn3BCgKzDCzPIbNbGmvq2J15nsnBvunBuelZV1zPUkxERr91ERkUZaZdWQc24f8C9gfKOntgLdGnzdFdgeqTq0akhE5IsiuWooy8zSwp/HA+cCKxs1ewO4Lrx6aCRQ7JzbEama4oMBauocNXX1kfoRIiJtTnQEXzsHeNrMAoQC5yXn3JtmdjOAc+5x4C3gAmAtUA7cGMF6SIg5tBV1MOCrWyhERJoVsSBwzi0Ghjbx+OMNPnfApEjV0FjDw2lS4oKt9WNFRE5ovvq1OD6oMwlERBrzVRAk6LhKEZEv8FUQxMeERsIqarSEVETkAF8FQYKOqxQR+QJfBYHmCEREvshfQRC+IqjUTWUiIgf5Kgg0NCQi8kX+CoJgaLJYQSAicoivgiAuJtRdnVssInKIr4IgJhBFIMq08ZyISAO+CgIzI0EH2IuIHMZXQQAQp8NpREQO47sgSNCZBCIih/FdEMRraEhE5DC+CwKdWywicjjfBUF8TEDnFouINOC/IAhGU1GjoypFRA7wXRCEhoZ0RSAicoAvg0CTxSIih/guCOKCmiwWEWnId0Gg+whERA7nyyCorXdU12rCWEQEfBgEB88t1vCQiAjgxyAIH1ep4SERkRDfBcGhU8q0hFREBHwYBPE6rlJE5DD+CwINDYmIHMZ3QXBgaEiTxSIiIb4LAg0NiYgczndBkHBg+WiNJotFRCCCQWBm3cxsppmtMLNlZnZrE21SzWyamS0Kt7kxUvUccGCOQFcEIiIh0RF87VrgdufcAjNLBuab2bvOueUN2kwCljvnLjazLGCVmT3nnKuOVFHxmiMQETlMxK4InHM7nHMLwp+XAiuALo2bAclmZkASsIdQgESMJotFRA4XySuCg8wsDxgKfNroqUeBN4DtQDIwwTkX0U2AgoEoggGjXMtHRUSAVpgsNrMk4FXgNudcSaOnzwMWAp2BIcCjZpbSxGtMNLN5ZjavqKjoK9ekrahFRA6JaBCYWZBQCDznnJvaRJMbgakuZC2wAejfuJFzbrJzbrhzbnhWVtZXrksH2IuIHBLJVUMGTAFWOOceaKbZZuCccPtsoB+wPlI1HZAQE62hIRGRsEjOEYwGrgWWmNnC8GM/A3IBnHOPA/8FPGVmSwADfuKc2xXBmoDQElKdWywiEhKxIHDOzSb05n6kNtuBcZGqoTnxOqVMROQg391ZDDrAXkSkIV8GQbxWDYmIHOTPINDQkIjIQb4MAg0NiYgc4ssgiA9Ga2hIRCTMl0EQuiKoxTnndSkiIp7zZRDExwSod1BdF9FtjURE2gR/BkFQO5CKiBzgyyBI0HGVIiIH+TIIdG6xiMgh/gyC8NBQpe4lEBHxZxAkxYa2WCqpqPG4EhER7/kyCHpkJQKwbtd+jysREfGeL4OgU0ocyXHRrC4o9boUERHP+TIIzIy+2cms2qkgEBHxZRAA9M1OZvXOUt1dLCK+59sg6JedxL7yGorKqrwuRUTEU74Ngr6dkgFYXVDmcSUiIt7ybRD0yw4FgeYJRMTvfBsEGUmxZCTGaOWQiPieb4MA0MohERF8HgT9OiWzRiuHRMTnfB0EfbOT2V9dx7Z9FV6XIiLiGV8HQb9OSQCs1vCQiPiYr4Ogd8fwyiEtIRURH/N1EKTGB8lJjdMVgYj4mq+DAMIrh7SEVER8zPdB0K9TMmuLyqir18ohEfEn3wdB3+xkqmvr2bRbZxOIiD/5Pgj6h/ccWry12ONKRES84fsgGJCTQmZSLNOXF3hdioiIJ1oUBGZ2q5mlWMgUM1tgZuOO8j3dzGymma0ws2Vmdmsz7c4ys4XhNh8cSye+ikCUcd6gbGauLKKiWofZi4j/tPSK4NvOuRJgHJAF3Aj85ijfUwvc7pwbAIwEJpnZwIYNzCwNeAy4xDk3CLjiS9R+3Jyfn0NFTR2z1hR58eNFRDzV0iCw8J8XAH9xzi1q8FiTnHM7nHMLwp+XAiuALo2aXQ1Mdc5tDrcrbGnhx9OpPTuQlhDk7aUaHhIR/2lpEMw3s+mEguAdM0sG6lv6Q8wsDxgKfNroqb5Aupn9y8zmm9l1zXz/RDObZ2bzioqO/2/twUAU5w7IZsaKnVTXtrhbIiLtQkuD4DvA3cApzrlyIEhoeOiozCwJeBW4LTy81FA0cDJwIXAe8HMz69v4NZxzk51zw51zw7OyslpY8pdzfn4nSitr+Wjdroi8vojIiaqlQXAasMo5t8/MrgH+AzjqekszCxIKgeecc1ObaLIVeNs5t985twuYBQxuYU3H1el9MkmKjeYdDQ+JiM+0NAj+BJSb2WDgLmAT8MyRvsHMDJgCrHDOPdBMs9eBM8ws2swSgFMJzSW0utjoAGP7d2T68p3U1ml4SET8o6VBUOtCp7dcCjzknHsISD7K94wGrgXGhpeHLjSzC8zsZjO7GcA5twJ4G1gMzAWecM4tPaaeHAfj8zuxZ381H67V8JCI+Ed0C9uVmtlPCb2xn2FmAULzBM1yzs3mKCuLwu3uB+5vYR0RdXa/jnRNj+euVxbz+qTRdE6L97okEZGIa+kVwQSgitD9BAWEloGeEG/ex1N8TIAnbziFiuo6vvv0PPZX1XpdkohIxLUoCMJv/s8BqWZ2EVDpnDviHEFb1Tc7mUevHsrKghJufWGhdiUVkXavpVtMXEloDP8K4ErgUzO7PJKFeemsfh355cWDmLFiJ79+64tz1zrsXkTak5bOEdxD6B6CQgAzywJmAK9EqjCvXT8qjw279vPE7A3kZiRw3Wl5AKwqKGXS3xZweu9M7r1kkLdFiogcBy0NgqhG2z/sxgc7l/78ooFs3VvOvW8so0taPDV1jh+/tJDaOsdThRsZ2TOD8fmdvC5TROQraemb+dtm9o6Z3WBmNwD/AN6KXFknhkCU8fBVQxnUOZVbnlvAzc/Op092Mu/fcSb5XVL46dTFFJZUel2miMhX0tLJ4juBycBJhO78neyc+0kkCztRJMREM+X64fTISGTC8G68OHEkXdMTeHDCEMqr67jr1cWaMxCRNs3a2pvY8OHD3bx587wuA4Cn52zkl28s44dje/ODc/oQDLT70TIRaaPMbL5zbnhTzx1xjsDMSoGmksIA55xLOQ71tVnXndaduRv38PD7a5m2eAc/Gd+f8wZlE9pdQ0SkbdAVwVfknGPmqkL+562VrC0sIyc1ji5p8XRKjeP8/BwuPCnH6xJFRI79ikCOzswY2z+bMX2ymLpgG5+s382O4ko+27iHd5YVcFLXVLp1SPC6TBGRZikIjpPoQBRXntKNK0/pBkBBcSVj7p/Jw++t4f4rPNlZW0SkRTS7GSGdUuO4dmR3Xl2wlfVFZV6XIyLSLAVBBN1yVi9iowM89N4ar0sREWmWgiCCMpNiuWF0Hm8s2s6qglKvyxERaZKCIMJuGtOTpJhofvv2St14JiInJAVBhKUlxPD9sb15b2Uh976xTGEgIiccrRpqBRPH9KSotIonZm/AzPjlxQMxM+rrHVW19cTHBLwuUUR8TEHQCsyMey4cQL2DJz/awPpd+ymvqmXFjhIAXr55FAM7+/ombRHxkIaGWomZ8fOLBnDzmb1Ytq0YM7j85K4kxUVz07Pz2Fde7XWJIuJT2mLCYws272XCnz9mVK9MnrzhFAJR2qdIRI6/I20xoSsCjw3LTefeSwbxweoi7n9nFVW1dV9o09bCWkTaFs0RnACuHpHL4i3FPP7BOp74cD29OybRMyuRotIqtuypYFdZFfldUhnTJ5NTenRg+74KFm4pZlVBCbeP68fo3pled0FE2jANDZ0gauvqmbFiJ4u3FrNsewmb95STlRxLbocE0hOCzN+0l4Vb9lEf/utKiYvGzMhIiuGd28boLAQROSLtPtoGRAeiGJ+fw/j85retLq6oYdGWfXRNjycvI5H3Vhby78/M44W5m7n2tLzWK1ZE2hX9GtmGpMYHGdM3i55ZSURFGecO6MiIHh14cMYaSitrACgsreT6J+dy37RllFfXelyxiLQFCoI2zMy454IB7N5fzeMfrGP59hIue/QjPlm/m6fmbGT8gx8yd8Mer8sUkROcgqCNG9wtjUsGd+aJDzdwxeNzqHcw9XujeOHfRwIwYfLHPDB9lVYeiUizFATtwJ3n9cMMemYl8fr3RzOocyqn9szgn7eeweXDuvLw+2u585XF1NTVe12qiJyANFncDnTrkMAHd55NekIMMdGHsj0xNprfXn4SXdMT+MOM1ewqq+K/L8tn7/4adpZUsnlPOWsKy1hXWEZKfJCfXdCfnllJB79/VUEpK3aUcMngzkTpRjeRditiy0fNrBvwDNAJqAcmO+ceaqbtKcAnwATn3CtHet32unw00p6fu5l7XltycPnpAWkJQXpnJbFqZylVtfXcek4fvj4wm0ffX8u0xdtxDs4dkM0fJgwmOS7oTfEi8pUdafloJIMgB8hxzi0ws2RgPnCZc255o3YB4F2gEnhSQRA58zbuYfmOErJT4shOiaNrejwZiTGYGYUlldw7bRlvLSkAID4Y4MbReaQnxPCbt1fSMzOR/7tuOHmZiR73QkSOhSdB0EQRrwOPOufebfT4bUANcArwpoLAW++t2MnKglKuHN6NrORYAOas3cWkvy2grKqWnNR4slNi6Z6RyA/H9iE3I8HjikWkJTwPAjPLA2YB+c65kgaPdwH+BowFptBMEJjZRGAiQG5u7smbNm2KeM1yuC17ynnu081s31fBzpJKlm4rBuAXFw/kyuHdMNMcgsiJzNMgMLMk4APgV865qY2eexn4vXPuEzN7Cl0RtBlb95Zzx8uL+GT9Hs7p35ErT+nG8O7pZCTFel2aiDTBsyAwsyDwJvCOc+6BJp7fABz4VTITKAcmOuf+3txrKghOHPX1jic/2sDvp6+moia0a2qPzEQyEmOIjwmQHBfN5Sd3ZWz/bI8rFRGvJosNeBrY45y7rQXtn0JXBG1SVW0dS7YW89nGvSzaso/iihrKa+ooKK5gZ0kVZ/XL4ucXDaS8qo7XF27jn0sLiI2Oon9OMv07pbC/upbl20tYsaOEwV3TeGDCEFLjtUJJ5HjyKghOBz4ElhBaPgrwMyAXwDn3eKP2T6EgaFeqa+t55uONPDRjDaVVoX2PggHjzL5ZBKKMlQWlbNpdTkwgir6dkuiZmcQ/l+4gt0MCf7lhBLkZCWzYtZ8ps9dTVw+/vHggcUGd7yxyLDyfLD6eFARtT1FpFc98vJHOafFckJ9DasKh3/bLq2uJjoo6eCPcJ+t3c9Nf5xOIMoZ3T+fdFTsJRkVRXVfPqF4ZTL5uOEmxug9S5MtSEEibsr6ojO88PY9dZVVcO7I7N4zO48PVu7jr1cXkd07hLzeOAEI7rcZGB+ihextEjkpBIG1OVW0dznHYUNC7y3cy6W8LqK49fM+kfxvWhbvP70/H5LjWLlOkzdDBNNLmxEZ/cS7g6wOzeXHiSGas2ElmUiwdk+NYsq2YKbPXM33ZTm4a05MRPTrQr1MyaQkxHlQt0jbpikDavA279vOf05Yxc1XRwce6dYjnjnH9uGRwZ93sJoKGhsQndhRXsKqglNU7S5m2aAdLthUzpm8W/31pvrbCEN87UhDoPAJpN3JS4zmrX0cmjunF3yeN5t6LBzJ/4x7GPfgBL3225bC2JZU1PD1nI7vKqjyqVuTEoSCQdikQZdwwugczbj+Tk7unc9eri7nj5UVUVIduajvn9x/wyzeWce2UuZSEz3sW8SsFgbRrOanxPPPtU/nh2N68umArI/5nBre+sJCc1Djuu2QQawtL+e7T86gMb5HRUF2944kP1+vcZ2n3tGpI2r1AlPHjcf04Oa8DD0xfxeXDu3H1iFwCUUZaQpDbXlzID57/nD99axjRgdDvRpU1dfz4pYW8taSAxJgAr9wyigE5KR73RCQyNFksvvfURxu4d9pyunWI55pTuzM+vxN3vrKYuRv28MNz+vDSZ1sIRBmvTRqlexWkzdKqIZGjeGdZAVNmbzg4DBQMGL+7YjCXDunC0m3FXPH4x/TrlMyfrhnGpt2hs5737q/GOah3jqzkWM7sm0W3DlqdJCcmBYFIC60sKGHqgm2M7d+RkT0zDj7+9tId3PzsgqN+f8/MRM7q15HzBmUzPK8Dgaij38PgnNO9DhJxCgKR42DmykLWFZXRJzuZPh2TyEqOJWCGWeimtg9WF/GvVUV8vH431bX1ZCTGcNFJOUwa27vZIaWX523hd9NX8cerhzE8r0Mr90j8REEg0orKqmr516pC3l5awNtLC4gLBph0dm++fXreYVtn/GPxDn7wfOgqo0NiLNN+MJqc1PiDzxcUV4bCpgVXFSJHoyAQ8cj6ojL+560VzFhRSJe0eC4/uSv/NqwL64rKmPjMfIbmpvHziwZy1eRP6N0xiRdvOo39VbXcO2050xZtp2t6PDeMyuPKU7qREqfDeuTYKQhEPDZrdRF/nrWOOet241xoSevAnBSe+/dTSYkLMn1ZARP/Op/RvTNYsaOU0soarjstjyXbipm7YQ+JMQF+/Y2TuGRwZ6+7Im2Udh8V8diYvlmM6ZvFjuIKXl+4nVUFpfziooEHf8sfN6gTt53bhwdnrGFw11R+e/lI+nVKBmDptmLufWMZP3pxIdFRxgVfyznqzyssqaSm3tElLf6obUV0RSBygnDOsXhrMYM6pxy8se2A/VW1XP/kXBZu2cdj3xrGyF4ZTF+2kxnLd9InO4nvnN6DtISYg3dD//7d1VTX1jOiRwe+MawLw3LTqaqtp6KmjsKSKlbvLGVtYRl19Y7x+Z04d2C2Tn5r5zQ0JNIOlFbWcO2UuSzbXoxhVNfV0zE5lsLSKpJjo7n2tO7MWbebhVv28fWB2ZzUJZXXPt/G+l37v/BaZpDbIYGqmnoKSiqJjY7i0iGd+dX/+xrBgHaeaY80NCTSDiTHBXn62yP42WtLyE6O4+LBOQzplsaqnaU8NGMNj/1rHWkJQR765pCD5zB8f2xvFm0tZvOecuKDAeKCUaQnxNArK4n4mAD19Y75m/cydcE2np+7mdT4IPdcONDrrkor0xWBSDuxZU85KXFBUhOObXXRL15fyjMfb+Lxa4YxPv/o8xDStug8AhEf6NYh4ZhDAOCeCwcwuFsad768mA1NDCftK69m2qLtTT4nbZuGhkQECJ0T/cerh3LRI7P5ztOfceOoPEb3ziQ9IYYpszfw1JyNlFXVAtAjM5Ez+2bRNzuZbh3iyctIpGt6vLbKaKM0NCQih/lo7S5+8upitu6tAEL3PNQ7xwX5OVwzsjurd5Yyc1UhH6/bTVVt/cHvO7VHB+4+vz9Dc9OB0FbeS7YV0yMzkcykWE/6Iodo1ZCIfCnOOTbvKWf22l1s3LWfy0/udvC+hgPq6h0FJZVs2VPO4q37mDxrPbvKqjl3QEeq6xyfrg8FRWx0FFeNyGXimJ501n0NnlEQiEjElVXVMuXDDTwxez0dk2M5o08Wp/bowPsrC3nt822YwY2je3D7uL6H7bkkrUNBICKtpqlttbfuLeeR99by4rwt9O+UzMNXDaVvdnIzryCRoFVDItJqmpow7pqewP9efhJTrh9OUWkVFz8ymymzN1Bf37Z+EW2vFAQi0mrOGZDN27eNYXTvTP7rzeVMmPxxs8tRSypr2Lq3vJUr9CcFgYi0qqzkWKZcP5zfXzGYVQWljH9w1heuDjbu2s+FD3/IeX+YpTBoBRELAjPrZmYzzWyFmS0zs1ubaPMtM1sc/phjZoMjVY+InDjMjG+c3JV3f3wmp4evDq57ci4FxZUs217M5Y9/TFll6J6Fu19dQluby2xrIjZZbGY5QI5zboGZJQPzgcucc8sbtBkFrHDO7TWz84F7nXOnHul1NVks0r4453jhsy3857TlxERHUV/vSIqL5q/fGcEn6/fwH39fyq//7WtcNSLX61LbNE8mi51zO5xzC8KflwIrgC6N2sxxzu0Nf/kJ0DVS9YjIicnMuGpELm/degY9sxLpnBbPq7eMonfHZK4ekcuoXhn86h8r2LavInR/w+5yFm3ZR91RJpora+paqQdtX6ssHzWzPGAWkO+cK2mmzR1Af+fcd4/0WroiEGm/nHM4B1ENzmnesqec8x6cRWp8kPLqOooragDITIrhvEGd+PrAbAbmpJCVHEu9g/dXFvLUnA18vG43f5gwhEuHdGnux/mKp/cRmFkS8AHwK+fc1GbanA08BpzunNvdxPMTgYkAubm5J2/atCmCFYvIiea1z7fy9JxNDMhJJr9LKokx0by7fCfvryykIvybf3JsNHExAYpKq8hJjSM1PsjG3fuZestoBnZO8bgH3vMsCMwsCLwJvOOce6CZNicBrwHnO+dWH+01dUUgIgdUVNexYPNe1hWVsa6wjF37q7nwazmMG5jN3vIaLn5kNsFoY9r3TyctIcbrcj3lSRBY6K6Sp4E9zrnbmmmTC7wPXOecm9OS11UQiEhLfb55LxP+/Akje2XwlxtOIRDl391RvbqzeDRwLTDWzBaGPy4ws5vN7OZwm18AGcBj4ef1Di8ix83Q3HTuvWQQs1YXcftLC6lusFuqHBKx8wicc7OBI8ZveGL4iJPDIiJfxdWn5rK3vJr731nF3vIa/nTNMBJiQm99O0sqWbqtmBU7SlhftJ/LhnZhTN8sjytufTqYRkTavUln9yYjMYafvbaEqyZ/Qq+OSXy2cQ9b9lQcbJMYE+CfSwuY+r1RDMgJTS7X1zv+OHMtHVNimXBK+72PQUEgIr7wzRG5pCfG8KMXF7J1bwWn5HXghlE9GNw1lX6dkqmoqePiR2Zz01/n88b3R5MUG81dryxm6ufbCEQZ+V1SGdQ51etuRIS2oRYRX6mpqyc6yprcJXXB5r1M+PPHnNYrk7joKKYv38n3zurFy/O30jE5lr9PGk0w0Da3aNM21CIiYcFAVLNnKw/LTee+S/KZtbqI6ct3ct8lg7hrfH/+69J8lm0vYfKs9a1cbevQ0JCISANXn5pLRU0dXdLiGJ+fA8D4/E5c+LUcHpqxhjP6ZJISF2RPeTWdUuLaxfGbGhoSEWmBotIqvv6HD9hXXnPwsbhgFA9OGHIwME5kRxoa0hWBiEgLZCXH8sLEkcxes4v0hBjSEoL8ceZabn52AXef35+bxvRsdsjpRKcgEBFpof6dUujf6dC+RaN7Z3LHy4v4zT9Xsr6ojP+8NJ+4YMDDCo+NgkBE5BjFBQM8/M2h9MhM5JH317JkWwmPfWsYPTITvS7tS9GqIRGRryAqyrh9XD+evGE4O4oruOjhD3lp3hb2V9V6XVqLabJYROQ42b6vgh88/znzN+0lGDBO7p7OyJ4ZdM9IoHNqPJ3T4slOiSMmuvV/B9dksYhIK+icFs+LE0fyyfo9fLimiFlrdvHgjDWHtTGDzKRYundI4Htn92Js/2yPqm1Qk64IREQip6K6ju3FFWzfd+Cjkh3FFXy2cS8bdu3nvEHZ/PLiQRG/H0FXBCIiHomPCdArK4leWUmHPV5dW8//fbieR95fw7kPfMB9lwziiuHdPKlRk8UiIh6IiY5i0tm9efdHZzK4axp3vrKYO19eREV1XavXoisCEREPdeuQwLPfPZWHZqzmkZlrWby1mHGDskmJC5KaEOSsvll0TImLaA0KAhERjwWijB+P68fJeR2457Ul/HHmWurD07ex0VFcNSKXW87qRXaEAkGTxSIiJ5j6esf+6lq27atgyocbDp6JcNd5/fjuGT2P6TW1DbWISBsSFWUkxwXp3ymF+68YzPu3n8llQzrTNT0yK4s0NCQicoLrnpHIby8fHLHX1xWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8bk2t8WEmRUBm47x2zOBXcexnLbCj/32Y5/Bn/32Y5/hy/e7u3Muq6kn2lwQfBVmNq+5vTbaMz/22499Bn/22499huPbbw0NiYj4nIJARMTn/BYEk70uwCN+7Lcf+wz+7Lcf+wzHsd++miMQEZEv8tsVgYiINKIgEBHxOd8EgZmNN7NVZrbWzO72up5IMLNuZjbTzFaY2TIzuzX8eAcze9fM1oT/TPe61uPNzAJm9rmZvRn+2g99TjOzV8xsZfjv/DSf9PtH4X/fS83seTOLa2/9NrMnzazQzJY2eKzZPprZT8PvbavM7Lwv+/N8EQRmFgD+CJwPDASuMrOB3lYVEbXA7c65AcBIYFK4n3cD7znn+gDvhb9ub24FVjT42g99fgh42znXHxhMqP/tut9m1gX4ITDcOZcPBIBv0v76/RQwvtFjTfYx/H/8m8Cg8Pc8Fn7PazFfBAEwAljrnFvvnKsGXgAu9bim4845t8M5tyD8eSmhN4YuhPr6dLjZ08BlnhQYIWbWFbgQeKLBw+29zynAGGAKgHOu2jm3j3be77BoIN7MooEEYDvtrN/OuVnAnkYPN9fHS4EXnHNVzrkNwFpC73kt5pcg6AJsafD11vBj7ZaZ5QFDgU+BbOfcDgiFBdDRw9Ii4UHgLqC+wWPtvc89gSLgL+EhsSfMLJF23m/n3Dbgd8BmYAdQ7JybTjvvd1hzffzK729+CQJr4rF2u27WzJKAV4HbnHMlXtcTSWZ2EVDonJvvdS2tLBoYBvzJOTcU2E/bHw45qvC4+KVAD6AzkGhm13hblee+8vubX4JgK9CtwdddCV1OtjtmFiQUAs8556aGH95pZjnh53OAQq/qi4DRwCVmtpHQkN9YM3uW9t1nCP2b3uqc+zT89SuEgqG99/tcYINzrsg5VwNMBUbR/vsNzffxK7+/+SUIPgP6mFkPM4shNLHyhsc1HXdmZoTGjFc45x5o8NQbwPXhz68HXm/t2iLFOfdT51xX51weob/X951z19CO+wzgnCsAtphZv/BD5wDLaef9JjQkNNLMEsL/3s8hNBfW3vsNzffxDeCbZhZrZj2APsDcL/XKzjlffAAXAKuBdcA9XtcToT6eTuiScDGwMPxxAZBBaJXBmvCfHbyuNUL9Pwt4M/x5u+8zMASYF/77/juQ7pN+3wesBJYCfwVi21u/gecJzYHUEPqN/ztH6iNwT/i9bRVw/pf9edpiQkTE5/wyNCQiIs1QEIiI+JyCQETE5xQEIiI+pyAQEfE5BYHIUZjZnPCfeWZ2tdf1iBxvCgKRo3DOjQp/mgd8qSD4srtAinhBQSByFGZWFv70N8AZZrYwvCd+wMzuN7PPzGyxmd0Ubn9W+FyIvwFLzCzRzP5hZovCe+hP8KwzIk2I9roAkTbkbuAO59xFAGY2kdDul6eYWSzwkZlND7cdAeQ75zaY2TeA7c65C8Pfl+pF8SLN0RWByLEbB1xnZgsJbfedQWifF4C5LrQ3PMAS4Fwz+18zO8M5V9z6pYo0T0EgcuwM+IFzbkj4o4cL7Y0PoW2hAXDOrQZOJhQIvzazX3hQq0izFAQiLVcKJDf4+h3glvDW35hZ3/DhMIcxs85AuXPuWUKHqgxrjWJFWkpzBCIttxioNbNFhM6UfYjQSqIF4S2Ri2j6iMSvAfebWT2h3SRvaY1iRVpKu4+KiPichoZERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8bn/Dw+Dk1jAz52AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r of small consequence,\\nWhich for some reasons I would not have seen.\\n\\nDUKE OF YORK:\\nWhich for some reasons, sir, I mean to see.ppo\\ttffoffofoff-fsspp\\t\\tBiptppppsfpf\\tf\\tpf\\to\\to\\t\\tp\\tppotffpfffbfoftof//\\t\\rBB\\tT\\t;p;;pp;J\\t\\rJpftffppsfpfff\\tpftoffff\\tpfff\\tp\\tpf\\tofpffpfpo\\rfffpfoofp\\tf\\tp\\tp\\t\\tpp\\t\\tpppffffffff\\tf\\tp\\tpf\\tpfpfppfpfffffffff\\to\\tf\\tff\\t\\r\\rpJ;;ppppfffffffpfffffppffffffffffffffff\\tpf\\t\\t\\tpfpfppfpfppfffff\\t\\t\\tf\\tff\\tfp\\tpfpfppfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "generate_text(model,rand_input,start_seq = rand_input,gen_len=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "In attempting to printing the output of the current model, the main change was for the model to pass in the input twice,since the target gave away the answers. This prevented the model from generalizing to other input and thus had bad behavior in printing words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
