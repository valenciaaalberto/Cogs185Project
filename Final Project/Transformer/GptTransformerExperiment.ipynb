{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c34c2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cee1e0",
   "metadata": {},
   "source": [
    "### Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a87fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82165d",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ff0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, nhead, nhid, nlayers, output_dim, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embed_dim = embed_dim\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n",
    "        self.encoder = nn.Embedding(input_dim, embed_dim)\n",
    "        self.transformer = nn.Transformer(embed_dim, nhead, nlayers, nlayers, nhid, dropout)\n",
    "        self.decoder = nn.Linear(embed_dim, output_dim)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        src = src\n",
    "        src = self.encoder(src) * math.sqrt(self.embed_dim)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer(src, src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ea59e",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60226d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = string.printable\n",
    "n_chars = len(all_chars)\n",
    "file = open('../Data/shakespeare.txt').read()\n",
    "file_len = len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c98568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seq():\n",
    "    seq_len = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "def seq_to_onehot(seq):\n",
    "    tensor = torch.zeros(len(seq), n_chars, dtype=torch.long)\n",
    "    for t, char in enumerate(seq):\n",
    "        index = all_chars.index(char)\n",
    "        tensor[t][index] = 1.0\n",
    "    return tensor\n",
    "\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype=torch.long)\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char)\n",
    "    return tensor\n",
    "\n",
    "def get_input_and_target():\n",
    "    seq = get_random_seq()\n",
    "    input = seq_to_index(seq[:-1])  # Input is represented in index.\n",
    "    target = seq_to_index(seq[1:])  # Target is represented in index.\n",
    "    return input, target\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.triu(torch.ones(sz, sz) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1750b",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "befed9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text(model, start_seq='W', max_len=100):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         input = seq_to_index(start_seq).unsqueeze(1)  # Shape: (seq_len, batch_size=1)\n",
    "#         generated = input.to(device)\n",
    "\n",
    "#         for _ in range(max_len):\n",
    "#             src_mask = generate_square_subsequent_mask(generated.size(0)).to(device)\n",
    "#             output = model(generated, src_mask)\n",
    "            \n",
    "#             # Select the last time step's output\n",
    "#             next_char_logits = output[-1, 0, :]\n",
    "#             next_char = torch.argmax(next_char_logits, dim=-1).unsqueeze(0).unsqueeze(1)  # Shape: (1, 1)\n",
    "            \n",
    "#             generated = torch.cat((generated, next_char), dim=0)  # Concatenate along the sequence dimension\n",
    "\n",
    "#         generated_seq = ''.join([all_chars[idx] for idx in generated.squeeze().tolist()])\n",
    "#     return generated_seq\n",
    "# gpt\n",
    "# def generate_text(model, start_seq='W', max_len=100):\n",
    "#     predicted_seq = start_seq\n",
    "# #     model.eval()\n",
    "# #     with torch.no_grad():\n",
    "#     init_input = seq_to_index(start_seq).to(device)\n",
    "#     input = init_input[-1]  # Shape: (seq_len, batch_size=1)\n",
    "#     for _ in range(max_len):\n",
    "#         src_mask = generate_square_subsequent_mask(input.size(0)).to(device)\n",
    "#         output = model(input, src_mask)\n",
    "#         predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "\n",
    "#         # Add predicted character to the sequence and use it as next input.\n",
    "#         predicted_char  = all_chars[predicted_index]\n",
    "#         predicted_seq  += predicted_char\n",
    "\n",
    "#         # Use the predicted character to generate the input of next round.\n",
    "#         input = seq_to_index(predicted_char)[0].to(device)\n",
    "#     return predicted_seq\n",
    "\n",
    "\n",
    "# Evaluation step function.\n",
    "# def generate_text(model, init_seq='W', predicted_len=100):\n",
    " \n",
    "#     init_input    = seq_to_onehot(init_seq).to(device)\n",
    "#     predicted_seq = init_seq\n",
    "\n",
    "#     # Set current input as the last character of the initial string.\n",
    "#     input = init_input[-1]\n",
    "    \n",
    "#     # Predict more characters after the initial string.\n",
    "#     for t in range(predicted_len):\n",
    "#         src_mask = generate_square_subsequent_mask(input.size(0)).to(device)\n",
    "#         output = model(input, src_mask)\n",
    "        \n",
    "#         # Sample from the output as a multinomial distribution.\n",
    "#         output = output.view(-1, output_dim)\n",
    "#         print(output.shape)\n",
    "#         predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "#         print(predicted_index)\n",
    "        \n",
    "#         # Add predicted character to the sequence and use it as next input.\n",
    "#         predicted_char  = all_chars[predicted_index]\n",
    "#         predicted_seq  += predicted_char\n",
    "        \n",
    "#         # Use the predicted character to generate the input of next round.\n",
    "#         input = seq_to_onehot(predicted_char)[0].to(device)\n",
    "\n",
    "#     return predicted_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37b0c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_seq='W', gen_len=100):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Convert the starting sequence to indices\n",
    "#     init_input = seq_to_index(start_seq).unsqueeze(1).to(device)\n",
    "    input_seq = seq_to_index(start_seq).unsqueeze(1).to(device)  # Add batch dimension, shape: (seq_len, 1)\n",
    "    \n",
    "    generated_text = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        src_mask = generate_square_subsequent_mask(input_seq.size(0)).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, src_mask)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :]  # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)\n",
    "        \n",
    "        # Sample the next character\n",
    "#         next_char_index = np.random.choice(len(all_chars), p=next_char_probs)\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        next_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        generated_text += next_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=0)\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f98f852b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (encoder): Embedding(512, 128)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=128, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 512\n",
    "embed_dim = 128\n",
    "nhead = 2\n",
    "nhid = 256\n",
    "nlayers = 2\n",
    "output_dim = len(all_chars)\n",
    "dropout = 0.2\n",
    "\n",
    "model = TransformerModel(input_dim, embed_dim, nhead, nhid, nlayers, output_dim, dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e0848",
   "metadata": {},
   "source": [
    "### Training Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9769d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.2844396162033083\n",
      "Generated output: Whe t t he t the t t he t the he he t the the he t the he he t the the the t t t t he t t t t t t t t\n",
      "Epoch 2, Loss: 2.741659643650055\n",
      "Generated output: Whe the the ther ther thererer ther ther ther ther ther ther ther ther ther the the the ther ther the\n",
      "Epoch 3, Loss: 2.644110989570618\n",
      "Generated output: WIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n",
      "Epoch 4, Loss: 2.6176751589775087\n",
      "Generated output: Whe the the the the the the the the the the the the the the the the the the the the the the the the t\n",
      "Epoch 5, Loss: 2.5990308237075808\n",
      "Generated output: Whe the the the the the the the the the the the the the the the the the the the the the the the the t\n",
      "Epoch 6, Loss: 2.575629086494446\n",
      "Generated output: Whe the the the the the the the the the the the the the the the the the the the the the the the the t\n",
      "Epoch 7, Loss: 2.5481351828575134\n",
      "Generated output: Whe the the the the the the the the the the the the the the the the the the the the the he the he the\n",
      "Epoch 8, Loss: 2.536631178855896\n",
      "Generated output: Wh the he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he h\n",
      "Epoch 9, Loss: 2.4886669611930845\n",
      "Generated output: WANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
      "Epoch 10, Loss: 2.3978920555114747\n",
      "Generated output: Wtttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n",
      "Epoch 11, Loss: 2.1871775341033937\n",
      "Generated output: WTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\n",
      "Epoch 12, Loss: 1.8335915327072143\n",
      "Generated output: WWWWWWWhththththththththththththththththththththththththththththththththththththththththththththththt\n",
      "Epoch 13, Loss: 1.4100770580768585\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 14, Loss: 1.1000174134969711\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 15, Loss: 0.8566264271736145\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 16, Loss: 0.7719288325309753\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 17, Loss: 0.6500152924656868\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 18, Loss: 0.6579040092229843\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 19, Loss: 0.5946475821733475\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 20, Loss: 0.5612431770563125\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 21, Loss: 0.5427965980768203\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 22, Loss: 0.5175023275613785\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 23, Loss: 0.5100596952438354\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 24, Loss: 0.5036847767233849\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 25, Loss: 0.47972493603825567\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 26, Loss: 0.49916188687086105\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 27, Loss: 0.4765144029259682\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 28, Loss: 0.4849448631703854\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 29, Loss: 0.45749376073479653\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 30, Loss: 0.4617000874876976\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 31, Loss: 0.4547984080016613\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 32, Loss: 0.4721109303832054\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 33, Loss: 0.456812037974596\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 34, Loss: 0.4287485049664974\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 35, Loss: 0.46435232400894166\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 36, Loss: 0.4446853721141815\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 37, Loss: 0.4475113296508789\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 38, Loss: 0.4387773209810257\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 39, Loss: 0.45018601924180984\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
      "Epoch 40, Loss: 0.4363202783465385\n",
      "Generated output: WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "iters = 100\n",
    "all_losses = []\n",
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for _ in range(iters):  # Adjust the number of batches\n",
    "        input, target = get_input_and_target()\n",
    "        # Add batch dimension, shape: (seq_len, batch_size=1)\n",
    "        input = input.unsqueeze(1).to(device)\n",
    "        target = target.unsqueeze(1).to(device)\n",
    "     \n",
    "        src_mask = generate_square_subsequent_mask(input.size(0)).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input, src_mask)\n",
    "        \n",
    "        # Reshape output to (seq_len * batch_size, output_dim) and target to (seq_len * batch_size)\n",
    "        output = output.view(-1, output_dim)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    all_losses.append(total_loss / iters)\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / iters}')\n",
    "    print(\"Generated output:\", generate_text(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77d7c2",
   "metadata": {},
   "source": [
    "### Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57cf0f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "all_losses = [loss for loss in all_losses]\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29b09fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      " ainst my canker'd country with the spleen\n",
      "Of all the under fiends. But if so be\n",
      "Thou darest not this and that to prove more fortu\n",
      "Output\n",
      "ainst my canker'd country with the spleen\n",
      "Of all the under fiends. But if so be\n",
      "Thou darest not this and that to prove more fortut t ou t t t t t thin m t the t d che t t ce he t be fout t t t t t t in m t t m t f ce nd m ce t t \n"
     ]
    }
   ],
   "source": [
    "rand_input = get_random_seq() \n",
    "print(\"Input\\n\",rand_input)\n",
    "print(\"Output\")\n",
    "print(generate_text(model, rand_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
