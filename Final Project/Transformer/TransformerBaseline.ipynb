{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.051203Z",
     "start_time": "2019-05-14T23:57:19.626384Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T23:57:20.129301Z",
     "start_time": "2019-05-14T23:57:20.081156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = (tgt_mask & nopeak_mask).to(device)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "    \n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output).to(device)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 1115394\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars       = string.printable\n",
    "n_chars         = len(all_chars)\n",
    "file            = open('../Data/shakespeare.txt').read()\n",
    "file_len        = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sequence of the Shakespeare dataset.\n",
    "def get_random_seq():\n",
    "    seq_len     = 128  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_len - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq):\n",
    "    tensor = torch.zeros(len(seq), dtype = torch.long)\n",
    "    # Shape of the tensor: \n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char) + 1\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target():\n",
    "    seq    = get_random_seq()\n",
    "    input  = seq_to_index(seq[:-1])      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:]) # Target is represented in index.\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(100, 128)\n",
       "  (decoder_embedding): Embedding(100, 128)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-3): 4 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Transformer model\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=100,\n",
    "    tgt_vocab_size=100,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    d_ff=d_ff,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dropout=dropout\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,target,start_seq='W', gen_len=10,temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    indices = \"\"\n",
    "    tensor = start_seq[0]\n",
    "    for char in tensor:\n",
    "        indices += all_chars[char-1] \n",
    "        \n",
    "    input_seq = start_seq\n",
    "    \n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, target)\n",
    "        \n",
    "        # Get the last output and convert to probabilities\n",
    "        next_char_logits = output[-1, 0, :] # Shape: (output_dim)\n",
    "        next_char_probs = torch.softmax(next_char_logits, dim=-1)/temperature\n",
    "\n",
    "        predicted_char_index = torch.argmax(next_char_probs)\n",
    "        predicted_char = all_chars[predicted_char_index]\n",
    "        \n",
    "        indices += predicted_char\n",
    "        \n",
    "        # Append the next character to the input sequence\n",
    "        next_char_tensor = torch.tensor([predicted_char_index], dtype=torch.long).unsqueeze(1).to(device)\n",
    "        input_seq = torch.cat([input_seq, next_char_tensor], dim=1)[:, 1:]\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:199/20000 loss:0.2270066896174103\n",
      "generated sequence: ted their foul ends.\n",
      "In few, they hurried us aboard a bark,\n",
      "Bore us some leagues to sea; where they prepared\n",
      "A rotten carcass offfffffffff\n",
      "\n",
      "iter:399/20000 loss:0.00483803846524097\n",
      "generated sequence:  part in't\n",
      "You chose her; then I'ld shriek, that even your ears\n",
      "Should rift to hear me; and the words that follow'd\n",
      "Should be 'Rqqqqqqqqqq\n",
      "\n",
      "iter:599/20000 loss:0.0018016745737986638\n",
      "generated sequence: he swoon? use means for her recovery.\n",
      "\n",
      "GLOUCESTER:\n",
      "Clarence, excuse me to the king my brother;\n",
      "I'll hence to London on a seriousffffffffff\n",
      "\n",
      "iter:799/20000 loss:0.0012054549128515646\n",
      "generated sequence:  my girl:\n",
      "By foul play, as thou say'st, were we heaved thence,\n",
      "But blessedly holp hither.\n",
      "\n",
      "MIRANDA:\n",
      "O, my heart bleeds\n",
      "To think nnnnnnnnnn\n",
      "\n",
      "iter:999/20000 loss:0.0007715856087452266\n",
      "generated sequence: base\n",
      "To stain the temper of my knightly sword.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Bagot, forbear; thou shalt not take it up.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "bbbbbbbbbb\n",
      "\n",
      "iter:1199/20000 loss:0.0005259593814844265\n",
      "generated sequence: ?\n",
      "\n",
      "Second Servant:\n",
      "Marry, sir, 'tis an ill cook that cannot lick his\n",
      "own fingers: therefore he that cannot lick his\n",
      "fingers goes\n",
      "\n",
      "iter:1399/20000 loss:0.00038347692650859245\n",
      "generated sequence: ler, and wild Half-can that stabbed\n",
      "Pots, and, I think, forty more; all great doers in\n",
      "our trade, and are now 'for the Lord's saffffffffff\n",
      "\n",
      "iter:1599/20000 loss:0.0003113175113685429\n",
      "generated sequence: for I command no more,\n",
      "That Margaret your queen and my son Edward\n",
      "Be sent for, to return from France with speed;\n",
      "For, till I seepppppppppp\n",
      "\n",
      "iter:1799/20000 loss:0.0002354450966231525\n",
      "generated sequence:  hear our tribune: peace Speak, speak, speak.\n",
      "\n",
      "SICINIUS:\n",
      "You are at point to lose your liberties:\n",
      "Marcius would have all from yoiiiiiiiiii\n",
      "\n",
      "iter:1999/20000 loss:0.0001906078606407391\n",
      "generated sequence: illy beggars\n",
      "Who sitting in the stocks refuge their shame,\n",
      "That many have and others must sit there;\n",
      "And in this thought they fimmmmmmmmmm\n",
      "\n",
      "iter:2199/20000 loss:0.0001553093015172635\n",
      "generated sequence: ?\n",
      "\n",
      "BUCKINGHAM:\n",
      "Marry, my lord, lest, by a multitude,\n",
      "The new-heal'd wound of malice should break out,\n",
      "Which would be so much the\n",
      "\n",
      "iter:2399/20000 loss:0.00013469942019582958\n",
      "generated sequence: So long could I\n",
      "Stand by, a looker on.\n",
      "\n",
      "PAULINA:\n",
      "Either forbear,\n",
      "Quit presently the chapel, or resolve you\n",
      "For more amazement. Ipppppppppp\n",
      "\n",
      "iter:2599/20000 loss:0.00010939405859971884\n",
      "generated sequence: lted language; meal and bran together\n",
      "He throws without distinction. Give me leave,\n",
      "I'll go to him, and undertake to bring him\n",
      "Wuuuuuuuuuu\n",
      "\n",
      "iter:2799/20000 loss:9.064967767699272e-05\n",
      "generated sequence: turn'd\n",
      "These terms of treason doubled down his throat.\n",
      "Setting aside his high blood's royalty,\n",
      "And let him be no kinsman to my lvvvvvvvvvv\n",
      "\n",
      "iter:2999/20000 loss:7.888071628258331e-05\n",
      "generated sequence: it with cursing cries and deep exclaims.\n",
      "If thou delight to view thy heinous deeds,\n",
      "Behold this pattern of thy butcheries.\n",
      "O, geuuuuuuuuuu\n",
      "\n",
      "iter:3199/20000 loss:7.076660711391014e-05\n",
      "generated sequence:  greater a run\n",
      "but my head and my neck. A fire good Curtis.\n",
      "\n",
      "CURTIS:\n",
      "Is my master and his wife coming, Grumio?\n",
      "\n",
      "GRUMIO:\n",
      "O, ay, Chhhhhhhhhh\n",
      "\n",
      "iter:3399/20000 loss:5.9244427320663816e-05\n",
      "generated sequence: shall a buzzard take thee?\n",
      "\n",
      "KATHARINA:\n",
      "Ay, for a turtle, as he takes a buzzard.\n",
      "\n",
      "PETRUCHIO:\n",
      "Come, come, you wasp; i' faith, you iiiiiiiiii\n",
      "\n",
      "iter:3599/20000 loss:4.933796095428988e-05\n",
      "generated sequence: eyes that never shed remorseful tear,\n",
      "No, when my father York and Edward wept,\n",
      "To hear the piteous moan that Rutland made\n",
      "When bzzzzzzzzzz\n",
      "\n",
      "iter:3799/20000 loss:4.338517886026239e-05\n",
      "generated sequence: it to resist.\n",
      "\n",
      "PETRUCHIO:\n",
      "They shall go forward, Kate, at thy command.\n",
      "Obey the bride, you that attend on her;\n",
      "Go to the feast, uuuuuuuuuu\n",
      "\n",
      "iter:3999/20000 loss:3.917230033039232e-05\n",
      "generated sequence: of them offends me more\n",
      "than the stripes I have received, which are mighty\n",
      "ones and millions.\n",
      "\n",
      "Clown:\n",
      "Alas, poor man! a million gggggggggg\n",
      "\n",
      "iter:4199/20000 loss:3.300675030914135e-05\n",
      "generated sequence: eath in this rude assault?\n",
      "Villain, thy own hand yields thy death's instrument.\n",
      "Go thou, and fill another room in hell.\n",
      "That hanbbbbbbbbbb\n",
      "\n",
      "iter:4399/20000 loss:2.961895657790592e-05\n",
      "generated sequence: might touch that cheek!\n",
      "\n",
      "JULIET:\n",
      "Ay me!\n",
      "\n",
      "ROMEO:\n",
      "She speaks:\n",
      "O, speak again, bright angel! for thou art\n",
      "As glorious to this nightjjjjjjjjjj\n",
      "\n",
      "iter:4599/20000 loss:2.5210738240275532e-05\n",
      "generated sequence: come near my person:\n",
      "Tell them, when that my mother went with child\n",
      "Of that unsatiate Edward, noble York\n",
      "My princely father thenpppppppppp\n",
      "\n",
      "iter:4799/20000 loss:0.46522922119624127\n",
      "generated sequence: having no\n",
      "other reason but because thou hast hazel eyes: what\n",
      "eye but such an eye would spy out such a quarrel?\n",
      "Thy head is as fbbbbbbbbbb\n",
      "\n",
      "iter:4999/20000 loss:0.0011631207272876055\n",
      "generated sequence: ou.\n",
      "\n",
      "First Murderer:\n",
      "Do so, it is a point of wisdom: fare you well.\n",
      "\n",
      "Second Murderer:\n",
      "What, shall we stab him as he sleeps?\n",
      "\n",
      "Firvvvvvvvvvv\n",
      "\n",
      "iter:5199/20000 loss:0.000637643430090975\n",
      "generated sequence: isplace it with your\n",
      "little finger, there is some hope the ladies of\n",
      "Rome, especially his mother, may prevail with him.\n",
      "But I satttttttttt\n",
      "\n",
      "iter:5399/20000 loss:0.0003941445234522689\n",
      "generated sequence:  drums and trumpets, and the king will fly.\n",
      "\n",
      "YORK:\n",
      "Sons, peace!\n",
      "\n",
      "KING HENRY VI:\n",
      "Peace, thou! and give King Henry leave to speak.eeeeeeeeee\n",
      "\n",
      "iter:5599/20000 loss:0.00021300150092429249\n",
      "generated sequence: DUKE VINCENTIO:\n",
      "You shall not be admitted to his sight.\n",
      "\n",
      "ISABELLA:\n",
      "Unhappy Claudio! wretched Isabel!\n",
      "Injurious world! most damneVVVVVVVVVV\n",
      "\n",
      "iter:5799/20000 loss:0.0001731478339570458\n",
      "generated sequence: ,\n",
      "To be discover'd, that can do me good?\n",
      "\n",
      "KING RICHARD III:\n",
      "The advancement of your children, gentle lady.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Up \n",
      "\n",
      "iter:5999/20000 loss:0.00014437732792430325\n",
      "generated sequence: er,\n",
      "To see if any mean to shrink from me.\n",
      "\n",
      "LORDS:\n",
      "Good morrow, Richmond!\n",
      "\n",
      "RICHMOND:\n",
      "Cry mercy, lords and watchful gentlemen,\n",
      "Thassssssssss\n",
      "\n",
      "iter:6199/20000 loss:0.00012225841237523127\n",
      "generated sequence: NCENTIO:\n",
      "I can hardly believe that, since you know not what\n",
      "you speak. But, if ever the duke return, as our\n",
      "prayers are he may, DDDDDDDDDD\n",
      "\n",
      "iter:6399/20000 loss:0.0001088078608881915\n",
      "generated sequence:  her!\n",
      "You are to blame, my lord, to rate her so.\n",
      "\n",
      "CAPULET:\n",
      "And why, my lady wisdom? hold your tongue,\n",
      "Good prudence; smatter witiiiiiiiiii\n",
      "\n",
      "iter:6599/20000 loss:9.407002975422075e-05\n",
      "generated sequence: own.\n",
      "\n",
      "Fourth Citizen:\n",
      "You have deserved nobly of your country, and you\n",
      "have not deserved nobly.\n",
      "\n",
      "CORIOLANUS:\n",
      "Your enigma?\n",
      "\n",
      "Fourtxxxxxxxxxx\n",
      "\n",
      "iter:6799/20000 loss:8.536876302969176e-05\n",
      "generated sequence:  on her frights and griefs,\n",
      "Which never tender lady hath born greater,\n",
      "She is something before her time deliver'd.\n",
      "\n",
      "PAULINA:\n",
      "A bpppppppppp\n",
      "\n",
      "iter:6999/20000 loss:7.725818833932863e-05\n",
      "generated sequence:  what men are rich,\n",
      "They shall subscribe them for large sums of gold\n",
      "And send them after to supply our wants;\n",
      "For we will make fxxxxxxxxxx\n",
      "\n",
      "iter:7199/20000 loss:7.173301077273208e-05\n",
      "generated sequence: st in question, is thy secondary.\n",
      "Take thy commission.\n",
      "\n",
      "ANGELO:\n",
      "Now, good my lord,\n",
      "Let there be some more test made of my metal,uuuuuuuuuu\n",
      "\n",
      "iter:7399/20000 loss:6.887332287078607e-05\n",
      "generated sequence: ok on us, and shake your head,\n",
      "And call us wretches, orphans, castaways\n",
      "If that our noble father be alive?\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "My llllllllll\n",
      "\n",
      "iter:7599/20000 loss:5.755059102739324e-05\n",
      "generated sequence: d cheeks shall fade\n",
      "To paly ashes, thy eyes' windows fall,\n",
      "Like death, when he shuts up the day of life;\n",
      "Each part, deprived of \t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:7799/20000 loss:4.984386901924154e-05\n",
      "generated sequence: command;\n",
      "Which since we cannot do to make you friends,\n",
      "Be ready, as your lives shall answer it,\n",
      "At Coventry, upon Saint Lambert'pppppppppp\n",
      "\n",
      "iter:7999/20000 loss:4.542173419395112e-05\n",
      "generated sequence:  we all. But, come, let's home.\n",
      "\n",
      "BRUTUS:\n",
      "I do not like this news.\n",
      "\n",
      "SICINIUS:\n",
      "Nor I.\n",
      "\n",
      "BRUTUS:\n",
      "Let's to the Capitol. Would half myxxxxxxxxxx\n",
      "\n",
      "iter:8199/20000 loss:4.3497534961716154e-05\n",
      "generated sequence:  fair Bohemia, and remember well,\n",
      "I mentioned a son o' the king's, which Florizel\n",
      "I now name to you; and with speed so pace\n",
      "To sgggggggggg\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:8399/20000 loss:3.578010422643274e-05\n",
      "generated sequence:  do not give us the lie.\n",
      "\n",
      "Clown:\n",
      "Your worship had like to have given us one, if you\n",
      "had not taken yourself with the manner.\n",
      "\n",
      "Sheeeeeeeeeee\n",
      "\n",
      "iter:8599/20000 loss:3.554983356480079e-05\n",
      "generated sequence: at does appear as he were flay'd? O gods\n",
      "He has the stamp of Marcius; and I have\n",
      "Before-time seen him thus.\n",
      "\n",
      "MARCIUS:\n",
      "\n",
      "COMINIUS:uuuuuuuuuu\n",
      "\n",
      "iter:8799/20000 loss:3.1250139345502246e-05\n",
      "generated sequence: ory sits on our helms.\n",
      "\n",
      "CATESBY:\n",
      "Rescue, my Lord of Norfolk, rescue, rescue!\n",
      "The king enacts more wonders than a man,\n",
      "Daring an ssssssssss\n",
      "\n",
      "iter:8999/20000 loss:2.8441989970815486e-05\n",
      "generated sequence: her some: why, 'tis a happy thing\n",
      "To be the father unto many sons.\n",
      "Answer no more, for thou shalt be my queen.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "CLAffffffffff\n",
      "\n",
      "iter:9199/20000 loss:2.605177839541284e-05\n",
      "generated sequence: your leave,\n",
      "I am an officer of state, and come\n",
      "To speak with Coriolanus.\n",
      "\n",
      "First Senator:\n",
      "From whence?\n",
      "\n",
      "MENENIUS:\n",
      "From Rome.\n",
      "\n",
      "Firpppppppppp\n",
      "\n",
      "iter:9399/20000 loss:2.3379848780678003e-05\n",
      "generated sequence: ll'd none so. Camillo,--\n",
      "As you are certainly a gentleman, thereto\n",
      "Clerk-like experienced, which no less adorns\n",
      "Our gentry than mmmmmmmmmm\n",
      "\n",
      "iter:9599/20000 loss:2.3383390052913457e-05\n",
      "generated sequence: but he's not to be found.\n",
      "I prithee, Lucio, do me this kind service:\n",
      "This day my sister should the cloister enter\n",
      "And there recevvvvvvvvvv\n",
      "\n",
      "iter:9799/20000 loss:2.0373619427118684e-05\n",
      "generated sequence:  yourself; for that which I must speak\n",
      "Must either punish me, not being believed,\n",
      "Or wring redress from you. Hear me, O hear me,zzzzzzzzzz\n",
      "\n",
      "iter:9999/20000 loss:1.7702234436001164e-05\n",
      "generated sequence: f; mine is not so,\n",
      "For nothing had begot my something grief;\n",
      "Or something hath the nothing that I grieve:\n",
      "'Tis in reversion that<<<<<<<<<<\n",
      "\n",
      "iter:10199/20000 loss:1.6236971155194625e-05\n",
      "generated sequence: ay it is not;\n",
      "And the moon changes even as your mind.\n",
      "What you will have it named, even that it is;\n",
      "And so it shall be so for Kazzzzzzzzzz\n",
      "\n",
      "iter:10399/20000 loss:1.4572268860320036e-05\n",
      "generated sequence:  rudely stamp'd, and want love's majesty\n",
      "To strut before a wanton ambling nymph;\n",
      "I, that am curtail'd of this fair proportion,\n",
      "Cssssssssss\n",
      "\n",
      "iter:10599/20000 loss:1.3660317849826242e-05\n",
      "generated sequence:  of this design, did give us, with\n",
      "Rich garments, linens, stuffs and necessaries,\n",
      "Which since have steaded much; so, of his gentpppppppppp\n",
      "\n",
      "iter:10799/20000 loss:1.260415884644317e-05\n",
      "generated sequence: is no sin,\n",
      "Or of the deadly seven, it is the least.\n",
      "\n",
      "ISABELLA:\n",
      "Which is the least?\n",
      "\n",
      "CLAUDIO:\n",
      "If it were damnable, he being so witttttttttt\n",
      "\n",
      "iter:10999/20000 loss:1.1583383266042801e-05\n",
      "generated sequence:  you to clap into your\n",
      "prayers; for, look you, the warrant's come.\n",
      "\n",
      "BARNARDINE:\n",
      "You rogue, I have been drinking all night; I am zzzzzzzzzz\n",
      "\n",
      "iter:11199/20000 loss:1.0639248566803871e-05\n",
      "generated sequence:  whether my old wit be in request\n",
      "With those that have but little: this must be patch'd\n",
      "With cloth of any colour.\n",
      "\n",
      "COMINIUS:\n",
      "Nayxxxxxxxxxx\n",
      "\n",
      "iter:11399/20000 loss:9.683778966973477e-06\n",
      "generated sequence: avy plight.\n",
      "\n",
      "KING LEWIS XI:\n",
      "Renowned queen, with patience calm the storm,\n",
      "While we bethink a means to break it off.\n",
      "\n",
      "QUEEN MARGAwwwwwwwwww\n",
      "\n",
      "iter:11599/20000 loss:8.495282652347668e-06\n",
      "generated sequence: spleen\n",
      "Of Tybalt deaf to peace, but that he tilts\n",
      "With piercing steel at bold Mercutio's breast,\n",
      "Who all as hot, turns deadly poqqqqqqqqqq\n",
      "\n",
      "iter:11799/20000 loss:7.689593223858537e-06\n",
      "generated sequence: ll thinking,\n",
      "Self-loving,--\n",
      "\n",
      "SICINIUS:\n",
      "And affecting one sole throne,\n",
      "Without assistance.\n",
      "\n",
      "MENENIUS:\n",
      "I think not so.\n",
      "\n",
      "SICINIUS:\n",
      "mmmmmmmmmm\n",
      "\n",
      "iter:11999/20000 loss:7.328525082357374e-06\n",
      "generated sequence: n he waked.\n",
      "\n",
      "Lord:\n",
      "Even as a flattering dream or worthless fancy.\n",
      "Then take him up and manage well the jest:\n",
      "Carry him gently to\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:12199/20000 loss:6.4802687938936284e-06\n",
      "generated sequence: INCENTIO:\n",
      "I never heard the absent duke much detected for\n",
      "women; he was not inclined that way.\n",
      "\n",
      "LUCIO:\n",
      "O, sir, you are deceived.OOOOOOOOOO\n",
      "\n",
      "iter:12399/20000 loss:6.022165650847455e-06\n",
      "generated sequence: ommanded the sleeves should be cut out and\n",
      "sewed up again; and that I'll prove upon thee,\n",
      "though thy little finger be armed in annnnnnnnnn\n",
      "\n",
      "iter:12599/20000 loss:5.512388092938636e-06\n",
      "generated sequence: r death eats up that plant.\n",
      "\n",
      "ROMEO:\n",
      "Good morrow, father.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Benedicite!\n",
      "What early tongue so sweet saluteth me?\n",
      "Yo\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:12799/20000 loss:4.9313290332975155e-06\n",
      "generated sequence: hou but think\n",
      "What 'tis to cram a maw or clothe a back\n",
      "From such a filthy vice: say to thyself,\n",
      "From their abominable and beastlpppppppppp\n",
      "\n",
      "iter:12999/20000 loss:4.789581773820828e-06\n",
      "generated sequence: y'd for a pair of stainless maidenhoods:\n",
      "Hood my unmann'd blood, bating in my cheeks,\n",
      "With thy black mantle; till strange love, ((((((((((\n",
      "\n",
      "iter:13199/20000 loss:4.197156158625148e-06\n",
      "generated sequence: stand upon this molehill here,\n",
      "That raught at mountains with outstretched arms,\n",
      "Yet parted but the shadow with his hand.\n",
      "What! wuuuuuuuuuu\n",
      "\n",
      "iter:13399/20000 loss:3.757464033924407e-06\n",
      "generated sequence: : talk no more.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "O, then I see that madmen have no ears.\n",
      "\n",
      "ROMEO:\n",
      "How should they, when that wise men have no eye\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:13599/20000 loss:3.4028016739284793e-06\n",
      "generated sequence: yesternight\n",
      "Return'd my letter back. Then all alone\n",
      "At the prefixed hour of her waking,\n",
      "Came I to take her from her kindred's vaffffffffff\n",
      "\n",
      "iter:13799/20000 loss:3.062250862058136e-06\n",
      "generated sequence: p'd this orchard wall:\n",
      "Call, good Mercutio.\n",
      "\n",
      "MERCUTIO:\n",
      "Nay, I'll conjure too.\n",
      "Romeo! humours! madman! passion! lover!\n",
      "Appear tho((((((((((\n",
      "\n",
      "iter:13999/20000 loss:2.8384799804825888e-06\n",
      "generated sequence:  send him many years of sunshine days!\n",
      "What more remains?\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "No more, but that you read\n",
      "These accusations and thestttttttttt\n",
      "\n",
      "iter:14199/20000 loss:2.6338386862789775e-06\n",
      "generated sequence: s!\n",
      "\n",
      "GLOUCESTER:\n",
      "Be patient, they are friends, Ratcliff and Lovel.\n",
      "\n",
      "LOVEL:\n",
      "Here is the head of that ignoble traitor,\n",
      "The dangerou\"\"\"\"\"\"\"\"\"\"\n",
      "\n",
      "iter:14399/20000 loss:2.313946151843993e-06\n",
      "generated sequence: is poor furniture and mean array.\n",
      "if thou account'st it shame. lay it on me;\n",
      "And therefore frolic: we will hence forthwith,\n",
      "To ftttttttttt\n",
      "\n",
      "iter:14599/20000 loss:2.1184971876664347e-06\n",
      "generated sequence: escue him from foul despair?\n",
      "\n",
      "BONA:\n",
      "My quarrel and this English queen's are one.\n",
      "\n",
      "WARWICK:\n",
      "And mine, fair lady Bona, joins with tttttttttt\n",
      "\n",
      "iter:14799/20000 loss:1.8294134724783362e-06\n",
      "generated sequence: ther supreme, how soon confusion\n",
      "May enter 'twixt the gap of both and take\n",
      "The one by the other.\n",
      "\n",
      "COMINIUS:\n",
      "Well, on to the markiiiiiiiiii\n",
      "\n",
      "iter:14999/20000 loss:1.7031226451535986e-06\n",
      "generated sequence: w, you hear:\n",
      "When she will take the rein I let her run;\n",
      "But she'll not stumble.\n",
      "\n",
      "PAULINA:\n",
      "Good my liege, I come;\n",
      "And, I beseech ----------\n",
      "\n",
      "iter:15199/20000 loss:1.5292461688432013e-06\n",
      "generated sequence: my good friends,'--this says the belly, mark me,--\n",
      "\n",
      "First Citizen:\n",
      "Ay, sir; well, well.\n",
      "\n",
      "MENENIUS:\n",
      "'Though all at once cannot\n",
      "Sezzzzzzzzzz\n",
      "\n",
      "iter:15399/20000 loss:1.410738033769121e-06\n",
      "generated sequence:  would you did but see how it chafes, how it rages,\n",
      "how it takes up the shore! but that's not the\n",
      "point. O, the most piteous cryxxxxxxxxxx\n",
      "\n",
      "iter:15599/20000 loss:1.2466223705587255e-06\n",
      "generated sequence: he doth possess,\n",
      "By having him, making yourself no less.\n",
      "\n",
      "Nurse:\n",
      "No less! nay, bigger; women grow by men.\n",
      "\n",
      "LADY CAPULET:\n",
      "Speak bffffffffff\n",
      "\n",
      "iter:15799/20000 loss:1.1375744983865843e-06\n",
      "generated sequence: h you, tribunes, hear me but a word.\n",
      "\n",
      "AEdile:\n",
      "Peace, peace!\n",
      "\n",
      "MENENIUS:\n",
      "\n",
      "BRUTUS:\n",
      "Sir, those cold ways,\n",
      "That seem like prudent hel\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:15999/20000 loss:9.80192365318544e-07\n",
      "generated sequence: s,\n",
      "I'll tell thee what befell me on a day\n",
      "In this self-place where now we mean to stand.\n",
      "\n",
      "Second Keeper:\n",
      "Here comes a man; let's----------\n",
      "\n",
      "iter:16199/20000 loss:8.653734388985868e-07\n",
      "generated sequence: e to your daughter.\n",
      "\n",
      "LADY CAPULET:\n",
      "I will, and know her mind early to-morrow;\n",
      "To-night she is mew'd up to her heaviness.\n",
      "\n",
      "CAPULE\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:16399/20000 loss:8.35828068943556e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: other's death,\n",
      "And shall the same give pardon to a slave?\n",
      "My brother slew no man; his fault was thought,\n",
      "And yet his punishment uuuuuuuuuu\n",
      "\n",
      "iter:16599/20000 loss:6.986866358715815e-07\n",
      "generated sequence: rk: I'll not be long before\n",
      "I call upon thee.\n",
      "\n",
      "Mariner:\n",
      "Make your best haste, and go not\n",
      "Too far i' the land: 'tis like to be lollllllllll\n",
      "\n",
      "iter:16799/20000 loss:6.32231703434627e-07\n",
      "generated sequence: r be it from my heart, the thought of it!\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "As little joy, my lord, as you suppose\n",
      "You should enjoy, were you th\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:16999/20000 loss:5.66112958750864e-07\n",
      "generated sequence: th\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "Second Citizeiiiiiiiiii\n",
      "\n",
      "iter:17199/20000 loss:5.166549640023277e-07\n",
      "generated sequence: a low submissive reverence\n",
      "Say 'What is it your honour will command?'\n",
      "Let one attend him with a silver basin\n",
      "Full of rose-water \t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:17399/20000 loss:4.522914737492556e-07\n",
      "generated sequence: , my friends are in the north.\n",
      "\n",
      "KING RICHARD III:\n",
      "Cold friends to Richard: what do they in the north,\n",
      "When they should serve the\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:17599/20000 loss:0.12850141611131874\n",
      "generated sequence: truchio, sister Katharina,\n",
      "And thou, Hortensio, with thy loving widow,\n",
      "Feast with the best, and welcome to my house:\n",
      "My banquet ssssssssss\n",
      "\n",
      "iter:17799/20000 loss:0.0009023455522037693\n",
      "generated sequence: ortune's malice overthrow my state,\n",
      "My mind exceeds the compass of her wheel.\n",
      "\n",
      "WARWICK:\n",
      "Then, for his mind, be Edward England's ssssssssss\n",
      "\n",
      "iter:17999/20000 loss:0.00024559526194934734\n",
      "generated sequence: hore's wife hath a pretty foot,\n",
      "A cherry lip, a bonny eye, a passing pleasing tongue;\n",
      "And that the queen's kindred are made gentpppppppppp\n",
      "\n",
      "iter:18199/20000 loss:8.789004624304653e-05\n",
      "generated sequence: oughly persuaded;\n",
      "For though abundantly they lack discretion,\n",
      "Yet are they passing cowardly. But, I beseech you,\n",
      "What says the ovvvvvvvvvv\n",
      "\n",
      "iter:18399/20000 loss:5.2962516310799404e-05\n",
      "generated sequence: on, go, and batten on cold bits.\n",
      "\n",
      "Third Servingman:\n",
      "What, you will not? Prithee, tell my master what a\n",
      "strange guest he has hereoooooooooo\n",
      "\n",
      "iter:18599/20000 loss:0.002382439171042279\n",
      "generated sequence: INGS:\n",
      "Cannot thy master sleep these tedious nights?\n",
      "\n",
      "Messenger:\n",
      "So it should seem by that I have to say.\n",
      "First, he commends him OOOOOOOOOO\n",
      "\n",
      "iter:18799/20000 loss:0.0004933894245368719\n",
      "generated sequence: ave need of you:\n",
      "Your brother is imprison'd by your means,\n",
      "Myself disgraced, and the nobility\n",
      "Held in contempt; whilst many fairwwwwwwwwww\n",
      "\n",
      "iter:18999/20000 loss:5.0207640188091316e-05\n",
      "generated sequence: nough for him.\n",
      "\n",
      "Second Servingman:\n",
      "Come, we are fellows and friends: he was ever too\n",
      "hard for him; I have heard him say so himsepppppppppp\n",
      "\n",
      "iter:19199/20000 loss:6.0319351805446784e-05\n",
      "generated sequence:  me--that a brother should\n",
      "Be so perfidious!--he whom next thyself\n",
      "Of all the world I loved and to him put\n",
      "The manage of my statnnnnnnnnnn\n",
      "\n",
      "iter:19399/20000 loss:3.941831485462899e-05\n",
      "generated sequence:  wail.\n",
      "To fear the foe, since fear oppresseth strength,\n",
      "Gives in your weakness strength unto your foe,\n",
      "And so your follies fightxxxxxxxxxx\n",
      "\n",
      "iter:19599/20000 loss:2.552641504280473e-05\n",
      "generated sequence: ere nor no man ever saw.\n",
      "\n",
      "SLY:\n",
      "Now Lord be thanked for my good amends!\n",
      "\n",
      "ALL:\n",
      "Amen.\n",
      "\n",
      "SLY:\n",
      "I thank thee: thou shalt not lose by itssssssssss\n",
      "\n",
      "iter:19799/20000 loss:2.107690760567493e-05\n",
      "generated sequence: r rivers drown their shores,\n",
      "As if the world were all dissolved to tears,\n",
      "So high above his limits swells the rage\n",
      "Of Bolingbrok\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "iter:19999/20000 loss:3.1146342435022236e-05\n",
      "generated sequence: gain.\n",
      "\n",
      "ROMEO:\n",
      "Alive, in triumph! and Mercutio slain!\n",
      "Away to heaven, respective lenity,\n",
      "And fire-eyed fury be my conduct now!\n",
      "Nobbbbbbbbbb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations.\n",
    "iters       = 20000\n",
    "# Number of printing iterations\n",
    "print_iters = 200   \n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the optimizer and the loss function.\n",
    "opt       = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    opt.zero_grad()\n",
    "    input, target = get_input_and_target()            # Fetch input and target.\n",
    "    input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "    input = input[None] \n",
    "    target = target[None] \n",
    "    predicted = model(input,target)\n",
    "    predicted = predicted.permute(0,2,1)\n",
    "    loss = loss_func(predicted,target)\n",
    "    \n",
    "    loss.backward()\n",
    "    loss_sum += loss.item()                                # Accumulate the loss.\n",
    "    opt.step()\n",
    "\n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(generate_text(model,target,input)))\n",
    "\n",
    "              \n",
    "        # Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T00:38:13.728474Z",
     "start_time": "2019-05-15T00:38:13.559531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(np.array(all_losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation: A Sample of Generated Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T03:10:52.267837Z",
     "start_time": "2019-05-15T03:10:51.986701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gain.\\n\\nROMEO:\\nAlive, in triumph! and Mercutio slain!\\nAway to heaven, respective lenity,\\nAnd fire-eyed fury be my conduct now!\\nNobbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input, rand_target = get_input_and_target()  \n",
    "rand_input = rand_input[None].to(device)\n",
    "rand_target = rand_target[None].to(device)\n",
    "print(\"\\n\")\n",
    "generate_text(model,target,input,gen_len=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
